<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>0x7df</title><link href="http://0x7df.github.io/" rel="alternate"></link><link href="http://0x7df.github.io/feeds/all.atom.xml" rel="self"></link><id>http://0x7df.github.io/</id><updated>2015-10-03T20:06:00+01:00</updated><entry><title>Static site generation, Pelican, and GitHub hosting</title><link href="http://0x7df.github.io/static-site-generation.html" rel="alternate"></link><updated>2015-10-03T20:06:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-10-03:static-site-generation.html</id><summary type="html">&lt;p&gt;This post discusses moving setting up and using a static site generator,
&lt;a href="http://blog.getpelican.com"&gt;Pelican&lt;/a&gt;, and moving existing posts from &lt;a href="http://www.wordpress.com"&gt;Wordpress&lt;/a&gt; to Pelican.&lt;/p&gt;
&lt;h2&gt;Comparing and choosing a generator&lt;/h2&gt;
&lt;p&gt;Many options are available for static site generation, with
&lt;a href="http://octopress.org"&gt;Octopress&lt;/a&gt; being a popular choice. I was interested in a Python-
based one, &lt;a href="https://jakevdp.github.io/blog/2013/05/07/migrating-from-octopress-to-pelican"&gt;for reasons that have been discussed elsewhere&lt;/a&gt;, and the
usual options that come up are &lt;a href="http://hyde.github.io"&gt;Hyde&lt;/a&gt;, &lt;a href="https://getnikola.com"&gt;Nikola&lt;/a&gt;, and
Pelican. &lt;a href="https://jakevdp.github.io/blog/2013/05/07/migrating-from-octopress-to-pelican"&gt;The article cited above&lt;/a&gt; suggested Hyde wasn't
well documented, so I skipped that altogether in the interests of time. The
Nikola documentation looked great, so I started with that; however, I spent
quite a while trying to install it, eventually with no luck. I needed to
install some prerequisites, the installation took a long time, and I ended up
with some missing packages. I'm sure another hour of Googling
&lt;a href="http://stackoverflow.com"&gt;StackOverflow&lt;/a&gt; and messing would have sorted it, but I lost
interest and moved on to Pelican; this &lt;a href="http://docs.getpelican.com/en/stable/quickstart.html"&gt;installed out of the box in a few
seconds&lt;/a&gt;, and I was away.&lt;/p&gt;
&lt;h2&gt;Importing from Wordpress&lt;/h2&gt;
&lt;p&gt;Importing from Wordpress just involves exporting the &lt;a href="http://0x7df.wordpress.com"&gt;original blog&lt;/a&gt; as
an XML file, which can be done from the "WP Admin" menu under "Tools". Pelican
provides a command for importing from this file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;pelican&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;wpfile&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="n"&gt;markdown&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="nb"&gt;dir&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;wordpress&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xml&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;--wpfile&lt;/code&gt; flag specifies that the source is Wordpress (various
alternatives are available), the &lt;code&gt;-m&lt;/code&gt; option specified that the output should
be Markdown (as opposed to reStructured Text), and &lt;code&gt;--dir-page&lt;/code&gt; tells Pelican
to include the "Pages" from the Wordpress blog as well as the blog articles,
and put them in a &lt;code&gt;pages&lt;/code&gt; directory.&lt;/p&gt;
&lt;h2&gt;Maths pain&lt;/h2&gt;
&lt;p&gt;The original Wordpress articles that I imported contained a lot of maths, and
there was a significant amount of pain involved in converting the syntax used
by Wordpress to the syntax required by Pelican. in fact, Pelican doesn't
natively support maths, so a plugin is required: for this I used
&lt;a href="https://github.com/barrysteyn/pelican_plugin-render_math"&gt;render-math&lt;/a&gt;. As per the docs, for this I needed to install
&lt;a href="https://github.com/mintchaos/typogrify"&gt;Typogrify&lt;/a&gt; first, then add the following to the &lt;code&gt;pelicanconf.py&lt;/code&gt;
settings file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;PLUGIN_PATHS = [&amp;quot;..&amp;quot;]
PLUGINS = [&amp;quot;pelican_plugin-render_math&amp;quot;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to point Pelican at the location where I cloned the plugin.&lt;/p&gt;
&lt;p&gt;The text wrangling that was required to convert the Wordpress-syntax maths
delimiters:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;\&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;latex&lt;/span&gt;&lt;span class="x"&gt; ...maths... \&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;latex&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to those required for Pelican (i.e.:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$$ ...maths... $$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;for displayed equations and:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;...math...&lt;span class="err"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;for in-line equations), was both annoying and unnecessary in theory (since
both platforms are using LaTeX, dammit), and is the subject of &lt;a href="http://0x7df.github.io/drafts/slug.html"&gt;a different
post&lt;/a&gt;. Once
done, I could move on to themes.&lt;/p&gt;
&lt;h2&gt;Pelican themes&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://pelicanthemes.com/"&gt;This website&lt;/a&gt; shows examples of available themes, from
which I chose the &lt;a href="https://github.com/molivier/nest"&gt;Nest&lt;/a&gt; theme; I cloned this directly into the Pelican
install directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cd /usr/local/lib/python2.7/dist-packages/pelican/themes/
sudo git clone https://github.com/molivier/nest.git
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(The &lt;code&gt;pelican-themes -lv&lt;/code&gt; command can be used to determine the path to the
Pelican installation directory.)&lt;/p&gt;
&lt;p&gt;(Afterwards I realised a &lt;a href="http://github.com"&gt;GitHub&lt;/a&gt; repository &lt;a href="https://github.com/getpelican/pelican-themes"&gt;pelican-themes&lt;/a&gt; containing
a large number of themes is available, making it a lot easier to switch while
looking for a good theme.)&lt;/p&gt;
&lt;h2&gt;Deployment to GitHub&lt;/h2&gt;
&lt;p&gt;Although I have a domain - &lt;a href="http://0x7df.io"&gt;0x7df.io&lt;/a&gt; - and a website hosted
on &lt;a href="http://aws.amazon.com/"&gt;Amazon Web Services&lt;/a&gt;, I wanted both to keep this separate to begin
with, and try out hosting on &lt;a href="https://pages.github.com/"&gt;GitHub Pages&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are two ways to manage a website/blog on GitHub pages. The first is to
create a special branch, which has to be called &lt;code&gt;gh-pages&lt;/code&gt; inside a repository;
the web documents committed on that branch then become available at:
&lt;code&gt;http://username.github.io/project/&lt;/code&gt;. This is ideal for creating
project-specific sites, like documentation. The second method, which is what I
used, is to create a special repository, called &lt;code&gt;username.github.io&lt;/code&gt; which
contains the web pages. These are then available at
&lt;code&gt;http://username.github.io/&lt;/code&gt;; they're considered the general user or
organisation web pages, as opposed to being specific to any one project. In
this case, the data doesn't need to be on the &lt;code&gt;gh-pages&lt;/code&gt; branch, but can be on
the more usual branch &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I used the &lt;a href="https://github.com/davisp/ghp-import/"&gt;ghp-import&lt;/a&gt; tool to do the uploading - this is used by the
Pelican &lt;code&gt;Makefile&lt;/code&gt; and is recommended &lt;a href="http://martinbrochhaus.com/pelican2.html"&gt;elsewhere&lt;/a&gt;. I installed it
with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-get install ghp-import
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;even though this isn't documented. As suggested &lt;a href="http://martinbrochhaus.com/pelican2.html#comment-1819417669"&gt;here&lt;/a&gt;, I added all
the content and tools to a
different branch called &lt;code&gt;source&lt;/code&gt;, but it can be anything - to keep it
separate from the output, which I want to commit to the &lt;code&gt;master&lt;/code&gt; branch. After
making changes to the content, running &lt;code&gt;make html&lt;/code&gt; to re-build, checking on a
local development server that runs in the background (initiated by &lt;code&gt;python -m
pelican.server &amp;amp;&lt;/code&gt; inside the &lt;code&gt;output&lt;/code&gt; directory), then committing to the
&lt;code&gt;source&lt;/code&gt; branch of my repository, I can just run &lt;code&gt;make github&lt;/code&gt; to call
&lt;code&gt;ghp-import&lt;/code&gt;. This commits the changes to the built website (in the &lt;code&gt;output&lt;/code&gt;
directory) to branch &lt;code&gt;master&lt;/code&gt;, and pushes the modified &lt;code&gt;master&lt;/code&gt; branch to the
repository on GitHub. With this workflow there is never a need to explicitly
switch to &lt;code&gt;master&lt;/code&gt; and do any commits - this is all handled by &lt;code&gt;ghp-import&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you're using the project-specific &lt;code&gt;gh-pages&lt;/code&gt; branch, the &lt;code&gt;ghp-import&lt;/code&gt; will
still do the job. It defaults actually to committing the built website to this
branch, and in my workflow requires the &lt;code&gt;-b master&lt;/code&gt; switch to tell it to commit
to &lt;code&gt;master&lt;/code&gt; instead. Note that the &lt;code&gt;-p&lt;/code&gt; flag to &lt;code&gt;ghp-import&lt;/code&gt; will handle the
push to GitHub, although in the Pelican Makefile this flag isn't used and the
push is a separate command.&lt;/p&gt;
&lt;p&gt;Either way, it's worth being very clear that &lt;code&gt;ghp-import&lt;/code&gt; treats the branch it
commits to - &lt;code&gt;gh-pages&lt;/code&gt; by default or whatever branch you specify if the &lt;code&gt;-b&lt;/code&gt;
flag is supplied - as &lt;em&gt;totally derivative&lt;/em&gt;. Assume it blows away whatever is
already there and replaces it with the new content. So you never manually
modify anything on that branch; keep all your content, configuration files,
tools, and anything else you care about, on a different branch, and keep the
destination branch for &lt;code&gt;ghp-import&lt;/code&gt; clean.&lt;/p&gt;</summary><category term="pelican"></category><category term="publishing"></category><category term="blog"></category><category term="python"></category><category term="github"></category><category term="latex"></category></entry><entry><title>Virtual Temperature</title><link href="http://0x7df.github.io/virtual-temperature.html" rel="alternate"></link><updated>2015-08-31T22:02:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-08-31:virtual-temperature.html</id><summary type="html">&lt;h2&gt;Equation of state for dry air&lt;/h2&gt;
&lt;p&gt;The ideal-gas equation of state is:&lt;/p&gt;
&lt;div class="math"&gt;$$ p = \rho R T $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( R\)&lt;/span&gt; is the individual gas constant for the
gas in question, and:&lt;/p&gt;
&lt;div class="math"&gt;$$ R = \frac{nR^*}{m} = \frac{R^*}{M} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( R^*\)&lt;/span&gt; is the universal gas constant (&lt;span class="math"&gt;\( 8.31~
\mathrm{J/mol.K}\)&lt;/span&gt;) and &lt;span class="math"&gt;\( n, m\)&lt;/span&gt; are the number of moles and the
mass of the sample of gas, respectively; and &lt;span class="math"&gt;\( M = m/n\)&lt;/span&gt;
is the molecular mass of the gas.&lt;/p&gt;
&lt;p&gt;Dry air is typically assumed to be a perfect gas, with an individual gas
constant of &lt;span class="math"&gt;\( 287~\mathrm{J/kg.K}\)&lt;/span&gt;  or &lt;span class="math"&gt;\( 2.87 \times 10^6~\mathrm{cm^2/s^2.K}\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2&gt;Moist air and virtual temperature&lt;/h2&gt;
&lt;p&gt;Water vapour is also assumed to be a perfect gas, with an individual gas
constant of &lt;span class="math"&gt;\( 461.5~\mathrm{J/kg.K}\)&lt;/span&gt;. The ratio of &lt;span class="math"&gt;\( R / R_v\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \sigma = \frac{R}{R_v} = \frac{M_v}{M} = 0.622 $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( R, M\)&lt;/span&gt; are the gas constant and molecular mass
of dry air, and &lt;span class="math"&gt;\( R_v, M_v\)&lt;/span&gt; of water vapour.&lt;/p&gt;
&lt;p&gt;Moist air is a mixture of dry air and water vapour. To determine the
individual gas constant of moist air, consisting of some mixture of dry
air and water vapour, we first write the equation of state for water
vapour:&lt;/p&gt;
&lt;div class="math"&gt;$$ e = \rho_v R_v T $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( e\)&lt;/span&gt; is the water vapour pressure and &lt;span class="math"&gt;\( \rho_v\)&lt;/span&gt; is the density of water
vapour. The pressure of the moist air is the sum of the partial pressures of
the dry air and the water vapour:&lt;/p&gt;
&lt;div class="math"&gt;$$ p_m = p + e = \rho R T + \rho_v R_v T $$&lt;/div&gt;
&lt;div class="math"&gt;$$ p_m = \rho R T + \rho_v \frac{R}{\sigma} T $$&lt;/div&gt;
&lt;div class="math"&gt;$$ p_m = RT\left(\rho + \frac{\rho_v}{\sigma}\right) $$&lt;/div&gt;
&lt;div class="math"&gt;$$ p_m = RT\frac{1}{V}\left(m + \frac{m_v}{\sigma}\right) $$&lt;/div&gt;
&lt;div class="math"&gt;$$ p_m = RT \frac{\rho_m}{m + m_v}\left(m +
\frac{m_v}{\sigma}\right) $$&lt;/div&gt;
&lt;p&gt;This allows us to introduce the &lt;em&gt;virtual temperature&lt;/em&gt;, which is the
fictitious temperature that dry air would have to have to achieve
the same (lower) density of the moist air, at the same pressure:&lt;/p&gt;
&lt;div class="math"&gt;$$ p_m = \rho_m RT_v $$&lt;/div&gt;
&lt;p&gt;From comparing the last two equations we can see that:&lt;/p&gt;
&lt;div class="math"&gt;$$ T_v = \left[m + \frac{m_v}{\sigma}\right]\frac{1}{m+m_v} T $$&lt;/div&gt;
&lt;div class="math"&gt;$$ T_v = \left[m + m_v + \frac{m_v}{\sigma} - m_v\right]
\frac{1}{m + m_v} T $$&lt;/div&gt;
&lt;div class="math"&gt;$$ T_v = \left[1 + \frac{m_v}{m +
m_v}\left(\frac{1}{\sigma} - 1\right)\right] T $$&lt;/div&gt;
&lt;div class="math"&gt;$$ T_v = \left[1 + \frac{m_v}{m + m_v}\frac{1 -
\sigma}{\sigma} \right] \frac{1}{m + m_v} T $$&lt;/div&gt;
&lt;p&gt;By definition, the mixing ratio &lt;span class="math"&gt;\( \mu = m_v/(m + m_v)\)&lt;/span&gt;
is the ratio of the mass of water vapour to the mass of
moist air:&lt;/p&gt;
&lt;div class="math"&gt;$$ T_v = \left[1 + \frac{1-\sigma}{\sigma} \mu \right] T $$&lt;/div&gt;
&lt;p&gt;The virtual temperature is always slightly higher, by at most a few
degrees, than the true temperature of the moist air.&lt;/p&gt;
&lt;h2&gt;Geopotential in terms of virtual temperature&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://0x7df.github.io/geopotential.html"&gt;Elsewhere&lt;/a&gt; we have seen that the geopotential is:&lt;/p&gt;
&lt;div class="math"&gt;$$ d\phi = -\frac{1}{\rho} dp $$&lt;/div&gt;
&lt;p&gt;Substituting in the equation of state for moist air, involving the
virtual temperature:&lt;/p&gt;
&lt;div class="math"&gt;$$ d\phi = -RT_v \frac{dp}{p} $$&lt;/div&gt;
&lt;p&gt;Integrating:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi = \phi_0 - R \int_{p_0}^p T_v d\ln p $$&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary></entry><entry><title>Geopotential</title><link href="http://0x7df.github.io/geopotential.html" rel="alternate"></link><updated>2015-08-30T16:58:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-08-30:geopotential.html</id><summary type="html">&lt;p&gt;The &lt;em&gt;geopotential&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi = gz $$&lt;/div&gt;
&lt;p&gt;is the gravitational potential - i.e. the gravitational potential energy
per unit mass - at a location in the earth's atmosphere. It is often
used as a vertical coordinate instead of height above sea level,
&lt;span class="math"&gt;\( z\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The geopotential at height &lt;span class="math"&gt;\( z\)&lt;/span&gt; is the difference
between the gravitational potential energy at some reference height,
&lt;span class="math"&gt;\( z_0\)&lt;/span&gt;, usually taken to be zero (sea level), and
that at &lt;span class="math"&gt;\( z\)&lt;/span&gt;. This difference is numerically equal
to the work done in raising the parcel from &lt;span class="math"&gt;\( z_0\)&lt;/span&gt;
to &lt;span class="math"&gt;\( z\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi(z) = \int_{z_0}^z g(z') dz' $$&lt;/div&gt;
&lt;p&gt;The simplification to:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi = gz $$&lt;/div&gt;
&lt;p&gt;assumes that &lt;span class="math"&gt;\( g\)&lt;/span&gt; is constant with height. If the
variation is to be taken into account, a suitable profile for
&lt;span class="math"&gt;\( g(z)\)&lt;/span&gt; is:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi(z) = \frac{g_0}{\left[ 1 + \left(
z/E\right)\right]^2} $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( g_0\)&lt;/span&gt; is the value at sea level and
&lt;span class="math"&gt;\( E\)&lt;/span&gt; is the earth's mean radius. Substituting into
the definition of geopotential:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi(z) = \int_{z_0}^z g(z') dz' $$&lt;/div&gt;
&lt;p&gt;gives:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi(z) = \int_{z_0}^z \frac{g_0}{\left[ 1 + z' / E
\right]^2} dz' $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \phi(z) = g_0 E^2 \int_{z_0}^z \frac{1}{\left[ E+z'
\right]^2} dz' $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \phi(z) = g_0 \frac{z-z_0}{\left( 1+z/E \right) \left(
1+z_0/E \right)} $$&lt;/div&gt;
&lt;p&gt;or, if we take &lt;span class="math"&gt;\( z_0\)&lt;/span&gt; to be zero:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi(z) = g_0 \frac{z}{1+z/E} $$&lt;/div&gt;
&lt;p&gt;The assumption that gravity is constant is equivalent to assuming that
&lt;span class="math"&gt;\( z \ll E\)&lt;/span&gt; so that &lt;span class="math"&gt;\( z/E \ll 1\)&lt;/span&gt;,
and therefore that the denominator on the right-hand
side of the above equation is unity.&lt;/p&gt;
&lt;p&gt;In terms of differentials:&lt;/p&gt;
&lt;div class="math"&gt;$$ d\phi = g dz $$&lt;/div&gt;
&lt;p&gt;and taking into consideration the hydrostatic equation:&lt;/p&gt;
&lt;div class="math"&gt;$$ dp = -\rho g dz $$&lt;/div&gt;
&lt;p&gt;we obtain:&lt;/p&gt;
&lt;div class="math"&gt;$$ d\phi = -\frac{dp}{\rho} = -\alpha dp $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( \alpha = 1 / \rho\)&lt;/span&gt; is the specific volume
(volume per unit mass).&lt;/p&gt;
&lt;p&gt;The geopotential is larger than the geometric height by a factor of
&lt;span class="math"&gt;\( g\)&lt;/span&gt; - e.g. the geopotential in &lt;span class="math"&gt;\( \mathrm{J/kg}\)&lt;/span&gt; is about 10
times the magnitude of the geometric altitude in metres. To make the
geopotential have numerical magnitude more nearly equal to the geometric
height, it is often expressed in units a factor of &lt;span class="math"&gt;\( g_0\)&lt;/span&gt;
smaller; these units are usually called &lt;em&gt;geopotential
metres&lt;/em&gt;, or &lt;em&gt;dynamic metres&lt;/em&gt;, or &lt;em&gt;geodynamic metres&lt;/em&gt;. That is, the
geopotential in these units, is:&lt;/p&gt;
&lt;div class="math"&gt;$$ \mathrm{gpm}(z) = \frac{\phi(z)}{g_0} $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \mathrm{gpm}(z) = \frac{\int_{z_0}^z g(z') dz'}{g_0} $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \mathrm{gpm}(z) = \frac{z}{1+z/E} $$&lt;/div&gt;
&lt;h2&gt;Rogers and Yau Problem 3.2b&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Show that the geopotential at pressure level &lt;span class="math"&gt;\( p\)&lt;/span&gt;
of an atmosphere in hydrostatic equilibium is given
by:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ \phi(p) = R\bar T\ln{\left(p_0/p\right)} $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( \phi(p_0) = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The differential expression for hydrostatic equilibrium is:&lt;/p&gt;
&lt;div class="math"&gt;$$ dp = -g\rho dz $$&lt;/div&gt;
&lt;p&gt;From the definition of geopotential:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi(z) = g \int_{z_0}^z dz' $$&lt;/div&gt;
&lt;p&gt;we have:&lt;/p&gt;
&lt;div class="math"&gt;$$ d\phi = g dz $$&lt;/div&gt;
&lt;p&gt;Hence:&lt;/p&gt;
&lt;div class="math"&gt;$$ dp = -\rho d\phi $$&lt;/div&gt;
&lt;p&gt;Introducing the equation of state gives:&lt;/p&gt;
&lt;div class="math"&gt;$$ dp = \frac{p}{RT} d\phi $$&lt;/div&gt;
&lt;div class="math"&gt;$$ \int \frac{dp}{p} = -\frac{1}{R} \int \frac{d\phi}{T} $$&lt;/div&gt;
&lt;p&gt;Performing the integration gives:&lt;/p&gt;
&lt;div class="math"&gt;$$ \ln(p) = -\frac{1}{R\bar T} \phi(p) + C $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( \bar T\)&lt;/span&gt; is the average temperature
through the layer from &lt;span class="math"&gt;\( p_0\)&lt;/span&gt; to &lt;span class="math"&gt;\( p\)&lt;/span&gt;.
Since &lt;span class="math"&gt;\( \phi(p_0) = 0\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ C = \ln{p_0} $$&lt;/div&gt;
&lt;p&gt;Hence:&lt;/p&gt;
&lt;div class="math"&gt;$$ \phi(p) = R\bar T\ln{(p_0/p)} $$&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary></entry><entry><title>Thermal radiation, Kirchhoff's law, and black bodies (1/4)</title><link href="http://0x7df.github.io/thermal-radiation-kirchhoffs-law-and-black-bodies-14.html" rel="alternate"></link><updated>2015-05-17T14:53:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-05-17:thermal-radiation-kirchhoffs-law-and-black-bodies-14.html</id><summary type="html">&lt;h2&gt;Thermal radiation&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Thermal imaging" src="https://0x7df.files.wordpress.com/2015/05/sts-3_infrared_on_reentry.jpg?w=127" /&gt;&lt;/p&gt;
&lt;p&gt;All matter continuously emits electromagnetic radiation as a consequence
of its temperature. This radiation is called &lt;strong&gt;thermal radiation&lt;/strong&gt; or
&lt;strong&gt;heat radiation&lt;/strong&gt; (although of course it isn't intrinsically different
from electromagnetic radiation generated by any other means). Thermal
radiation is what makes thermal imaging possible, and why hot embers
glow, etc. From our everyday experience and from experimentation we can
see that both the wavelength and intensity of radiation emitted depend
in some way on the temperature of the matter.&lt;/p&gt;
&lt;p&gt;We can understand a lot about the properties of thermal radiation from
thought experiments, in particular by considering a hollow enclosure of
any shape, whose walls are opaque to radiation and which are held
everywhere at a constant temperature. The inner surface emits thermal
radiation, and therefore the interior space is filled with a radiation
field. The walls also absorb radiation. If at a particular time a small
volume &lt;span class="math"&gt;\( dv\)&lt;/span&gt; of space around a point &lt;span class="math"&gt;\( P\)&lt;/span&gt; contains an amount of radiation &lt;span class="math"&gt;\( Q\)&lt;/span&gt;,
then the quantity &lt;span class="math"&gt;\( Q/dv\)&lt;/span&gt; is called the &lt;strong&gt;energy
density&lt;/strong&gt; at point &lt;span class="math"&gt;\( P\)&lt;/span&gt;. We can show that &lt;em&gt;the energy
density in a constant-temperature enclosure is independent of the nature
of the walls of the enclosure, and depends only on the temperature of
the walls&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;First, imagine two such containers, &lt;span class="math"&gt;\( A\)&lt;/span&gt; and &lt;span class="math"&gt;\( B\)&lt;/span&gt;,
with the same wall temperatures, but in which, for some
reason (e.g. the material of the walls perhaps) the energy density is
different. It is higher in &lt;span class="math"&gt;\( B\)&lt;/span&gt;
&lt;a href="https://0x7df.files.wordpress.com/2015/05/two_cavities.png"&gt;&lt;img alt="two_cavities" src="https://0x7df.files.wordpress.com/2015/05/two_cavities.png?w=300" /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then imagine we can bring the two enclosures together to form a single
enclosure - perhaps they each have at least one flat face of a given
shape and size, which we can match up, and then instantaneously remove
these walls so the two cavities are joined into one. If &lt;span class="math"&gt;\( B\)&lt;/span&gt;
had the higher initial energy density, then the energ
density in &lt;span class="math"&gt;\( A\)&lt;/span&gt; will begin to increase, and the energy
density in &lt;span class="math"&gt;\( B\)&lt;/span&gt; will decrease. Correspondingly, the
walls of &lt;span class="math"&gt;\( A\)&lt;/span&gt; will increase in temperature by
absorbing the excess radiation, and the walls of &lt;span class="math"&gt;\( B\)&lt;/span&gt;
will cool. The result is that we are causing heat to flow from one body
to another at higher temperature without doing any work, which
contravenes the second law of thermodynamics. From this we can conclude
that, if the walls are at the same temperature, then the energy
densities must be the same, no matter what. Hence, the energy density in
each enclosure is dependent on only the wall temperature.&lt;/p&gt;
&lt;p&gt;The result also applies to the energy density in any restricted range of
wavelengths,  between &lt;span class="math"&gt;\( \lambda\)&lt;/span&gt; and &lt;span class="math"&gt;\( \lambda
+ d\lambda\)&lt;/span&gt;. If, when we first conjoin the two enclosures,
instead of simply removing the interior walls we replace them with a
screen that is transparent to radiation only in the wavelength range of
interest, then the situation is the same. Therefore not only must the
total energy density be the same in the two enclosures (if their wall
temperatures are the same), but the energy density in any given range of
wavelengths must also be the same; i.e. the energy in both enclosures
must have the same &lt;em&gt;spectrum&lt;/em&gt;. This spectrum is called the &lt;strong&gt;Planck
spectrum&lt;/strong&gt; or the &lt;strong&gt;black-body spectrum&lt;/strong&gt;, and is evidently a function
of temperature only.&lt;/p&gt;
&lt;h2&gt;Kirchhoff's Law (1859)&lt;/h2&gt;
&lt;p&gt;For radiation of wavelengths between &lt;span class="math"&gt;\( \lambda\)&lt;/span&gt; and
&lt;span class="math"&gt;\( \lambda + d\lambda\)&lt;/span&gt;, the &lt;strong&gt;absorptive power&lt;/strong&gt; (or
&lt;strong&gt;absorptivity&lt;/strong&gt;), &lt;span class="math"&gt;\( a_\lambda\)&lt;/span&gt;, of a surface is
defined as the fraction of the energy incident on the surface that is
absorbed. The &lt;strong&gt;emissive power&lt;/strong&gt;, &lt;span class="math"&gt;\( e_\lambda\)&lt;/span&gt;, is
the energy emitted per unit area per unit time (per unit wavelength);
such that &lt;span class="math"&gt;\( e_\lambda d\lambda\)&lt;/span&gt; is the energy
emitted per unit area per unit time.&lt;/p&gt;
&lt;p&gt;Knowing this, we can determine that, if a new body is inserted into a
constant-temperature enclosure of the kind discussed earlier, then some
amount of radiation, &lt;span class="math"&gt;\( dQ\)&lt;/span&gt;, will be incident on each
unit area in each unit time, and an amount &lt;span class="math"&gt;\( a_\lambda dQ\)&lt;/span&gt;
will be absorbed. Since the nature of the walls of the
outer container cannot have any effect on the density or spectrum of the
radiation inside the enclosure, then the body cannot either; it must be
in equilibrium and the emission per unit area per unit time -
&lt;span class="math"&gt;\( e_\lambda d\lambda\)&lt;/span&gt; - must equate to the absorption.
Hence:&lt;/p&gt;
&lt;div class="math"&gt;$$ a_\lambda dQ = e_\lambda d\lambda $$&lt;/div&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{dQ}{d\lambda} = \frac{e_\lambda}{a_\lambda} $$&lt;/div&gt;
&lt;p&gt;Because &lt;span class="math"&gt;\( dQ\)&lt;/span&gt; depends only on the temperature, then
for a given temperature both sides of the above equation are equal to a
constant, whose value depends on the temperature and the wavelengths in
question, but not on the composition of the body. This is &lt;strong&gt;Kirchhoff's
law&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The ratio of the emissive to absorptive power for radiation of a
given wavelength is the same for all bodies at the same temperature&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A way of clarifying this is to compare two different bodies, placed
separately in the interior. The body discussed above, has equilibrium
state:&lt;/p&gt;
&lt;div class="math"&gt;$$ a_\lambda dQ = e_\lambda d\lambda $$&lt;/div&gt;
&lt;p&gt;but if this is replaced with a different body having different surface
properties &lt;span class="math"&gt;\( a_\lambda'\)&lt;/span&gt; and &lt;span class="math"&gt;\( e_\lambda'\)&lt;/span&gt;,
then the new equilibrium state is:&lt;/p&gt;
&lt;div class="math"&gt;$$ a_\lambda' dQ = e_\lambda' d\lambda $$&lt;/div&gt;
&lt;p&gt;The ratios &lt;span class="math"&gt;\( a_\lambda/e_\lambda\)&lt;/span&gt; and
&lt;span class="math"&gt;\( a_\lambda' / e_\lambda'\)&lt;/span&gt; must clearly be equal.
Alternatively, you can think of a body inside and therefore in
equilibrium with one enclosure, being instantaneously transferred to a
different enclosure at the same temperature, and arrive at the same
conclusion again.&lt;/p&gt;
&lt;h2&gt;Black bodies and perfect radiators&lt;/h2&gt;
&lt;p&gt;One interesting consequence of the fact that:&lt;/p&gt;
&lt;div class="math"&gt;$$ a_\lambda dQ = e_\lambda d\lambda $$&lt;/div&gt;
&lt;p&gt;is that a stronger absorber (larger &lt;span class="math"&gt;\( a_\lambda\)&lt;/span&gt;) is
also a stronger emitter (larger &lt;span class="math"&gt;\( e_\lambda\)&lt;/span&gt;), at a
given temperature and for a given wavelength of radiation. In fact a
perfect absorber, for which &lt;span class="math"&gt;\( a\lambda = 1\)&lt;/span&gt;, and
which we therefore refer to as a &lt;strong&gt;black body&lt;/strong&gt;, also radiates as
intensely as it's possible to do so under the given conditions; so it is
also sometimes called a &lt;strong&gt;full&lt;/strong&gt; or &lt;strong&gt;perfect radiator&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Hole in cavity as black body" src="http://upload.wikimedia.org/wikipedia/commons/e/ef/Hole_in_Cavity_as_Blackbody.png" /&gt;&lt;/p&gt;
&lt;p&gt;An enclosure with a small hole acts nearly as a block body, absorbing
radiation incident on it with a very small probability of escape (as
long as the walls absorb a non-zero fraction of the radiation incident
on them).&lt;/p&gt;
&lt;p&gt;A black body is a theoretical construct - a substance like
&lt;a href="https://paleotechnics.wordpress.com/2014/02/25/lampblack-what-it-is-and-what-its-good-for/"&gt;lamp black&lt;/a&gt;
is an excellent but not perfect absorber - but one way to approach a
black body very nearly, is by constructing a sealed enclosure with only
a small hole through the walls. Radiation incident on this hole has a
very tiny probability of escaping again (i.e. by being reflected off the
interior walls) as long as the hole is small in comparison with the
dimensions of the enclosure; therefore this system acts as a perfect
absorber or black body.&lt;/p&gt;
&lt;p&gt;Interestingly, such an enclosure doesn't have the characteristics of a
black body only in terms of its ability to &lt;em&gt;absorb&lt;/em&gt; the radiation
incident on it; radiation &lt;em&gt;emitted&lt;/em&gt; from the hole also has identical
characteristics to radiation emitted from a black body. We can see this
from the fact that, if we were to place a black body of the same
temperature into the interior of the cavity, then for it to remain at
this original temperature (which it must), the radiation emitted from
the cavity walls must be incident on the black body inside it with just
the same rate as the rate at which the black body is emitting radiation
itself. Hence, the radiation in the enclosure - or any enclosure with
constant wall temperature - is black-body radiation.&lt;/p&gt;
&lt;p&gt;Since the radiation in the interior of any constant-temperature
enclosure has the intensity of black-body radiation, then another way of
expressing Kirchhoff's law is that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The ratio of the emissive power of a body to the emissive power of a
black body at the same temperature is equal to the absorptive power of
the body.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(Recall that the absorptive power is just a number between 0 and 1).
This ratio is also called the &lt;strong&gt;emissivity&lt;/strong&gt;, or &lt;strong&gt;absorptivity&lt;/strong&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="black body"></category><category term="thermal radiation"></category><category term="thermodynamics"></category></entry><entry><title>Python wordcloud for WordPress</title><link href="http://0x7df.github.io/python-wordcloud-for-wordpress.html" rel="alternate"></link><updated>2015-05-10T12:06:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-05-10:python-wordcloud-for-wordpress.html</id><summary type="html">&lt;p&gt;There is a &lt;a href="http://www.python.org"&gt;Python&lt;/a&gt; routine available on
&lt;a href="https://github.com/"&gt;Github&lt;/a&gt; for creating a word cloud, created by
&lt;a href="http://peekaboo-vision.blogspot.co.uk/"&gt;Andreas Mueller&lt;/a&gt;:
&lt;a href="https://github.com/amueller/word_cloud"&gt;https://github.com/amueller/word_cloud&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://sebastianraschka.com/Articles/2014_twitter_wordcloud.html"&gt;A blog post
here&lt;/a&gt;,
and &lt;a href="https://github.com/rasbt/datacollect"&gt;the Github repo that it goes
with&lt;/a&gt; (both due to &lt;a href="http://sebastianraschka.com/"&gt;Sebastien
Raschka&lt;/a&gt;), make it easy to use the
&lt;a href="https://dev.twitter.com/rest/public"&gt;Twitter API&lt;/a&gt; to download your
&lt;a href="https://support.twitter.com/articles/164083-what-s-a-twitter-timeline#"&gt;Twitter
timeline&lt;/a&gt;
(as a &lt;a href="http://en.wikipedia.org/wiki/Comma-separated_values"&gt;CSV&lt;/a&gt; file),
and then use the word cloud script to produce a word cloud from it.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://0x7df.files.wordpress.com/2015/04/my_twitter_wordcloud_1.png"&gt;&lt;img alt="my_twitter_wordcloud_1" src="https://0x7df.files.wordpress.com/2015/04/my_twitter_wordcloud_1.png?w=660" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To add something to this, I did the same thing with my
&lt;a href="https://wordpress.com"&gt;WordPress&lt;/a&gt; blog posts. I didn't want to bother
fighting with the WordPress API, so I simply exported the blog contents
to an XML file, which WordPress allows you to do through the admin
interface (so you can archive your blog locally and/or transfer it into
a different blog). Hence, this really just ends up being about XML
parsing. Here is the source code:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
#!/usr/bin/python&lt;/p&gt;
&lt;p&gt;from HTMLParser import HTMLParser&lt;br /&gt;
import xml.etree.ElementTree as ET&lt;br /&gt;
import matplotlib.pyplot as plt&lt;br /&gt;
from wordcloud import WordCloud, STOPWORDS&lt;/p&gt;
&lt;p&gt;#
http://stackoverflow.com/questions/753052/strip-html-from-strings-in-python&lt;br /&gt;
class MLStripper(HTMLParser):&lt;br /&gt;
def &lt;strong&gt;init&lt;/strong&gt;(self):&lt;br /&gt;
self.reset()&lt;br /&gt;
self.fed = []&lt;br /&gt;
def handle_data(self, d):&lt;br /&gt;
self.fed.append(d)&lt;br /&gt;
def get_data(self):&lt;br /&gt;
return ''.join(self.fed)&lt;/p&gt;
&lt;p&gt;tree = ET.parse('0x7df.wordpress.2015-04-25.xml')&lt;/p&gt;
&lt;p&gt;root = tree.getroot()&lt;/p&gt;
&lt;p&gt;postwords = []&lt;/p&gt;
&lt;p&gt;for child in root.iter():&lt;br /&gt;
if child.tag == 'item':&lt;br /&gt;
if child.find('{http://wordpress.org/export/1.2/}status').text ==
'publish':&lt;br /&gt;
postbody =
child.find('{http://purl.org/rss/1.0/modules/content/}encoded').text&lt;br /&gt;
s = MLStripper()&lt;br /&gt;
s.feed(postbody)&lt;br /&gt;
postwords += s.get_data().split()&lt;/p&gt;
&lt;p&gt;keywords = ' '.join([wd for wd in postwords&lt;br /&gt;
if 'http' not in wd and&lt;br /&gt;
'bg=' not in wd and&lt;br /&gt;
not wd.startswith('$') and&lt;br /&gt;
not wd.startswith('[') and&lt;br /&gt;
not wd.startswith('&amp;amp;')&lt;br /&gt;
])&lt;/p&gt;
&lt;p&gt;wordcloud = WordCloud(&lt;br /&gt;
font_path='./SaucerBB.ttf',&lt;br /&gt;
stopwords=STOPWORDS,&lt;br /&gt;
background_color='black',&lt;br /&gt;
width=1800,&lt;br /&gt;
height=1800&lt;br /&gt;
).generate(keywords)&lt;/p&gt;
&lt;p&gt;plt.imshow(wordcloud)&lt;br /&gt;
plt.axis('off')&lt;br /&gt;
plt.savefig('./my_wordpress_wordcloud_2.png', dpi=300)&lt;br /&gt;
plt.show()&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;I used the standard library light-weight
&lt;code&gt;&amp;lt;a href="https://docs.python.org/2/library/xml.etree.elementtree.html" target="_blank"&amp;gt;xml.etree.ElementTree&amp;lt;/a&amp;gt;&lt;/code&gt;
parser. I get the root of the &lt;a href="http://en.wikipedia.org/wiki/XML"&gt;XML&lt;/a&gt;
document, and iterate over its children; this is recursive, so it
descends down the tree to all nodes. Whenever I encounter a node which
has the tag &lt;code&gt;item&lt;/code&gt; (which contains the post information), I search
amongst its immediate children using the &lt;code&gt;find()&lt;/code&gt; method, to find one
with tag &lt;code&gt;{http://wordpress.org/export/1.2/}status&lt;/code&gt;, which contains the
status of the post, i.e. whether it's published, draft, etc. If it's
published (the text that the XML tag contains &lt;code&gt;== publish&lt;/code&gt;), then I
search again using &lt;code&gt;find()&lt;/code&gt; for the tag
&lt;code&gt;{http://purl.org/rss/1.0/modules/content/}encoded&lt;/code&gt;, which contains the
blog post text. I put this in the &lt;code&gt;postbody&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;The next few lines use the &lt;code&gt;class&lt;/code&gt; defined earlier on in the script -
&lt;code&gt;MLStripper()&lt;/code&gt; - to strip out the &lt;a href="http://www.w3schools.com/html/"&gt;HTML&lt;/a&gt;
tags from the blog post. (This came from
&lt;a href="//stackoverflow.com/questions/753052/strip-html-from-strings-in-python"&gt;StackOverflow&lt;/a&gt;.)
The rest of the script is essentially the same as &lt;a href="http://sebastianraschka.com/Articles/2014_twitter_wordcloud.html"&gt;Raschka's code for
Twitter&lt;/a&gt;,
tweaked a little where necessary.&lt;br /&gt;
The result is:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://0x7df.files.wordpress.com/2015/04/my_wordpress_wordcloud_21.png"&gt;&lt;img alt="my_wordpress_wordcloud_2" src="https://0x7df.files.wordpress.com/2015/04/my_wordpress_wordcloud_21.png?w=660" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The font is called Saucer BB, from
&lt;a href="http://www.1001fonts.com/saucer-bb-font.html"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary><category term="api"></category><category term="html"></category><category term="python"></category><category term="twitter"></category><category term="wordcloud"></category><category term="wordpress"></category><category term="xml"></category></entry><entry><title>Hydrostatic balance in the atmosphere</title><link href="http://0x7df.github.io/hydrostatic-balance-in-the-atmosphere.html" rel="alternate"></link><updated>2015-05-02T22:10:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-05-02:hydrostatic-balance-in-the-atmosphere.html</id><summary type="html">&lt;p&gt;Atmospheric pressure at any altitude represents the total weight, per
unit area, of the air column above that altitude. The pressure,
therefore, decreases with altitude as there is less air above pressing
down. To find the rate of decrease of pressure with height, consider a
vertical column of air with unit cross-sectional area, having
pressure &lt;span class="math"&gt;\( p\)&lt;/span&gt; at height &lt;span class="math"&gt;\( z
$. At height $ z + dz\)&lt;/span&gt; the pressure
has decreased to some value &lt;span class="math"&gt;\( p-dp\)&lt;/span&gt;, and the
pressure difference &lt;span class="math"&gt;\( dp\)&lt;/span&gt; is equal to the weight
of the slice of the vertical air column having thickness &lt;span class="math"&gt;\( dz\)&lt;/span&gt;
(at height &lt;span class="math"&gt;\( z\)&lt;/span&gt;).
Assuming &lt;span class="math"&gt;\( dz\)&lt;/span&gt; is small enough that the air
density, &lt;span class="math"&gt;\( \rho\)&lt;/span&gt;, and the acceleration due to
gravity, &lt;span class="math"&gt;\( g\)&lt;/span&gt;, can both be considered constant
within the slice:&lt;/p&gt;
&lt;div class="math"&gt;$$ dp = -g \rho dz $$&lt;/div&gt;
&lt;p&gt;Here &lt;span class="math"&gt;\( g\)&lt;/span&gt; is the acceleration of gravity that
transforms the areal mass element &lt;span class="math"&gt;\( \rho dz\)&lt;/span&gt; into
an areal weight element &lt;span class="math"&gt;\( g\rho dz\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This equation is called the &lt;em&gt;hydrostatic equation&lt;/em&gt;. It is commonly
written as:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial p}{\partial z} = -g \rho $$&lt;/div&gt;
&lt;p&gt;This expresses that the upward vertical pressure-gradient force is
balanced by the downward gravitational force, a situation usually
referred to as &lt;em&gt;hydrostatic equilibrium&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;With increasing altitude, the density of air also decreases (e.g. from
an average of 1.2 kg/m^3^ at the surface to an average of 0.7 kg/m^3^ at
5 km); hence the rate of change of pressure with height decreases with
height. Air temperature also affects density (in a way described by the
equation of state), and therefore the rate of pressure decrease with
altitude.&lt;/p&gt;
&lt;p&gt;Substituting in the equation of state allows us to integrate the
hydrostatic equation to obtain an expression for &lt;span class="math"&gt;\( p(z)\)&lt;/span&gt;.
The equation of state for dry air is:&lt;/p&gt;
&lt;div class="math"&gt;$$ p = \rho R T $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( R = R^{*}/m\)&lt;/span&gt; is the individual gas
constant for dry air, and &lt;span class="math"&gt;\( R^{*}\)&lt;/span&gt; and &lt;span class="math"&gt;\( m
are the universal gas constant and the molecular weight
of dry air, respectively. (The equation of state for moist air can be
obtained by replacing $ T\)&lt;/span&gt; with &lt;span class="math"&gt;\( T_v\)&lt;/span&gt;,
which is the &lt;em&gt;virtual temperature&lt;/em&gt;. It can be shown
that moist air is lighter than dry air of the same temperature and
pressure, because the water vapour is lighter than the dry air it
replaces; so that in cases where only the density of air is important,
dry air of slightly higher temperature may be substituted for moist air.
Virtual temperature is the fictitious temperature to which dry air must
be raised to have the same density as the moist air in question, and of
course it depends on the moisture content as well as the pressure.)&lt;/p&gt;
&lt;p&gt;Making this substitution gives:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial p}{\partial z} = -\frac{g}{RT}p
$$&lt;/div&gt;
&lt;p&gt;and hence:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{dp}{p} = \frac{g}{RT}dz $$&lt;/div&gt;
&lt;p&gt;By integration:&lt;/p&gt;
&lt;div class="math"&gt;$$ p = p_0 \exp \left( -\frac{g}{R} \int_{z_0}^z
\frac{1}{T} dz' \right) $$&lt;/div&gt;
&lt;p&gt;(assuming &lt;span class="math"&gt;\( g\)&lt;/span&gt; is constant with height).&lt;/p&gt;
&lt;p&gt;In the special case where the temperature is constant with height, the
pressure profile is:&lt;/p&gt;
&lt;div class="math"&gt;$$ p = p_0 \exp \left( -\frac{g(z-z_0)}{RT} \right)
$$&lt;/div&gt;
&lt;p&gt;The temperature in the atmosphere varies by a factor of two, whereas the
pressure varies by six orders of magnitude.&lt;/p&gt;
&lt;h2&gt;Model atmospheres&lt;/h2&gt;
&lt;p&gt;The following is question 3.5 from &lt;a href="https://www.elsevier.com/books/a-short-course-in-cloud-physics/yau/978-0-7506-3215-7"&gt;&lt;em&gt;A Short Course in Cloud Physics&lt;/em&gt;,
by Rogers and
Yau&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Two model atmospheres often used in theoretical work are the
homogeneous atmosphere:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\( \rho(z) = \rho_0 $\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;and the exponential atmosphere:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\( \rho(z) = \rho_0 e^{-z/H} $\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;where&lt;/em&gt; &lt;span class="math"&gt;\( \rho_0\)&lt;/span&gt; &lt;em&gt;is the density at the
surface and H is called the scale height of the atmosphere. The top of
the homogeneous atmosphere is defined as the altitude where the
pressure falls to zero. Prove that the height of the top of the
homogeneous atmosphere equals the scale height of the exponential
atmosphere.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For this problem we need the equation of &lt;a href="en.wikipedia.org/wiki/Hydrostatic_equilibrium"&gt;hydrostatic
balance&lt;/a&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial p}{\partial z} = -\rho(z) g $$&lt;/div&gt;
&lt;p&gt;which describes the equilibrium achieved in a fluid under gravity, where
the upward&lt;a href="en.wikipedia.org/wiki/Pressure-gradient_force"&gt;pressure gradient
force&lt;/a&gt; balances the
opposing force due to gravity.&lt;/p&gt;
&lt;p&gt;First consider the &lt;a href="http://glossary.ametsoc.org/wiki/Homogeneous_atmosphere"&gt;homogeneous
atmosphere&lt;/a&gt;;
using this equation it is very simple to calculate the height at which
the pressure falls to zero because, since the density is constant, the
gradient of pressure with height is also constant:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{\partial p}{\partial z} = -\rho_0 g $$&lt;/div&gt;
&lt;p&gt;That is, the pressure falls off linearly:&lt;/p&gt;
&lt;div class="math"&gt;$$ p(z) = \left( -\rho_0 g \right) z + p_0 $$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\( p_0\)&lt;/span&gt; is the pressure at the surface
(&lt;span class="math"&gt;\( z = 0\)&lt;/span&gt;). From this equation we see that the
pressure falls to zero when:&lt;/p&gt;
&lt;div class="math"&gt;$$ z|_{p=0} = \frac{p_0}{\rho_0 g} $$&lt;/div&gt;
&lt;p&gt;Now consider the &lt;a href="http://en.wikipedia.org/wiki/Barometric_formula"&gt;exponential
atmosphere&lt;/a&gt;; we can
determine &lt;em&gt;H&lt;/em&gt; in the following way. First, we integrate the equation for
hydrostatic balance from some height &lt;span class="math"&gt;\( z = z'\)&lt;/span&gt; up
to &lt;span class="math"&gt;\( z = \infty\)&lt;/span&gt; to obtain the pressure at height
&lt;span class="math"&gt;\($ z'\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ \int_{z'}^{\infty} \frac{\partial p}{\partial z} dz =
-\rho_0 g \int_{z'}^{\infty} e^{-z/H} dz $$&lt;/div&gt;
&lt;p&gt;If we assume that the pressure tends to zero as height tends to
infinity, and we set &lt;span class="math"&gt;\( z' = 0\)&lt;/span&gt;, then:&lt;/p&gt;
&lt;div class="math"&gt;$$ p_0 = \rho_0 g H $$&lt;/div&gt;
&lt;p&gt;Consequently:&lt;/p&gt;
&lt;div class="math"&gt;$$ H = \frac{p_0}{\rho_0 g} $$&lt;/div&gt;
&lt;p&gt;Hence, as long as &lt;span class="math"&gt;\( p_0\)&lt;/span&gt; has the same value in
both the homogeneous and exponential atmospheres, the height of the top
of the homogeneous atmosphere is equal to the scale height of the
exponential atmosphere.&lt;/p&gt;
&lt;div&gt;

[![Pressure (mb) vs. height (m) for two model
atmospheres](https://plot.ly/~0x7df/11.png)](https://plot.ly/~0x7df/11/ "Pressure (mb) vs. height (m) for two model atmospheres")  
&lt;https://plot.ly/embed.js&gt;

&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="exponential atmosphere"></category><category term="fluid dynamics"></category><category term="homogeneous atmosphere"></category><category term="hydrostatic balance"></category><category term="hydrostatic equilibrium"></category><category term="meteorology"></category></entry><entry><title>Creating a new Ubuntu virtual machine in Oracle VirtualBox</title><link href="http://0x7df.github.io/creating-a-new-ubuntu-virtual-machine-in-oracle-virtualbox.html" rel="alternate"></link><updated>2015-04-26T12:29:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-04-26:creating-a-new-ubuntu-virtual-machine-in-oracle-virtualbox.html</id><summary type="html">&lt;p&gt;These instructions are for a Windows host machine. An article
&lt;a href="http://osxdaily.com/2012/03/27/install-run-ubuntu-linux-virtualbox/"&gt;here&lt;/a&gt;gives
instructions for Mac OS X, but are unlikely to be very different. This
assumed you've already
&lt;a href="https://www.virtualbox.org/wiki/Downloads"&gt;downloaded&lt;/a&gt; and
&lt;a href="https://www.virtualbox.org/manual/ch02.html"&gt;installed&lt;/a&gt;VirtualBox.&lt;/p&gt;
&lt;h2&gt;Create the VM&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open the Oracle VM VirtualBox Manager. This brings up the window
    shown in Figure 1.
    &lt;p&gt;
    [caption id="attachment_474" align="alignnone"
    width="276"]&lt;a href="https://0x7df.files.wordpress.com/2015/04/01_oracle_virtualbox_manager.png"&gt;&lt;img alt="Figure 1. Oracle VirtualBox VM Manager
    window." src="https://0x7df.files.wordpress.com/2015/04/01_oracle_virtualbox_manager.png?w=276" /&gt;&lt;/a&gt;
    Figure 1. Oracle VirtualBox VM Manager window.[/caption]&lt;/li&gt;
&lt;li&gt;Click "New" in the top-left corner. This brings up the "Create
    Virtual Machine" dialogue box, shown in Figure 2.&lt;/li&gt;
&lt;li&gt;Give the system a descriptive name, and select "Linux" from the
    "Type" drop-down menu, and then "Ubuntu (64 bit)" from the "Version"
    drop-down menu. (Obviously you can choose whatever you like at this
    point, I default to Ubuntu.) Click "Next".
    &lt;p&gt;
    [caption id="attachment_475" align="alignnone"
    width="300"]&lt;a href="https://0x7df.files.wordpress.com/2015/04/02_create_vm_dialogue.png"&gt;&lt;img alt="Figure 2. Create Virtual Machine dialogue
    box." src="https://0x7df.files.wordpress.com/2015/04/02_create_vm_dialogue.png?w=300" /&gt;&lt;/a&gt;
    Figure 2. Create Virtual Machine dialogue box.[/caption]&lt;/li&gt;
&lt;li&gt;The next  few dialogue boxes allow you to select how much memory you
    want, decide whether or not to create a virtual hard drive or not
    (or use an existing one), and assuming you do, define its properties
    (file format, whether or not to dynamically allocate storage, size
    (or maximum size), and location). Assuming you want to keep the
    defaults for all these, click "Next" or "Create" until you get to
    the end.&lt;/li&gt;
&lt;li&gt;You've finished the first phase and have been returned to the
    VirtualBox Manager window, and you should see the system you've just
    created in the list of available VMs on the left-hand side. If you
    click on it once, the details of the system will be shown in the
    right-hand pane. To launch it, either double-click, or click "Start"
    up at the top when the VM is selected.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Install the OS&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;[caption id="attachment_476" align="alignright"
    width="300"]&lt;a href="https://0x7df.files.wordpress.com/2015/04/03_select_start-up_disk_dialogue.png"&gt;&lt;img alt="Figure 3. Select start-up disk dialogue
    box." src="https://0x7df.files.wordpress.com/2015/04/03_select_start-up_disk_dialogue.png?w=300" /&gt;&lt;/a&gt;
    Figure 3. Select start-up disk dialogue box.[/caption]&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The next step is to install the operating system. A "Select start-up
disk" dialogue box comes up, with a drop-down menu. The default
selection is "Host drive 'D:'". Rather than use a DVD installation
disk however, I've previously downloaded an ISO disk image file. I
can select this directly from the drop-down menu (see Figure 3)
because I've used it before, so VirtualBox remembers its location.
If this isn't the case for you, you can click the folder icon to the
right of the drop-down menu, which opens up a file browser and
allows you to navigate to wherever you stored the downloaded ISO
file (look &lt;a href="http://www.ubuntu.com/download/desktop"&gt;here&lt;/a&gt; for a
download). Click "Start", and the VM will start to boot from the
ISO.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;From here on the instructions are as to install Ubuntu from disk.
    Click through the defaults and self-explanatory settings, until the
    installation begins proper. This takes a while, and when it's
    complete you'll be prompted to restart.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Install Guest Additions&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;When the restart has completed, you have working VM. However,
    there's something obviously wrong with the desktop. When you re-size
    the VM window, the desktop doesn't scale with it but remains a fixed
    size, which is way too small. This is because the resolution is
    fixed, and having the desktop size scale with the window size
    essentially means changing the VM screen resolution. To do this you
    need to install additional software on the VM, called the Guest
    Additions. The next stage is to install the Guest Additions.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;First, the Linux VM needs Dynamic Kernel Module Support (DKMS) to be
    installed. Open a terminal on the VM and run:&lt;/p&gt;
&lt;p&gt;[code lang="bash"]sudo apt-get install dkms[/code]&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
This allows it to build external module kernels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select, from the VM's "Devices" menu, "Insert Guest Additions CD
    image...". This will open File Manager showing the contents of the
    CD, and the path, which will be something like
    "/media/username/VBOXADDITIONS_4.3.26_98988/".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Return to the terminal, cd into the Guest Additions directory, then
    run:&lt;/p&gt;
&lt;p&gt;[code lang="bash"]sudo sh ./VBoxLinuxAdditions.run[/code]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Restart the VM. You're done.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Initial software stack&lt;/h2&gt;
&lt;p&gt;While I try to have a VM for each project I'm working on, I start each
one with a few bits and pieces that I expect to find useful on most
projects. To make this as quick as possible I have &lt;a href="https://github.com/0x7df/mkvm"&gt;a script on
GitHub&lt;/a&gt; that performs the installation
for me. To use this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install git:&lt;/p&gt;
&lt;p&gt;[code lang="bash"] sudo apt-get install git [/code]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Clone the repository:&lt;/p&gt;
&lt;p&gt;[code lang="bash"] git clone https://github.com/0x7df/mkvm.git
[/code]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the script:&lt;/p&gt;
&lt;p&gt;[code lang="bash"] cd mkvm ; ./mkvm.sh [/code]&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can see the software that gets installed from the listing below:&lt;/p&gt;
&lt;p&gt;[code lang="bash"]&lt;/p&gt;
&lt;p&gt;# mkvm - Make virtual machine&lt;br /&gt;
# This script configures an Ubuntu virtual machine how I like it&lt;/p&gt;
&lt;p&gt;sudo apt-get -y update               # Must be done before upgrade&lt;br /&gt;
sudo apt-get -y dist-upgrade         # Does upgrade with intelligent
dependency-handling&lt;/p&gt;
&lt;p&gt;sudo apt-get -y install dkms         # For installing VirtualBox Linux
Guest Additions (https://www.virtualbox.org/manual/ch04.html)&lt;/p&gt;
&lt;p&gt;sudo apt-get -y install git&lt;br /&gt;
sudo apt-get -y install nedit&lt;br /&gt;
sudo apt-get -y install python-numpy # Contains, amongst other things,
f2py&lt;br /&gt;
sudo apt-get -y install python-dev   # For Python.h; required by f2py&lt;br /&gt;
sudo apt-get -y install gfortran&lt;br /&gt;
sudo apt-get -y install python-pip&lt;br /&gt;
sudo apt-get -y install python-matplotlib&lt;br /&gt;
sudo apt-get -y install okular&lt;br /&gt;
sudo apt-get -y upgrade graphviz&lt;br /&gt;
sudo apt-get -y install texlive&lt;br /&gt;
sudo apt-get -y install doxygen&lt;/p&gt;
&lt;p&gt;sudo pip install robotframework&lt;br /&gt;
sudo pip install prospector[with_frosted]&lt;br /&gt;
sudo pip install prospector[with_pyroma]&lt;br /&gt;
sudo pip install prospector[with_vulture]&lt;/p&gt;
&lt;p&gt;sudo add-apt-repository ppa:staticfloat/juliareleases&lt;br /&gt;
sudo add-apt-repository ppa:staticfloat/julia-deps&lt;br /&gt;
sudo apt-get -y install julia&lt;/p&gt;
&lt;p&gt;# python-scipy&lt;br /&gt;
# matplotlib&lt;/p&gt;
&lt;p&gt;# If Java JDK is required, determine the path:&lt;br /&gt;
#   &amp;gt; update-alternatives --config java&lt;br /&gt;
# Set JAVA_HOME=/usr/bin/java (or wherever) in /etc/environment,
which is the preferred location for JAVA_HOME or any system variable.&lt;/p&gt;
&lt;p&gt;echo "&lt;br /&gt;
# Now install the Linux Guest Additions for VirtualBox. Go to the&lt;br /&gt;
# \"Devices\" menu of VirtualBox when the VM is running (make sure
it is not in&lt;br /&gt;
# stretch mode or the menu bar will not be visible); select \"Insert
Guest&lt;br /&gt;
# Additions CD image...\"; then run VBoxLinuxAdditions.run with
administrator&lt;br /&gt;
# privileges. Re-boot the VM; after this the VM desktop should resize
with the&lt;br /&gt;
# VirtualBox window, rather than being a fixed (small) size.&lt;br /&gt;
"&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;h2&gt;Shared clipboard&lt;/h2&gt;
&lt;p&gt;One extra useful thing to do is enable the shared clipboard, which
allows copy-and-paste from the host to the guest, vice versa, or both.
Make sure the VM is shut down, select it in the VirtualBox Manager
window, go to "Settings", "General", "Advanced" and select from the
"Shared Clipboard" drop-down. Detailed descriptions with screen shots
are
&lt;a href="http://www.howtogeek.com/187535/how-to-copy-and-paste-between-a-virtualbox-host-machine-and-a-guest-machine"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary><category term="linux"></category><category term="ubuntu"></category><category term="virtual machine"></category><category term="virtualbox"></category><category term="vm"></category></entry><entry><title>CUDA basics part 2</title><link href="http://0x7df.github.io/cuda-basics-part-2.html" rel="alternate"></link><updated>2015-04-21T20:58:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-04-21:cuda-basics-part-2.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Recently, I posted &lt;a href="https://0x7df.wordpress.com/2015/04/05/cuda-basics-part-1/" title="CUDA basics part 1"&gt;a basic introduction to CUDA C for programming
GPUs&lt;/a&gt;,
which showed how to do a vector addition. This illustrated some of the
CUDA basic syntax, but it wasn't a complex- enough example to bring to
light some of the trickier issues to do with designing algorithms
carefully to minimise data movement. Here we move on to the more
complicated algorithm for matrix multiplication, &lt;em&gt;C = AB&lt;/em&gt;, where we'll
see that elements of the matrices get used multiple times, so we'll want
to put them in the shared memory to minimise the number of times they
get retrieved from the much slower global (or device) memory. We'll also
see that, because data that a thread puts into shared memory is only
accessible by the other threads in the same thread block, we need to be
careful how we do this.&lt;/p&gt;
&lt;h2&gt;Naive matrix multiplication in CUDA&lt;/h2&gt;
&lt;p&gt;First, let's ignore those concerns and put together the simplest
implementation of matrix multiplication; then we'll analyse the memory
access, and see how we can improve on it.&lt;/p&gt;
&lt;p&gt;Before we begin, however, some-error checking. Below is a function-like
C macro that will be used to surround each CUDA statement we execute
with a check of the return code. The return code is set to the
pre-defined variable &lt;code&gt;cudaSuccess&lt;/code&gt; if the statement executed
successfully, or an error value otherwise. (Hence, we declare the
variable that will contain the CUDA statement return to be type
&lt;code&gt;cudaError_t&lt;/code&gt;.) Where an error value is returned, we pass this to the
CUDA function &lt;code&gt;cudaGetErrorString&lt;/code&gt;, which returns an error message that
we can print.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\#define cudaCheck(stmt)                                               
\\  
    do \\  
{                                                                \\  
        cudaError_t err = stmt;                                       
\\  
        if (err != cudaSuccess) \\  
{                          \\  
     printf("ERROR: failed to run %s\\n", stmt);                \\  
      printf("ERROR: CUDA error %s\\n", cudaGetErrorString(err)); \\  
      return -1;                                                 \\  
    }                                                              \\  
} while (0)&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Simple matrix multiplication kernel&lt;/h3&gt;
&lt;h3&gt;&lt;a href="https://0x7df.files.wordpress.com/2015/03/tiled_matrix_multiplication_1.png"&gt;&lt;img alt="tiled_matrix_multiplication_1" src="https://0x7df.files.wordpress.com/2015/03/tiled_matrix_multiplication_1.png?w=296" /&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now for the kernel function. The way we've chosen to divide this problem
up amongst threads is to have each thread calculate a single element in
the output vector, &lt;em&gt;C&lt;/em&gt;. Mathematically, for an &lt;em&gt;m&lt;/em&gt;-by-&lt;em&gt;n&lt;/em&gt; matrix &lt;em&gt;A&lt;/em&gt; and
an &lt;em&gt;n&lt;/em&gt;-by-&lt;em&gt;p&lt;/em&gt; matrix &lt;em&gt;B&lt;/em&gt;, this is:&lt;/p&gt;
&lt;div class="math"&gt;$$ C_{i,j} = \sum_{k=1}^n A_{i,k}B_{k,j} $$&lt;/div&gt;
&lt;p&gt;for each of the &lt;em&gt;m&lt;/em&gt;-by-&lt;em&gt;p&lt;/em&gt; elements in &lt;em&gt;C&lt;/em&gt;. This is illustrated in the
figure, where the input matrices &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; are shown in grey, and the
result, matrix &lt;em&gt;C&lt;/em&gt;, in blue; a single element of &lt;em&gt;C&lt;/em&gt; is highlighted in
red, and the corresponding row and column of &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; are also
highlighted.&lt;/p&gt;
&lt;p&gt;We implement this in CUDA C as follows:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;__global__ void matrixMultiply(float *A, float *B,  
float *C, int numACols,  
int numBRows, int numBCols,  
    int numCRows, int numCCols)  
{  
        
// Get the row and column indices of the single  
// element of the output matrix that this thread  
// is dealing with  
    int col = threadIdx.x + blockDim.x*blockIdx.x;  
    int row = threadIdx.y + blockDim.y*blockIdx.y;  
      
// Calculate the output matrix element  
    if ((row &amp;lt; numCRows) &amp;amp;&amp;amp; (col &amp;lt; numCCols))  
{  
        float Ctmp = 0;  
        for (int k = 0; k &amp;lt; numACols; ++k)  
{  
            Ctmp += A[row*numACols+k]*B[k*numBCols+col];  
        }  
        C[row*numCCols + col] = Ctmp;  
    }  
}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is reasonably simple. Each thread figures out which output matrix
element it is responsible for, simply by checking the thread indices. It
proceeds only if the element indices are within the correct bounds of
the output matrix, which may not be the case if there are more threads
than elements (because we have to have a whole number of thread blocks).
Where they are, it retrieves the correct row of &lt;em&gt;A&lt;/em&gt; and column of &lt;em&gt;B&lt;/em&gt;,
and calculates the corresponding single element of &lt;em&gt;C&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Naive matrix multiplication host code&lt;/h3&gt;
&lt;p&gt;For completeness, here is the host code. The new things here that we
didn't see in the vector multiplication example are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The use of the C macro &lt;code&gt;cudaCheck&lt;/code&gt; (defined above) for error
    checking&lt;/li&gt;
&lt;li&gt;The fact that the grid and the thread blocks are two-dimensional&lt;/li&gt;
&lt;li&gt;The call to &lt;code&gt;cudaDeviceSynchronize()&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;`&lt;/p&gt;
&lt;p&gt;int main(int argc, char **argv) {&lt;/p&gt;
&lt;p&gt;float &lt;em&gt;hostA, &lt;/em&gt;hostB, &lt;em&gt;hostC;&lt;br /&gt;
  float &lt;/em&gt;deviceA, &lt;em&gt;deviceB, &lt;/em&gt;deviceC;&lt;br /&gt;
  int numARows, numACols; // Rows, columns in the matrix A&lt;br /&gt;
  int numBRows, numBCols; // Rows, columns in the matrix B&lt;br /&gt;
  int numCRows, numCCols; // Rows, columns in the matrix C&lt;br /&gt;
    int sizeA, sizeB, sizeC; // Size in memory of each of A, B and C&lt;br /&gt;
    int gridXSize, gridYSize; // Number of thread blocks in x, y
dimensions of grid&lt;br /&gt;
    int blockSize; // Number of threads in block&lt;/p&gt;
&lt;p&gt;// Allocate and populate the A and B matrices&lt;br /&gt;
// hostA and hostB, and get numARows, numACols,&lt;br /&gt;
// numBRows, numBCols&lt;/p&gt;
&lt;p&gt;// Set numCRows and numCCols&lt;br /&gt;
    numCRows = numARows;&lt;br /&gt;
    numCCols = numBCols;&lt;br /&gt;
&lt;br /&gt;
  // Allocate the C matrix&lt;br /&gt;
    hostC = (float&lt;em&gt;)malloc(numCRows&lt;/em&gt;numCCols&lt;em&gt;sizeof(float));&lt;br /&gt;
&lt;br /&gt;
// Allocate GPU memory&lt;br /&gt;
sizeA = numARows&lt;/em&gt;numACols&lt;em&gt;sizeof(float);&lt;br /&gt;
sizeB = numBRows&lt;/em&gt;numBCols&lt;em&gt;sizeof(float);&lt;br /&gt;
sizeC = numCRows&lt;/em&gt;numCCols&lt;em&gt;sizeof(float);&lt;br /&gt;
cudaCheck(cudaMalloc((void &lt;strong&gt;) &amp;amp;deviceA, sizeA));&lt;br /&gt;
cudaCheck(cudaMalloc((void &lt;/strong&gt;) &amp;amp;deviceB, sizeB));&lt;br /&gt;
   cudaCheck(cudaMalloc((void &lt;/em&gt;*) &amp;amp;deviceC, sizeC));&lt;/p&gt;
&lt;p&gt;// Copy data to the GPU&lt;br /&gt;
   cudaCheck(cudaMemcpy(deviceA, hostA, sizeA,
cudaMemcpyHostToDevice));&lt;br /&gt;
   cudaCheck(cudaMemcpy(deviceB, hostB, sizeB,
cudaMemcpyHostToDevice));&lt;/p&gt;
&lt;p&gt;// Initialize the grid and block dimensions&lt;br /&gt;
   blockSize = 16;&lt;br /&gt;
   gridXSize = (numCCols-1)/blockSize + 1;&lt;br /&gt;
   gridYSize = (numCRows-1)/blockSize + 1;&lt;br /&gt;
   dim3 dimGrid(gridXSize, gridYSize, 1);&lt;br /&gt;
   dim3 dimBlock(blockSize, blockSize, 1);&lt;br /&gt;
&lt;br /&gt;
   // Launch the GPU Kernel&lt;br /&gt;
   matrixMultiply&amp;lt;&amp;lt;&lt;dimGrid,dimBlock&gt;&amp;gt;&amp;gt;(deviceA, deviceB,&lt;br /&gt;
deviceC, numACols,&lt;br /&gt;
numBRows, numBCols,&lt;br /&gt;
                               numCRows, numCCols);&lt;br /&gt;
  cudaDeviceSynchronize();&lt;/p&gt;
&lt;p&gt;// Copy the GPU memory back to the CPU&lt;br /&gt;
   cudaCheck(cudaMemcpy(hostC, deviceC, sizeC,
cudaMemcpyDeviceToHost));&lt;/p&gt;
&lt;p&gt;// Free the GPU memory&lt;br /&gt;
   cudaCheck(cudaFree(deviceA));&lt;br /&gt;
   cudaCheck(cudaFree(deviceB));&lt;br /&gt;
   cudaCheck(cudaFree(deviceC));&lt;br /&gt;
&lt;br /&gt;
  // Do something with the solution, free the host memory, return&lt;/p&gt;
&lt;p&gt;}&lt;br /&gt;
`&lt;/p&gt;
&lt;p&gt;The call to &lt;code&gt;cudaDeviceSynchronize()&lt;/code&gt; ensures that all threads have
finished before the host code proceeds any further.&lt;/p&gt;
&lt;h3&gt;Performance analysis of the naive implementation&lt;/h3&gt;
&lt;p&gt;Clearly, each of the &lt;em&gt;mp&lt;/em&gt; elements of &lt;em&gt;C&lt;/em&gt; requires a full row of &lt;em&gt;A&lt;/em&gt; and
a full column of &lt;em&gt;B&lt;/em&gt; - both of length &lt;em&gt;n&lt;/em&gt; - to be read from memory, and
one value to be written back. Hence there are &lt;em&gt;(2n + 1)mp&lt;/em&gt; memory
accesses. Re-examining the kernel, we see that there are two floating
point operations per iteration of the inner loop (one multiply and one
add), and &lt;em&gt;n&lt;/em&gt; iterations of that loop, which is completed for each of
the &lt;em&gt;mp&lt;/em&gt; elements in the product matrix. Hence, there are 2&lt;em&gt;nmp&lt;/em&gt; FLOP,
and the CGMA is 2&lt;em&gt;n&lt;/em&gt;/(2&lt;em&gt;n&lt;/em&gt; + 1); which is effectively 1, except when the
matrices are very small. With a memory bandwidth of 150 GB/s, the
algorithm is limited to just under 150/8 = 20 GFLOP/s (assuming double
precision), which is still less than 2% of the available compute of our
nominal 1 TFLOP GPU.&lt;/p&gt;
&lt;h2&gt;Improving on the naive implementation&lt;/h2&gt;
&lt;p&gt;However, it turns out that we can improve on this. So far, all the data
storage has been in global memory, because that's the only permissible
location for CUDA memory allocations in the host code, and that's where
the data stays unless we explicitly move it, once inside the kernel
function (we'll see how later). It's also clear that in this algorithm
data gets re-used frequently. Every row of matrix &lt;em&gt;A&lt;/em&gt; is used &lt;em&gt;p&lt;/em&gt; times
and every column of matrix &lt;em&gt;B&lt;/em&gt; is used &lt;em&gt;m&lt;/em&gt; times. If we contrive an
algorithm that gets the necessary data into shared memory before it is
needed, and keeps it there while it is being re-used, then we can
clearly reduce the global memory accesses.&lt;/p&gt;
&lt;p&gt;However, it's not as though we can read &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; into shared memory
and have them accessible to all the threads working on the computation;
shared memory isn't globally accessible, despite the name, but is
instead local to a single streaming multiprocessor, and only 'shared'
amongst the threads in whichever thread block is currently assigned to
the SM. Hence our goal is to ensure that the threads in a given thread
block have the subset of input data they need available in their SM's
shared memory, under the general assumption that because of the small
size of the shared memory, not all of the needed data will fit in at
once.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://0x7df.files.wordpress.com/2015/03/tiled_matrix_multiplication_2.png"&gt;&lt;img alt="tiled_matrix_multiplication_2" src="https://0x7df.files.wordpress.com/2015/03/tiled_matrix_multiplication_2.png?w=285" /&gt;&lt;/a&gt;Consider
a thread block covering an area of the product matrix &lt;em&gt;C&lt;/em&gt;, which is &lt;em&gt;a&lt;/em&gt;
rows high by &lt;em&gt;a&lt;/em&gt; columns wide, with the top-left element being &lt;em&gt;i&lt;/em&gt;,&lt;em&gt;j&lt;/em&gt;
and the bottom-right therefore being &lt;em&gt;i+a,j+a&lt;/em&gt;. This is shown in the
figure. To compute these values, the rows &lt;em&gt;i, i+1, ..., i+a&lt;/em&gt; of matrix
&lt;em&gt;A&lt;/em&gt; and columns &lt;em&gt;j, j+1, ..., j+a&lt;/em&gt; of matrix &lt;em&gt;B&lt;/em&gt; are required,
comprising horizontal and vertical strips, respectively, of dimension &lt;em&gt;a
× n&lt;/em&gt; elements. We assume in general these strips comprise too much data
to move all together to shared memory. Instead, we move a block of
elements from the strip of &lt;em&gt;A&lt;/em&gt;, and a block of elements from the strip
of &lt;em&gt;B&lt;/em&gt; - i.e. two blocks of size &lt;em&gt;a&lt;/em&gt; × &lt;em&gt;a&lt;/em&gt;, one from each matrix; we
will refer to these as &lt;em&gt;tiles&lt;/em&gt;. Performing matrix multiplication on
these two tiles creates a tile of partial sums in the &lt;em&gt;C&lt;/em&gt; elements. When
the next pair of tiles from &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; are retrieved, the partial sums
are further incremented, until eventually the full strips have been
processed and the final answers are available.&lt;/p&gt;
&lt;p&gt;There is still some duplication of global memory accesses, because any
given strip of &lt;em&gt;A&lt;/em&gt; will be required by all the thread blocks of the &lt;em&gt;C&lt;/em&gt;
matrix that share the same row indices; and any given strip of &lt;em&gt;B&lt;/em&gt; will
be required by all the thread blocks of the &lt;em&gt;C&lt;/em&gt; matrix that share the
same column indices. However, we can see that there is at least &lt;em&gt;some&lt;/em&gt;
re-use of data in shared memory; each sub-row of the tile from &lt;em&gt;A&lt;/em&gt; gets
re-used &lt;em&gt;a&lt;/em&gt; times (for the &lt;em&gt;a&lt;/em&gt; elements of the output matrix that have
the same row index), as does each sub-column of the tile from &lt;em&gt;B&lt;/em&gt;. This
data re-use reduces the retrievals from global memory by a factor of
&lt;em&gt;a&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Here is the kernel for tiled matrix multiplication.&lt;/p&gt;
&lt;p&gt;`&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;global&lt;/strong&gt; void matrixMultiply(float &lt;em&gt;A, float &lt;/em&gt;B, float *C,&lt;br /&gt;
int numARows, int numACols,&lt;br /&gt;
int numBRows, int numBCols,&lt;br /&gt;
int numCRows, int numCCols) {&lt;/p&gt;
&lt;p&gt;// Define device shared-memory storage for&lt;br /&gt;
// tiles of the matrices&lt;br /&gt;
// Scope: each tile is accessible by a single&lt;br /&gt;
// block of threads&lt;br /&gt;
&lt;strong&gt;shared&lt;/strong&gt; float tileA[TILE_WIDTH][TILE_WIDTH];&lt;br /&gt;
&lt;strong&gt;shared&lt;/strong&gt; float tileB[TILE_WIDTH][TILE_WIDTH];&lt;/p&gt;
&lt;p&gt;// Define abbreviated variables for the&lt;br /&gt;
// block and thread IDs&lt;br /&gt;
// Scope: stored in registers and therefore&lt;br /&gt;
// accessible by single threads&lt;br /&gt;
int bx =  blockIdx.x;&lt;br /&gt;
int by =  blockIdx.y;&lt;br /&gt;
int tx =  threadIdx.x;&lt;br /&gt;
int ty =  threadIdx.y;&lt;/p&gt;
&lt;p&gt;// Each thread is responsible for a single&lt;br /&gt;
// element of the product matrix C.&lt;br /&gt;
// Determine which element, from the block&lt;br /&gt;
// and thread indices&lt;br /&gt;
int row = by&lt;em&gt;TILE_WIDTH + ty;&lt;br /&gt;
int col = bx&lt;/em&gt;TILE_WIDTH + tx;&lt;/p&gt;
&lt;p&gt;// Initialise a temp variable for the solution&lt;br /&gt;
// for this matrix element&lt;br /&gt;
// Scope: in register, private to individual thread&lt;br /&gt;
float Ctemp = 0;&lt;/p&gt;
&lt;p&gt;// Loop over the tiles in the A and B matrices&lt;br /&gt;
// that will contribute to the calculation of&lt;br /&gt;
// this element in the product matrix. We are&lt;br /&gt;
// looping over columns of A for a given row&lt;br /&gt;
// (equal to the row index of the C element),&lt;br /&gt;
// and over rows of the B matrix for a given&lt;br /&gt;
// column index (equal to the column index of&lt;br /&gt;
// the C element)&lt;br /&gt;
int numTiles = (numACols-1)/TILE_WIDTH + 1;&lt;/p&gt;
&lt;p&gt;for (int tl = 0; tl &amp;lt; numTiles; ++tl) {&lt;/p&gt;
&lt;p&gt;// Load the tiles into shared memory, so all&lt;br /&gt;
// threads in the block have access to the&lt;br /&gt;
// whole tiles. Each thread needs to load only&lt;br /&gt;
// a single value of each of the A and B tiles.&lt;br /&gt;
if ((row &amp;lt; numARows) &amp;amp;&amp;amp; (tl&lt;em&gt;TILE_WIDTH + tx &amp;lt; numACols)) {&lt;br /&gt;
tileA[ty][tx] = A[row&lt;/em&gt;numACols + tl&lt;em&gt;TILE_WIDTH + tx];&lt;br /&gt;
} else {&lt;br /&gt;
tileA[ty][tx] = 0.;&lt;br /&gt;
}&lt;br /&gt;
if ((tl&lt;/em&gt;TILE_WIDTH + ty &amp;lt; numBRows) &amp;amp;&amp;amp; (col &amp;lt; numBCols)) {&lt;br /&gt;
tileB[ty][tx] = B[(tl&lt;em&gt;TILE_WIDTH + ty)&lt;/em&gt;numBCols + col];&lt;br /&gt;
} else {&lt;br /&gt;
tileB[ty][tx] = 0.;&lt;br /&gt;
}&lt;br /&gt;
__syncthreads();&lt;/p&gt;
&lt;p&gt;// Loop over the elements within the A and B&lt;br /&gt;
// tiles that contribute to this element of C&lt;br /&gt;
for (int k = 0; k &amp;lt; TILE_WIDTH; ++k) {&lt;br /&gt;
Ctemp += tileA[ty][k] * tileB[k][tx];&lt;br /&gt;
}&lt;br /&gt;
__syncthreads();&lt;br /&gt;
}&lt;/p&gt;
&lt;p&gt;// Write the final value into the output array&lt;br /&gt;
if ((row &amp;lt; numARows) &amp;amp;&amp;amp; (col &amp;lt; numBCols)) {&lt;br /&gt;
C[row*numBCols + col] = Ctemp;&lt;br /&gt;
}&lt;br /&gt;
}&lt;br /&gt;
`&lt;/p&gt;
&lt;p&gt;In each thread block, the &lt;em&gt;a&lt;/em&gt;^2^ threads load two float values each and
perform 2&lt;em&gt;a&lt;/em&gt; floating-point operations to compute the dot product of the
row and column sub-sections (both of length &lt;em&gt;a&lt;/em&gt;) required for the single
output matrix element it holds. Hence there are 2&lt;em&gt;a&lt;/em&gt; computations for
two memory loads, which gives a CGMA ratio of &lt;em&gt;a&lt;/em&gt;. For the naive
implementation it was 1, so we have improved the CGMA by a factor of &lt;em&gt;a&lt;/em&gt;
by tiling the data.&lt;/p&gt;
&lt;p&gt;There are a few other things to note in the kernel.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The use of the &lt;code&gt;__shared__&lt;/code&gt; identifier in the allocations statements
    for &lt;code&gt;tileA&lt;/code&gt; and &lt;code&gt;tileB&lt;/code&gt; (which are the temporary storage arrays for
    the tiles of &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt;). This keyword is how we cause the storage
    to be allocated in shared memory (and therefore it can be used only
    in &lt;code&gt;__device__&lt;/code&gt; functions, not &lt;code&gt;__host__&lt;/code&gt; functions).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TILE_WIDTH&lt;/code&gt; is a C macro that we assume has been defined elsewhere.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Calculation of the &lt;em&gt;C&lt;/em&gt; element indices &lt;code&gt;row&lt;/code&gt; and &lt;code&gt;col&lt;/code&gt; is done using
    &lt;code&gt;TILE_WIDTH&lt;/code&gt;, where previously &lt;code&gt;blockDim.x&lt;/code&gt; and &lt;code&gt;blockDim.y&lt;/code&gt;
    appeared. This works because we have &lt;em&gt;defined&lt;/em&gt; the tile to be the
    same size as the thread block. In theory it could be different, but
    doing so gives us the very convenient consequence that each thread
    needs only to load a single element from each of &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; into
    shared memory to construct the tiles. This means the host code that
    calls the kernel needs to use &lt;code&gt;TILE_WIDTH&lt;/code&gt; to define the block size:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;gridXSize = (numCCols-1)/TILE_WIDTH + 1;  
gridYSize = (numCRows-1)/TILE_WIDTH + 1;  
dim3 DimGrid(gridXSize, gridYSize, 1);  // gridSize blocks in the
grid  
dim3 DimBlock(TILE_WIDTH, TILE_WIDTH, 1); // blockSize threads in
each block  
matrixMultiply&amp;lt;&amp;lt;&amp;lt;DimGrid,DimBlock&amp;gt;&amp;gt;&amp;gt;(deviceA, deviceB,
deviceC, ...&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We have put some logic around the statements that transfer data to
    the shared-memory tile storage. Since we can't guarantee that there
    will be a whole number of thread blocks in the matrix, this prevents
    threads whose &lt;code&gt;row&lt;/code&gt;, &lt;code&gt;col&lt;/code&gt; indices are outside the bounds of either
    &lt;em&gt;A&lt;/em&gt; or &lt;em&gt;B&lt;/em&gt; from attempting to retrieve data that isn't there.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;The appearance of &lt;code&gt;__syncthreads()&lt;/code&gt;. This is a barrier
    synchronization across all threads that ensures all threads complete
    any work up to this point before any proceed further. Without this,
    some threads could move on to begin computing matrix elements before
    other threads have loaded the correct data into shared memory, and
    out-of-date data could be used.&lt;/li&gt;
&lt;/ol&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="C"></category><category term="CUDA"></category><category term="GPU"></category><category term="HPC"></category><category term="massively parallel"></category><category term="parallel computing"></category><category term="parallel programming"></category></entry><entry><title>Python code analysis using Prospector</title><link href="http://0x7df.github.io/python-code-analysis-using-prospector.html" rel="alternate"></link><updated>2015-04-11T23:32:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-04-11:python-code-analysis-using-prospector.html</id><summary type="html">&lt;p&gt;A &lt;a href="https://blog.landscape.io/prospector-python-static-analysis-for-humans.html"&gt;recent blog
post&lt;/a&gt;
I came across introduced me to
&lt;a href="https://github.com/landscapeio/prospector"&gt;Prospector&lt;/a&gt;, a
&lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt;&lt;a href="http://en.wikipedia.org/wiki/Static_program_analysis"&gt;static
analysis&lt;/a&gt; tool
developed by &lt;a href="https://landscape.io/"&gt;Landscape&lt;/a&gt;. From the
&lt;a href="https://prospector.readthedocs.org"&gt;documentation&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prospector is a tool to analyse Python code and output information
about errors, potential problems, convention violations and
complexity.&lt;/p&gt;
&lt;p&gt;It brings together the functionality of other Python analysis tools
such as &lt;a href="http://docs.pylint.org/"&gt;Pylint&lt;/a&gt;,
&lt;a href="http://pep8.readthedocs.org/en/latest/"&gt;pep8&lt;/a&gt;, and &lt;a href="https://pypi.python.org/pypi/mccabe"&gt;McCabe
complexity&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The primary aim of Prospector is to be useful ‘out of the box’. A
common complaint of other Python analysis tools is that it takes a
long time to filter through which errors are relevant or interesting
to your own coding style. Prospector provides some default profiles,
which hopefully will provide a good starting point and will be useful
straight away, and adapts the output depending on the libraries your
project uses.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So rather than configuring and individually using the various different
static analysis packages mentioned, and wading through the potentially
overwhelming output, Prospector provides a single interface to all of
them, and is set up to give a more manageable level of information
straight-away, without much user intervention. I won't repeat the sales
pitch and the basic how-to that &lt;a href="https://blog.landscape.io/prospector-python-static-analysis-for-humans.html"&gt;that
post&lt;/a&gt;
contains, but will go on from there to give a bit more information.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Cyclomatic complexity&lt;/h2&gt;
&lt;p&gt;The first thing you might come across that might not be self-evident is
the complexity rating given by the
&lt;a href="https://github.com/flintwork/mccabe"&gt;&lt;code&gt;mccabe&lt;/code&gt;&lt;/a&gt; package. E.g.:&lt;/p&gt;
&lt;p&gt;[code lang="bash"]&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;prospector --strictness low&lt;br /&gt;
Messages&lt;br /&gt;
========&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;main.py&lt;br /&gt;
  Line: 13&lt;br /&gt;
    mccabe: MC0001 / run is too complex (17)&lt;/p&gt;
&lt;h1&gt;Check Information&lt;/h1&gt;
&lt;p&gt;Started: 2015-04-11 15:59:47.759944&lt;br /&gt;
       Finished: 2015-04-11 15:59:51.598176&lt;br /&gt;
     Time Taken: 3.84 seconds&lt;br /&gt;
      Formatter: grouped&lt;br /&gt;
       Profiles: default, strictness_low, strictness_medium,
strictness_high, strictness_veryhigh, no_doc_warnings,
no_test_warnings, no_member_warnings&lt;br /&gt;
     Strictness: low&lt;br /&gt;
 Libraries Used:&lt;br /&gt;
      Tools Run: dodgy, mccabe, pep8, profile-validator, pyflakes,
pylint&lt;br /&gt;
 Messages Found: 1&lt;/p&gt;
&lt;p&gt;[/code]&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;cyclomatic complexity&lt;/em&gt; metric was defined by &lt;a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1702388&amp;amp;filter%3DAND%28p_IS_Number%3A35895%29"&gt;Thomas J. McCabe in a
1976
paper&lt;/a&gt;
(the PDF of which can be found
&lt;a href="http://www.literateprogramming.com/mccabe.pdf"&gt;here&lt;/a&gt;, or reproduced in
the &lt;a href="https://books.google.co.uk/books?id=vtNWAAAAMAAJ&amp;amp;dq=%22structured%20testing%22&amp;amp;pg=PR1#v=onepage&amp;amp;q=%22structured%20testing%22&amp;amp;f=false"&gt;book "Structured Testing" which is available on Google
Books&lt;/a&gt;).
It is essentially a measure of the number of logical paths through a
piece of source code: the higher the number, the higher the complexity,
and therefore the more error-prone the code is likely to be. McCabe
suggested "10... seems like a reasonable, but not magical, upper limit".
The example given above was found to have a complexity of 17, so needs
simplifying (e.g by breaking up into more than one routine).&lt;/p&gt;
&lt;p&gt;For more detail, the McCabe paper gives a very good description which is
hard to improve on:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Given a program we will associate with it a directed graph that has
unique entry and exit nodes [vertices]. Each node in the graph
corresponds to a block of code in the program where the flow is
sequential and the arcs [edges] correspond to branches taken in the
program. This graph is classically known as the program control
graph... and it is assumed that each node can be reached by the entry
node and each node can reach the exit node. For example the following
is a program control graph with entry node &lt;span class="math"&gt;\( a\)&lt;/span&gt; and
exit node &lt;span class="math"&gt;\( f\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Reproduced from McCabe (1976)" src="https://books.google.co.uk/books?id=vtNWAAAAMAAJ&amp;amp;pg=PA3&amp;amp;img=1&amp;amp;zoom=3&amp;amp;hl=en&amp;amp;sig=ACfU3U2LbN62dSqC_xZCFeoYcb-COKZ7IA&amp;amp;ci=642%2C968%2C254%2C220&amp;amp;edge=0" /&gt;&lt;/p&gt;
&lt;p&gt;The following mathematical preliminaries will be needed...&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Definition 1&lt;/em&gt;: The cyclomatic number &lt;span class="math"&gt;\( V(G)\)&lt;/span&gt; of a
graph &lt;span class="math"&gt;\( G\)&lt;/span&gt; with &lt;span class="math"&gt;\( n\)&lt;/span&gt; vertices,
&lt;span class="math"&gt;\( e\)&lt;/span&gt; edges and &lt;span class="math"&gt;\( p\)&lt;/span&gt; connected
components is&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ V(G) = e - n + p $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Theorem 1&lt;/em&gt;: In a strongly connected graph &lt;span class="math"&gt;\( G\)&lt;/span&gt; the
cyclomatic number is equal to the maximum number of linearly
independent circuits.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note here that at this stage we are concerned with &lt;em&gt;circuits&lt;/em&gt; - i.e.
closed loops that start at a given node and return back to that same
node - rather than &lt;em&gt;paths&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Theorem 1 is applied to &lt;span class="math"&gt;\( G\)&lt;/span&gt; in the following way.
Imagine that the exit node &lt;span class="math"&gt;\( f\)&lt;/span&gt; branches back to the
entry node &lt;span class="math"&gt;\( a\)&lt;/span&gt;. The control graph &lt;span class="math"&gt;\( G\)&lt;/span&gt;
is now strongly connected (there is a path joining any
pair of arbitrary distinct vertices) so Theorem 1 applies. Therefore
the maximum number of linearly independent circuits in &lt;span class="math"&gt;\( G\)&lt;/span&gt;
is &lt;span class="math"&gt;\( 9 - 6 + 2\)&lt;/span&gt;. For example one could
choose the following 5 independent circuits in &lt;span class="math"&gt;\( G\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ B1: (abefa), (beb), (abea), (acfa), (adcfa) $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;It follows that &lt;span class="math"&gt;\( B1\)&lt;/span&gt; forms a basis for the set of
all circuits in &lt;span class="math"&gt;\( G\)&lt;/span&gt; and any path through &lt;span class="math"&gt;\( G\)&lt;/span&gt;
can be expressed as a linear combination of circuits from
&lt;span class="math"&gt;\( B1\)&lt;/span&gt;. For instance the path &lt;span class="math"&gt;\( (abeabebebef)\)&lt;/span&gt;
is expressible as &lt;span class="math"&gt;\( (abea) + 2(beb) + (abefa)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To see how this works it's necessary to number the edges on &lt;span class="math"&gt;\( G\)&lt;/span&gt;
as in:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Reproduced from McCabe, 1976." src="https://books.google.co.uk/books?id=vtNWAAAAMAAJ&amp;amp;pg=PA4&amp;amp;img=1&amp;amp;zoom=3&amp;amp;hl=en&amp;amp;sig=ACfU3U2LMlgVCsIny0X682Rs8LVIkP0WqA&amp;amp;ci=165%2C387%2C235%2C207&amp;amp;edge=0" /&gt;&lt;/p&gt;
&lt;p&gt;Now for each member of the basis &lt;span class="math"&gt;\( B1\)&lt;/span&gt; associate a
vector as follows:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Reproduced from McCabe, 1976." src="https://books.google.co.uk/books?id=vtNWAAAAMAAJ&amp;amp;pg=PA4&amp;amp;img=1&amp;amp;zoom=3&amp;amp;hl=en&amp;amp;sig=ACfU3U2LMlgVCsIny0X682Rs8LVIkP0WqA&amp;amp;ci=66%2C638%2C279%2C134&amp;amp;edge=0" /&gt;&lt;/p&gt;
&lt;p&gt;The path &lt;span class="math"&gt;\( (abea(be)^3fa)\)&lt;/span&gt; corresponds to the
vector &lt;span class="math"&gt;\( 2004200111\)&lt;/span&gt; and the vector addition of
&lt;span class="math"&gt;\( (abefa)\)&lt;/span&gt;, &lt;span class="math"&gt;\( 2(beb)\)&lt;/span&gt; and
&lt;span class="math"&gt;\( (abea)\)&lt;/span&gt; yields the desired result.&lt;/p&gt;
&lt;p&gt;In using Theorem 1 one can choose a basis set of circuits that
correspond to paths through the program. The set &lt;span class="math"&gt;\( B2\)&lt;/span&gt;
is a basis of program paths.&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ B2: (abef), (abeabef), (abebef), (acf), (adcf) $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Linear combination of paths in &lt;span class="math"&gt;\( B2\)&lt;/span&gt; will also
generate any path. For example:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ (abea(be)^3f) = 2(abebef) - (abef) $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ (a(be)^2(abef) = (a(be)^2f) + (abeabef) - (abef) $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;The overall strategy will be to measure the complexity of a program by
computing the number of linearly independent paths &lt;span class="math"&gt;\( V(G)\)&lt;/span&gt;,
control the size of programs by setting an upper limit
to &lt;span class="math"&gt;\( V(G)\)&lt;/span&gt; (instead of using just physical size),
and use the cyclomatic complexity as the basis for a testing
methodology.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;[caption id="attachment_450" align="alignleft" width="178"]&lt;a href="https://0x7df.files.wordpress.com/2015/04/example_mccabe_graph.png"&gt;&lt;img alt="Example
mccabe graph
output" src="https://0x7df.files.wordpress.com/2015/04/example_mccabe_graph.png?w=178" /&gt;&lt;/a&gt;
Example mccabe graph output[/caption]&lt;/p&gt;
&lt;p&gt;If you want to run &lt;code&gt;mccabe&lt;/code&gt; separately from &lt;code&gt;prospector&lt;/code&gt; you can do,
using:&lt;/p&gt;
&lt;p&gt;[code lang="bash"]  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python -m mccabe mysourcefile.py&lt;br /&gt;
('If 209', 2)&lt;br /&gt;
("13:1: 'run'", 8)&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can add the &lt;code&gt;-d&lt;/code&gt; option (documented
&lt;a href="http://nedbatchelder.com/blog/200803/python_code_complexity_microtool.html"&gt;here&lt;/a&gt;)
to produce output that can be passed to the
&lt;a href="http://www.graphviz.org/"&gt;Graphviz&lt;/a&gt; program
&lt;a href="http://www.graphviz.org/pdf/dotguide.pdf"&gt;dot&lt;/a&gt;, which will plot the
graph. I.e.:&lt;/p&gt;
&lt;p&gt;[code lang="bash"]  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python -m mccabe -d example.py | \&lt;br /&gt;
dot -Tpng -o example.png&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;produces something like the graph shown to the left.&lt;/p&gt;
&lt;p&gt;As well as using the cyclomatic complexity as a metric of whether a
particular piece of source code needs simplifying, it can also give an
indication of the number of tests that are required. If the number of
tests is less than the complexity metric, then clearly there must be
some paths through that are not being tested. Obviously, it doesn't
necessarily follow that, if the number of tests is equal to or greater
than the complexity, then all paths &lt;em&gt;are&lt;/em&gt; being tested - more than one
test might be following a particular logical path. So having
&lt;span class="math"&gt;\( V(G)\)&lt;/span&gt; tests for a particular routine &lt;span class="math"&gt;\( G\)&lt;/span&gt;
is necessary but not sufficient to ensure full coverage of all the
paths; but it seems like a good start.&lt;/p&gt;
&lt;h2&gt;Fine-tuning using profiles in Prospector&lt;/h2&gt;
&lt;p&gt;Probably one of the most useful aspects of Prospector is the ability to
fine-tune the warnings that are issued. For instance, once the
strictness level is up to medium or above, you might start to get a lot
of warnings from Pylint about invalid constant names:&lt;/p&gt;
&lt;p&gt;[code]&lt;br /&gt;
example.py&lt;br /&gt;
Line: 1&lt;br /&gt;
pylint: invalid-name / Invalid constant name "nmats"&lt;br /&gt;
Line: 17&lt;br /&gt;
pylint: invalid-name / Invalid constant name "dcoeff"&lt;br /&gt;
Line: 21&lt;br /&gt;
pylint: invalid-name / Invalid constant name "tpower"&lt;br /&gt;
Line: 23&lt;br /&gt;
pylint: invalid-name / Invalid constant name "tmp0"&lt;br /&gt;
...&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://www.python.org/dev/peps/pep-0008"&gt;PEP8 style guide&lt;/a&gt;
suggests constants should be in upper case; I'm happy with this rule but
in most cases that were identified for a particular project I used a
trial run, I didn't regard the variable as a constant (e.g. like
&lt;span class="math"&gt;\( \pi\)&lt;/span&gt;, &lt;span class="math"&gt;\( c\)&lt;/span&gt;, &lt;span class="math"&gt;\( h\)&lt;/span&gt;,
etc.), but a variable that happens not to change - in a lot of the cases
just because the code is incomplete and, at some point down the line,
these will end up changing.&lt;/p&gt;
&lt;p&gt;When we move to the &lt;code&gt;veryhigh&lt;/code&gt; strictness level, another example that
comes up is trailing whitespace. I want to remove trailing whitespace
from lines of code; but because my editor automatically indents, &lt;em&gt;blank&lt;/em&gt;
lines also get indented to the same level as the most recent non-blank
line. This whitespace on otherwise blank lines counts as trailing
whitespace, so I get far too many warning messages.&lt;/p&gt;
&lt;p&gt;Thirdly, classes that have too few (fewer than two) public methods are
warned against; &lt;a href="http://stackoverflow.com/questions/14027417/what-does-pylints-too-few-public-methods-message-mean"&gt;the advice is that classes shouldn't be used for data
storage, but should include
functions&lt;/a&gt;.
If the only purpose is data storage, then a data structure  like a
dictionary is more appropriate. However, again because of the
work-in-progress status of the code being analysed, I've defined certain
classes that currently only register data, but I expect at some point
will include methods. So in the meantime I want to turn this check off,
for the moment at least.&lt;/p&gt;
&lt;p&gt;The fine-tuning is done using profiles. A profile is just a
&lt;a href="http://yaml.org/"&gt;YAML&lt;/a&gt;file with some configuration information, so you
can give different projects different rule sets by giving them their own
configuration file. An example is:&lt;/p&gt;
&lt;p&gt;[code]&lt;br /&gt;
strictness: veryhigh&lt;br /&gt;
ignore-paths: QA&lt;br /&gt;
pylint:&lt;br /&gt;
disable:&lt;br /&gt;
- invalid-name&lt;br /&gt;
- trailing-whitespace&lt;br /&gt;
- too-few-public-methods&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The really nice part is that configurations can inherit from other
configurations. For example, Prospector's different &lt;code&gt;--strictness&lt;/code&gt;
options are really just different pre-defined profiles, and the example
above has been set up to inherit from the &lt;code&gt;--strictness high&lt;/code&gt; profile.
The project-specific tweaks are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ignore the directory called `QA` and its contents (which in this
    project contains temporary/intermediate files). This can also be
    achieved by using `--ignore-paths QA` on the command line.&lt;/li&gt;
&lt;li&gt;Disable the `invalid-name` messages from Pylint.&lt;/li&gt;
&lt;li&gt;Disable the `trailing-whitespace` messages from Pylint&lt;/li&gt;
&lt;li&gt;Disable the `too-few-public-methods` messages from Pylint&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Adding additional tools&lt;/h2&gt;
&lt;p&gt;As well as the default tools (Pylint,
&lt;a href="https://pypi.python.org/pypi/pep8"&gt;pep8&lt;/a&gt;,
&lt;a href="https://pypi.python.org/pypi/pyflakes"&gt;pyflakes&lt;/a&gt;, mccabe,
&lt;a href="https://github.com/landscapeio/dodgy"&gt;dodgy&lt;/a&gt; and profile_validator),
additional tools can be turned on either via the command line or by
adding them to a profile. The useful extra options are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.python.org/pypi/pep257"&gt;pep257&lt;/a&gt;, which checks that
    docstrings conform to the &lt;a href="https://www.python.org/dev/peps/pep-0257/"&gt;PEP257 docstring conventions
    guide&lt;/a&gt;. Use `--with-tool
    pep257` on the command line, or add `run: true` to a `pep257:`
    section in a profile file.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.python.org/pypi/vulture"&gt;vulture&lt;/a&gt;, which checks for
    'dead code' (unused variables, functions, classes, etc.). This
    requires installation first, via `pip install
    prospector[with_vulture]`. (NB this syntax doesn't work in a &lt;a href="http://zsh.sourceforge.net/"&gt;Z
    shell&lt;/a&gt;.)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.python.org/pypi/pyroma"&gt;pyroma&lt;/a&gt;, used for checking
    that Python packaging best practices are being followed. Requires
    `pip install prospector[with_pyroma]`. Note that using pyroma
    implies the use of pep257.&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="cyclomatic complexity"></category><category term="graph theory"></category><category term="mccabe"></category><category term="pep8"></category><category term="prospector"></category><category term="pylint"></category><category term="python"></category><category term="static analysis"></category><category term="yaml"></category></entry><entry><title>CUDA basics part 1</title><link href="http://0x7df.github.io/cuda-basics-part-1.html" rel="alternate"></link><updated>2015-04-05T20:59:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-04-05:cuda-basics-part-1.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/CUDA"&gt;CUDA (Compute Unified Device
Architecture)&lt;/a&gt;is an extension of
&lt;a href="http://www.tutorialspoint.com/cprogramming/c_overview.htm"&gt;C/C++&lt;/a&gt;,
developed by &lt;a href="http://www.nvidia.com/page/home.html"&gt;NVIDIA&lt;/a&gt;, the
&lt;a href="http://www.webopedia.com/TERM/G/GPU.html"&gt;GPU&lt;/a&gt;manufacturer, for
programming their devices. (There is also a &lt;a href="https://www.pgroup.com/resources/cudafortran.htm"&gt;Fortran
version&lt;/a&gt;, developed by
&lt;a href="http://www.pgroup.com/"&gt;PGI&lt;/a&gt;.) The purpose of CUDA is to allow
developers to program GPUs much more easily than previously, and since
its inception in 2007, the use of GPUs has opened up beyond just
graphics to more general, e.g. scientific, computing, which is often
referred to as general-purpose GPU computing -
&lt;a href="http://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units"&gt;GPGPU&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;CUDA is proprietary, which in my opinion disqualifies it from use in
major code development. The lifetime of high-performance scientific and
engineering codes is typically decades, and given &lt;a href="http://dx.doi.org/10.1017/S0962492912000050"&gt;the uncertainty
surrounding supercomputing
architectures&lt;/a&gt;, a credible
candidate for a programming model needs to be supported by a wide range
of compilers and on a wide range of platforms. (A similar programming
language is &lt;a href="https://www.khronos.org/opencl/"&gt;OpenCL&lt;/a&gt;, which as the name
suggests, is an open standard, being developed by a consortium of
organisations.) However, the &lt;a href="https://www.coursera.org/course/hetero"&gt;point has been
made&lt;/a&gt;that CUDA is a useful
teaching vehicle for the basic concepts of programming heterogeneous,
many-core supercomputers.&lt;/p&gt;
&lt;h2&gt;Heterogeneous Computing&lt;/h2&gt;
&lt;p&gt;Let's assume here that the model is heterogeneous; i.e. there are CPUs
(hosts) and GPUs (devices) working in conjunction, and that the
application runs on the CPU host, handing specific, highly
&lt;a href="http://queue.acm.org/detail.cfm?id=1365499"&gt;data-parallel&lt;/a&gt; parts of the
program off to the device as and when appropriate. Also , we assume
initially that the CPU part is basically serial; that is, we're not
combining CUDA with &lt;a href="http://www.mpi-forum.org/"&gt;MPI&lt;/a&gt; at this stage.&lt;/p&gt;
&lt;p&gt;To exploit this kind of architecture, it's necessary to &lt;em&gt;kernelise&lt;/em&gt; the
code: identify parts of it suitable for a high level of concurrency,
turn them into kernel functions that are handed over to the GPU device.
These will typically be portions of the code that are highly
data-parallel - i.e. loops over large sets of data items where the
iterations of the loops are independent of each other. A nice example is
a simple "DAXPY" loop (i.e. a double precision &lt;em&gt;Ax&lt;/em&gt; + &lt;em&gt;y&lt;/em&gt; vector
addition) or "DAXBY" loop (&lt;em&gt;Ax&lt;/em&gt; × &lt;em&gt;y&lt;/em&gt;), implemented here in C:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;void vectorAdd(int n, double a, double *x, double *y) {
    for (int i = 0; i &amp;lt; n; ++i) {  
        y[i] = a*x[i] + y[i];
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that the element indices are all &lt;code&gt;i&lt;/code&gt;; there's no use of data from
previous iterations of the loop. It's this absence of &lt;em&gt;loop-carried
dependencies&lt;/em&gt; that makes this loop data-parallel, and therefore suitable
for threading. Essentially, we can calculate all the iterations of the
loop independently, in any order; hence we can pass it to a GPU and
invoke as many threads as there are elements, to do the work as
concurrently as possible.&lt;/p&gt;
&lt;h2&gt;GPU hardware overview&lt;/h2&gt;
&lt;h3&gt;Threading&lt;/h3&gt;
&lt;p&gt;This post is about how to program using CUDA, but to understand what's
going on it's necessary to have a minimum of knowledge about the
hardware architecture. A single GPU is comprised of a set of what are
known, in NVIDIA's terminology, as &lt;em&gt;streaming multiprocessors&lt;/em&gt; (SMs);
these are, according to &lt;a href="http://booksite.elsevier.com/9780123838728/"&gt;Hennessy and
Patterson&lt;/a&gt;, "multithreaded
&lt;a href="http://en.wikipedia.org/wiki/SIMD"&gt;SIMD&lt;/a&gt; processors", with the nearest
non-GPU equivalent being a multithreaded &lt;a href="http://www.phy.ornl.gov/csep/ca/node24.html"&gt;vector
processor&lt;/a&gt;. The typical
number of SMs in one GPU is between 2 and 30, varying from generation to
generation. Each SM can support a maximum number of threads at one time,
typically in the low thousands (e.g. 1,536) ; so overall the GPU can
handle tens of thousands of threads simultaneously. A key aspect of the
GPU is that, as well as being massively multithreaded, it also has a
SIMD aspect. The threads assigned to a streaming multiprocessor are
grouped into sets of 32 threads, called &lt;em&gt;warps&lt;/em&gt;. Each 32-thread warp is
dealt with by the SM in a SIMD fashion; that is, each instruction is
fetched once and executed for all 32 threads at the same time. So all
the threads in a particular warp are progressed in lock-step. Hence
there are two types of parallelism at play in a GPU:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multithreading (a kind of&lt;a href="en.wikipedia.org/wiki/SPMD"&gt;SPMD - single program/multiple data
    parallelism&lt;/a&gt;), where different
    processors execute the same program independently, on different
    subsets of the data; and&lt;/li&gt;
&lt;li&gt;SIMD (single instruction/multiple data), where each processor is
    executing the same instruction at the same time as every other.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that the SIMD aspect causes problems in cases where, as a result of
the logic of the particular bit of code being executed, different
threads within the same warp end up going down different paths through
the code, and therefore require different instructions. The GPU can
handle this &lt;em&gt;control divergence&lt;/em&gt;, but execution becomes inefficient; so
it's something the programmer needs to be aware of and think explicitly
about avoiding.&lt;/p&gt;
&lt;h3&gt;Memory&lt;/h3&gt;
&lt;p&gt;As will become clear, it's also vitally important to understand the
memory hierarchy of a GPU. As well as, and separate from, the host CPU's
memory (and we'll ignore the
&lt;a href="http://www.bottomupcs.com/memory.html"&gt;hierarchy&lt;/a&gt;there), the GPU device
has several different levels of memory:&lt;/p&gt;
&lt;p&gt;&lt;img alt="gpu_layout" src="https://0x7df.files.wordpress.com/2015/02/gpu_layout.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The main &lt;em&gt;global memory&lt;/em&gt; or &lt;em&gt;device memory&lt;/em&gt;, which is accessible to
    all the threads on the GPU,&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;constant memory&lt;/em&gt;, also globally accessible,&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;shared memory&lt;/em&gt;, of which each streaming multiprocessor has its
    own private bank, accessible to only the threads on that SM, and&lt;/li&gt;
&lt;li&gt;The per-thread &lt;em&gt;private memory&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On reaching a portion of the code that is data parallel and suitable for
passing to the GPU, the programmer allocates memory in the device's
global memory, and then uses CUDA commands to transfer data items from
the CPU host memory into the global memory. Calculated quantities then
need to be explicitly transferred back again. This is where we see the
first key difference from &lt;a href="www.openmp.org"&gt;OpenMP&lt;/a&gt; threading; in that
model, variables and arrays in memory are declared as either private
(each thread has its own copy) or global (every thread sees the same bit
of memory); but either way they all reside on the same memory hardware.
In CUDA we explicitly have to transfer data from CPU to GPU memory space
and back again.&lt;/p&gt;
&lt;p&gt;The global (device) memory is the only memory that the host CPU can read
and write to. Transfers into shared memory and private memory can be
done only by the GPU itself.&lt;/p&gt;
&lt;h2&gt;Threads and blocks&lt;/h2&gt;
&lt;p&gt;When we implement a CUDA kernel function, which is a chunk of highly
data-parallel code that will be handled by a large set of threads
working concurrently, we arrange the threads into a &lt;em&gt;grid&lt;/em&gt; of &lt;em&gt;thread
blocks&lt;/em&gt;. We'll worry about why this is, later; for now just note that a
grid is a three-dimensional construction of &lt;em&gt;l ×&lt;/em&gt; &lt;em&gt;m&lt;/em&gt; × &lt;em&gt;n&lt;/em&gt; thread
blocks, each of which is three-dimensional grouping of &lt;em&gt;i&lt;/em&gt; × &lt;em&gt;j&lt;/em&gt; × &lt;em&gt;k&lt;/em&gt;
threads. The actual values of &lt;em&gt;i&lt;/em&gt;, &lt;em&gt;j&lt;/em&gt;, ... to be used are defined in
the host code by the special CUDA statements:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;dim3 gridDims(l,m,n);  
dim3 blockDims(i,j,l);  
myKernel&amp;lt;&amp;lt;&amp;lt;gridDims,blockDims&amp;gt;&amp;gt;&amp;gt;(args);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The third statement launches the kernel function called &lt;code&gt;myKernel&lt;/code&gt;, and
is a standard C function call statement - i.e. &lt;code&gt;myKernel(args)&lt;/code&gt; - but
with the special CUDA notation - &lt;code&gt;&amp;lt;&amp;lt;&amp;lt;gridDims, blockDims&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; - rather
unpleasantly intruding between the function name and its arguments. The
previous two lines define the variables &lt;code&gt;gridDims&lt;/code&gt; and &lt;code&gt;blockDims&lt;/code&gt; as
having &lt;code&gt;dim3&lt;/code&gt; type.&lt;/p&gt;
&lt;p&gt;CUDA requires that the blocks be independent of each other; there is no
way to communicate between different blocks that are executing.&lt;/p&gt;
&lt;p&gt;The reason for grouping threads together into blocks, is so that the
streaming multiprocessor can switch between threads (or really between
warps, which are sets of 32 threads that are always executed in
lock-step) - this means that one warp is waiting for a memory access,
the SM can switch to another in the meantime.&lt;/p&gt;
&lt;h2&gt;Vector addition - host code&lt;/h2&gt;
&lt;p&gt;The host C code running on the CPU will look something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;int main(int argc, char **argv) {
    int n, gridSize;  
    float *hostX, *hostY;  
    float *deviceX, *deviceY;  
    cudaError_t err;

    // Allocate and populate the hostX and hostY vectors

    // Allocate GPU memory  
    int size = n*sizeof(float);  
    err = cudaMalloc((void **) &amp;amp;deviceX, size);  
    err = cudaMalloc((void **) &amp;amp;deviceY, size);

    // Copy memory to the GPU  
    err = cudaMemcpy(deviceX, hostX, size, cudaMemcpyHostToDevice);  
    err = cudaMemcpy(deviceY, hostY, size, cudaMemcpyHostToDevice);

    // Initialize the grid and block dimensions  
    dim3 gridDims(ceil(n/256),1,1);  
    dim3 blockDims(256,1,1);

    // Launch the GPU Kernel  
    myKernel&amp;lt;&amp;lt;&amp;lt;gridDims,blockDims&amp;gt;&amp;gt;&amp;gt;(n, deviceX, deviceY);

    // Copy the GPU memory back to the CPU  
    err = cudaMemcpy(hostY, deviceY, size, cudaMemcpyDeviceToHost);

    // Free the GPU memory  
    err = cudaFree(deviceX);  
    err = cudaFree(deviceY);

    // Do something with the solution, free the host  
    // arrays, return  
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the definition of the grid and block dimensions, we've chosen to have
256 threads per block, and therefore &lt;em&gt;n&lt;/em&gt;/256 blocks (and we've used the
ceiling function to make sure the number of blocks is rounded &lt;em&gt;up&lt;/em&gt; to
the nearest integer if &lt;em&gt;n&lt;/em&gt; isn't divisible by 256). The grid and the
blocks are one-dimensional, for simplicity.&lt;/p&gt;
&lt;p&gt;Hopefully, the various CUDA functions that are called - &lt;code&gt;cudaMalloc&lt;/code&gt;,
&lt;code&gt;cudaMemcpy&lt;/code&gt; and &lt;code&gt;cudaFree&lt;/code&gt; - are fairly self-explanatory, and are &lt;a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide"&gt;well
documented&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Vector addition - kernel code&lt;/h2&gt;
&lt;p&gt;The CUDA kernel function that is called looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;__global__ void vecAdd(int n, float *x, float *y) {  
    int i = threadIdx.x + blockDim.x*blockIdx.x;  
    if (i &amp;lt; n) y[i] = x[i] + y[i];  
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first difference from an ordinary C function is the &lt;code&gt;__global__&lt;/code&gt;
keyword at the beginning of the function declaration. The compiler needs
to distinguish between functions for the host CPU and kernel functions
intended for the GPU; it does this using the keywords &lt;code&gt;__host__&lt;/code&gt; for the
former, and either &lt;code&gt;__global__&lt;/code&gt; or &lt;code&gt;__device__&lt;/code&gt; for the latter. The
second difference is the existence of the pre-defined variables
&lt;code&gt;threadIdx&lt;/code&gt; and &lt;code&gt;blockIdx&lt;/code&gt;, which give the (&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;, &lt;em&gt;z&lt;/em&gt;) indices of
the thread within the block, and of the block within the grid,
respectively; and &lt;code&gt;blockDim&lt;/code&gt;, which gives the (&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;, &lt;em&gt;z&lt;/em&gt;) dimensions
of the block, as defined in the function call.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;if&lt;/code&gt; statement is included for the case where &lt;em&gt;n&lt;/em&gt; is not divisible
by 256 and therefore we have &lt;code&gt;ceil(n/256)&lt;/code&gt; blocks, resulting in there
being more threads than elements in the vector(s).&lt;/p&gt;
&lt;h2&gt;Parallel efficiency&lt;/h2&gt;
&lt;p&gt;If we ignore the multiplication by the constant &lt;em&gt;A&lt;/em&gt; for the moment, and
concentrate on the vector addition &lt;code&gt;y[i] = x[i] + y[i]&lt;/code&gt;, we can see that
there are three memory accesses (two reads and a write) for each
statement, and only one floating-point calculation (the addition). The
&lt;a href="http://www.greatlakesconsortium.org/events/GPUMulticore/Chapter4-CudaMemoryModel.pdf"&gt;compute-to-global-memory-access (CGMA)
ratio&lt;/a&gt;
is therefore 1:3, or 1/3. This is an important metric of the performance
of an application or section of code. We often refer to codes as being
either &lt;em&gt;compute-bound&lt;/em&gt; or &lt;em&gt;memory-bound&lt;/em&gt;, depending on whether the
limiting factor on improving their performance is the rate at which we
can do computations, or the rate at which we can retrieve and send data
to and from memory. We'll see now that for a typical GPU, this vector
addition operation is very clearly memory-limited.&lt;/p&gt;
&lt;p&gt;A typical memory bandwidth for a GPU might be, say, 200GB/s, which means
that we can load/store:&lt;/p&gt;
&lt;div class="math"&gt;$$ \frac{200\,\mathrm{GB/s}}{8\,\mathrm{B/memory\:access}} =
25 \times 10^9\,\mathrm{memory\:access/s} $$&lt;/div&gt;
&lt;p&gt;Crudely, this limits the actual computation rate to&lt;/p&gt;
&lt;div class="math"&gt;$$ 25 \times
10^9\,\mathrm{memory\:access/s}\,\times\,0.33\,\mathrm{FLOP}/\mathrm{memory\:access}
\approx 8\,\mathrm{GFLOP/s} $$&lt;/div&gt;
&lt;p&gt;The peak theoretical performance of the GPU might be, say, 1000 GFLOP/s
double-precision – i.e. the actual performance obtained is  less than 1%
of peak. This is the case no matter how many threads there are - the
limiting factor is how quickly data can be transferred between the
global memory and the processors.&lt;/p&gt;
&lt;p&gt;For this function - simple vector addition - there isn't a great deal we
can do about the fact that it's memory bound. You have to bring back
each pair of elements from &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; from memory, then put the result
back again - the number of memory operations is irreducible. For more
complex operations, where pieces of data are typically used multiple
times, the trick is to use shared memory, which is much, much faster
than global memory. However, there is obviously much less of it, so only
small chunks of data can be placed there at a time; this means that
programmers need to think very carefully about memory access patterns in
their code, to ensure that multiple uses of a given chunk of data are
grouped as closely together as possible in the flow of the program, so
data isn't continually being placed and replaced in shared memory, via
expensive global memory operations. This is analogous to moving data
from memory into local
&lt;a href="http://searchstorage.techtarget.com/definition/cache-memory"&gt;cache&lt;/a&gt; in
a normal CPU, except that in CUDA programming for GPUs, the programmer
is explicitly controlling movement of data between the shared and global
memory.&lt;/p&gt;
&lt;p&gt;Actually, one way to improve the vector addition might be to
utilise &lt;a href="www.cs.iastate.edu/~prabhu/Tutorial/PIPELINE/instrLevParal.html"&gt;instruction-level parallelism
(ILP)&lt;/a&gt;.
In the kernel, the single floating-point operation has to wait for both
of the input vector elements (&lt;code&gt;x[i]&lt;/code&gt; and &lt;code&gt;y[i]&lt;/code&gt;) to be retrieved from
global memory before it can begin. Hence if the global memory reads and
writes take &lt;em&gt;M&lt;/em&gt; clock cycles each, and the floating operation takes &lt;em&gt;N&lt;/em&gt;,
then the total number of clock cycles is &lt;em&gt;(M+1)+N+M&lt;/em&gt; (assuming the
second load begins one clock cycle after the first, but otherwise that
they are done simultaneously). This is &lt;em&gt;2M+N+1&lt;/em&gt;, so to go through it &lt;em&gt;k&lt;/em&gt;
times is &lt;em&gt;k(2M+N+1)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;However, if within the kernel we loaded two values of each input vector,
say &lt;code&gt;x[i+1]&lt;/code&gt; and &lt;code&gt;y[i+1]&lt;/code&gt; as well as &lt;code&gt;x[i]&lt;/code&gt; and &lt;code&gt;y[i]&lt;/code&gt;, then the
computation of &lt;code&gt;x[i] + y[i]&lt;/code&gt; starts after &lt;em&gt;M+1&lt;/em&gt; cycles and takes &lt;em&gt;N&lt;/em&gt;
cycles, so the result is written back to global memory after &lt;em&gt;(M+1)+N+M&lt;/em&gt;
cycles as before; &lt;em&gt;but&lt;/em&gt;, x[i+1] can start to load after 2 cycles, and
y[i+1] after 3 cycles, so computation of &lt;code&gt;x[i+1] + y[i+1]&lt;/code&gt; can begin
after &lt;em&gt;M+3&lt;/em&gt; cycles, and still takes &lt;em&gt;N&lt;/em&gt;. Hence &lt;code&gt;y[i+1]&lt;/code&gt; has been written
back to global memory after &lt;em&gt;(M+3)+N+M&lt;/em&gt; cycles. This means the whole
operation to get &lt;code&gt;x[i] + y[i]&lt;/code&gt; and &lt;code&gt;x[i+1] + y[i+1]&lt;/code&gt; takes &lt;em&gt;(M+3)+N+M&lt;/em&gt;
cycles overall, which is only 2 cycles more than it took to get only
&lt;code&gt;x[i] + y[i]&lt;/code&gt; in the original kernel. For &lt;em&gt;k&lt;/em&gt; elements, it will take
&lt;em&gt;k(2M+N+3)/2&lt;/em&gt;. This is basically going to take half the time of the
original (as long as &lt;em&gt;2M+N&lt;/em&gt; is large enough that the constant doesn't
matter).&lt;/p&gt;
&lt;p&gt;Nothing has been done to reduce the
&lt;a href="http://www.hardwaresecrets.com/article/Understanding-RAM-Timings/26/2"&gt;latency&lt;/a&gt;of
the memory operations, or to do fewer of them; instead they've been
overlapped as much as possible. This is called &lt;em&gt;latency-hiding&lt;/em&gt; - doing
other useful things while waiting for data to return from memory.
Actually, at a different level, the concept of latency-hiding is also
fundamental to the GPU and threading; by dividing up the data to be
processed into small chunks, and having many different threads operate
on those chunks, the GPU has much more flexibility to schedule work so
that memory latency can be hidden. For this reason, GPUs are described
as &lt;em&gt;throughput-oriented&lt;/em&gt; - they are more concerned with operating on
lots of data concurrently so they need to worry less about latency;
whereas CPUs, on the other hand, are &lt;em&gt;latency-oriented&lt;/em&gt;, and are
designed with as many tricks as possible up their sleeve to reduce
latency, under the assumption of, basically, a sequential execution
model.&lt;/p&gt;
&lt;p&gt;If the same sequential processor were handling all the elements, like in
a typical CPU, then this
&lt;a href="cs.stanford.edu/people/eroberts/courses/soco/projects/risc/pipelining/"&gt;pipelining&lt;/a&gt;
is the sort of thing modern processors try to do for you anyway, without
you having to worry about it.&lt;/p&gt;
&lt;hr /&gt;
&lt;div style="background:#FFFFFF;margin:0 10px 10px 0;padding:0 10px 0 0;text-align:left;font-family:Arial, Helvetica, sans-serif;line-height:1em;"&gt;
&lt;div style="font-size:11px;padding:0 0 10px;font-weight:bold;color:#045989;"&gt;

High-performance computing systems: Status and outlook

&lt;/div&gt;

&lt;div style="font-size:11px;"&gt;

J. J. Dongarra and A. J. van der Steen (2012).
&lt;a href="http://journals.cambridge.org/action/displayJournal?jid=ANU"&gt;Acta Numerica&lt;/a&gt;,
&lt;a href="http://journals.cambridge.org/action/displayIssue?iid=8539365"&gt;Volume 21 &lt;/a&gt;,
&lt;a href="http://journals.cambridge.org/action/displayAbstract?aid=8539374"&gt;May 2012, pp.379-474&lt;/a&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="C"></category><category term="CUDA"></category><category term="GPU"></category><category term="HPC"></category><category term="massively parallel"></category><category term="parallel computing"></category><category term="parallel programming"></category></entry><entry><title>Converting from Doxygen to WordPress</title><link href="http://0x7df.github.io/converting-from-doxygen-to-wordpress.html" rel="alternate"></link><updated>2015-03-29T19:27:00+01:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-03-29:converting-from-doxygen-to-wordpress.html</id><summary type="html">&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;I write code documentation in &lt;a href="www.doxygen.org/"&gt;Doxygen&lt;/a&gt;, and in some
cases include a fair amount of information about the mathematical theory
of the problem that the code is solving. It seemed worthwhile posting
the same content on &lt;a href="https://wordpress.com"&gt;Wordpress&lt;/a&gt;. However, the
syntax isn't 100% interchangeable, despite both applications supporting
&lt;a href="http://daringfireball.net/projects/markdown/"&gt;Markdown&lt;/a&gt;. This is mainly
because Doxygen extends Markdown by providing &lt;a href="http://www.stack.nl/~dimitri/doxygen/manual/commands.html"&gt;a large range of special
commands&lt;/a&gt;,
which begin with a &lt;code&gt;/&lt;/code&gt; or a &lt;code&gt;@&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The bulk of the changes that need to be made are to the equations.
Doxygen and WordPress both allow 
&lt;a href="http://www.latex.org"&gt;&lt;img alt="\LaTeX" src="https://s0.wp.com/latex.php?latex=%5CLaTeX&amp;amp;fg=000" title="\LaTeX" /&gt;&lt;/a&gt;
equations; Doxygen by actually
calling &lt;img alt="\LaTeX" src="https://s0.wp.com/latex.php?latex=%5CLaTeX&amp;amp;fg=000" title="\LaTeX" /&gt;
to generate
&lt;a href="en.wikipedia.org/wiki/Portable_Network_Graphics"&gt;PNG&lt;/a&gt;-format images
which it embeds in the &lt;a href="www.w3schools.com/html/"&gt;HTML&lt;/a&gt;files that it
generates, and WordPress by using one of &lt;a href="https://wordpress.org/plugins/search.php?q=latex"&gt;various
plug-ins&lt;/a&gt; (see
documentation &lt;a href="https://en.support.wordpress.com/latex/"&gt;here&lt;/a&gt;). However,
while the code for the actual equation is identical in both, being
standard
&lt;a href="http://www.ams.org/publications/authors/tex/amsmath"&gt;amsmath&lt;/a&gt;-style
&lt;a href="http://www.latex.org"&gt;&lt;img alt="\LaTeX" src="https://s0.wp.com/latex.php?latex=%5CLaTeX&amp;amp;fg=000" title="\LaTeX" /&gt;&lt;/a&gt;,
the delimiters that identify it as maths and separate it from the body
of the text are different. References also need to be handled
differently.&lt;/p&gt;
&lt;p&gt;[caption id="" align="alignright" width="404"]&lt;img alt="xkcd:
Automation" src="http://imgs.xkcd.com/comics/automation.png" /&gt; xkcd: Automation
- http://imgs.xkcd.com/comics/automation.png[/caption]&lt;/p&gt;
&lt;p&gt;Rather than do the conversion by hand, I knocked up a simple
&lt;a href="http://python.org"&gt;Python&lt;/a&gt; script to do it (and in doing so risked
falling into the trap of spending more time writing code to automate the
task than I would have spent doing it manually) using simple &lt;a href="www.regular-expressions.info/"&gt;regular
expressions&lt;/a&gt; in some cases. This post
describes how the script works, so along the way we'll learn a bit of
Python, something about regular expressions, and a bit about Doxygen and
WordPress syntax.&lt;/p&gt;
&lt;p&gt;Let's jump straight in. The script is called from the command line:&lt;/p&gt;
&lt;p&gt;[code lang="bash"]&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python dox2wp.py /path/to/doxygen/data/example.md&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;[/code]&lt;/p&gt;
&lt;p&gt;The script is called &lt;code&gt;dox2wp.py&lt;/code&gt;, and we've passed the full path to a
Doxygen Markdown file called &lt;code&gt;example.md&lt;/code&gt; as an argument to the Python
script.&lt;/p&gt;
&lt;h2&gt;Main script&lt;/h2&gt;
&lt;p&gt;The first part of the script looks like this:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
if &lt;strong&gt;name&lt;/strong&gt; == "&lt;strong&gt;main&lt;/strong&gt;":&lt;/p&gt;
&lt;p&gt;args = sys.argv[1:]&lt;/p&gt;
&lt;p&gt;reffile = '/default/path/to/references.md'&lt;/p&gt;
&lt;p&gt;for arg in args:&lt;br /&gt;
errmsg = processdox(arg,reffile)&lt;br /&gt;
for msg in errmsg:&lt;br /&gt;
print msg&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The first line - &lt;code&gt;if __name__ == "__main__":&lt;/code&gt; - is a fairly standard
Python construct that checks that the module being executed has been
called from the command-line or interpreter directly, and not by some
other Python module or function. &lt;a href="http://stackoverflow.com/a/419185/3832350"&gt;This
answer&lt;/a&gt; on
&lt;a href="http://stackoverflow.com"&gt;StackOverflow&lt;/a&gt;gives more details. The next
line retrieves the arguments that were passed in to the Python script
using the &lt;code&gt;sys&lt;/code&gt; module's &lt;code&gt;argv&lt;/code&gt; function  (this assumes &lt;code&gt;sys&lt;/code&gt; has been
imported using &lt;code&gt;import sys&lt;/code&gt; somewhere prior to this statement; usually
at the very top of the file). The &lt;code&gt;argv&lt;/code&gt; function returns the arguments
as a list; the zeroth element corresponds to the name of the script, so
we ignore that and just get elements 1 through to the end of the list
and store them in a new list called &lt;code&gt;args&lt;/code&gt;. You can find documentation
for the &lt;code&gt;sys&lt;/code&gt; module &lt;a href="https://docs.python.org/2/library/sys.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Next we define a hard-wired path to a file, which we'll come back to
later.&lt;/p&gt;
&lt;p&gt;The next chunk of code is where the main business happens. We loop over
all the items in &lt;code&gt;args&lt;/code&gt;, each of which is assumed to be a Markdown file
we want to process. For each, we call the function &lt;code&gt;processdox&lt;/code&gt;, passing
in both the path to the file, and the hard-wired path mentioned above.
The &lt;code&gt;processdox&lt;/code&gt; function returns a list of error messages, which we
bind to the variable &lt;code&gt;errmsg&lt;/code&gt;. The last action in this script is to loop
over the error messages returned by the processing function, and print
them to the screen.&lt;/p&gt;
&lt;h2&gt;Function `processdox`&lt;/h2&gt;
&lt;p&gt;The body of the &lt;code&gt;processdox&lt;/code&gt; function is given below:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
def processdox(filename,reffile):&lt;/p&gt;
&lt;p&gt;errmsg = checkfile(filename)&lt;/p&gt;
&lt;p&gt;if len(errmsg) == 0:&lt;br /&gt;
processfile(filename,reffile=reffile)&lt;/p&gt;
&lt;p&gt;return errmsg&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The first line is the function definition, which also specifies the
arguments that function accepts: &lt;code&gt;filename&lt;/code&gt; and &lt;code&gt;reffile&lt;/code&gt;. Then, two
functions are called: the first, &lt;code&gt;checkfile&lt;/code&gt;, does some error-checking,
and the second, &lt;code&gt;processfile&lt;/code&gt;, does the main work - but only if the
length of the list &lt;code&gt;errmsg&lt;/code&gt; is zero (i.e. it contains no data, which is
a way of checking that &lt;code&gt;checkfile&lt;/code&gt; didn't return any error messages).&lt;/p&gt;
&lt;h2&gt;Error checking&lt;/h2&gt;
&lt;p&gt;Let's see the file-checking function &lt;code&gt;checkfile&lt;/code&gt; next:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
def checkfile(filename):&lt;/p&gt;
&lt;p&gt;errmsg = []&lt;/p&gt;
&lt;p&gt;filebase, fileext = os.path.splitext(filename)&lt;/p&gt;
&lt;p&gt;if fileext != '.md':&lt;br /&gt;
errmsg.append(filename+' is not Markdown')&lt;/p&gt;
&lt;p&gt;if not os.path.isfile(filename):&lt;br /&gt;
errmsg.append(filename+' does not exist or is&lt;br /&gt;
not a file')&lt;/p&gt;
&lt;p&gt;return errmsg&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This first declares the &lt;code&gt;errmsg&lt;/code&gt; variable as an empty list, and then
uses the standard &lt;code&gt;os.path&lt;/code&gt; module's &lt;code&gt;splitext&lt;/code&gt; function, which returns
the file's extension, and everything up to that extension (as a tuple),
which we write into &lt;code&gt;fileext&lt;/code&gt; and &lt;code&gt;filebase&lt;/code&gt;. Doing this allows us to
check easily that the file extension is &lt;code&gt;.md&lt;/code&gt;. The next check is that
the filename given refers to something that exists and is a file (e.g.
as opposed to a directory), using the &lt;code&gt;isfile()&lt;/code&gt; function. Documentation
for &lt;code&gt;os.path&lt;/code&gt; can be found
&lt;a href="https://docs.python.org/2/library/os.path.html#module-os.path"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Notice that all we do on finding an error is to append an error message
to the previously defined list, using &lt;code&gt;errmsg.append()&lt;/code&gt;. The reason for
this is that, although it scarcely matters for this almost trivial
application, I find it good practice to let a piece of code go on for as
long as it can after encountering errors, because there may be further
errors that will get picked up subsequently. If it stopped immediately,
the user would fix that error, and start it again, whereupon the next
error encountered would cause it to bail out again. For software with
complicated input this could go on for a long time and cause a lot of
frustration. The behaviour here, however, is to keep going and identify
as many errors as possible before stopping, so we minimise the number of
iterations the user will have to go through to fix everything.&lt;/p&gt;
&lt;p&gt;For example, if we call:&lt;/p&gt;
&lt;p&gt;[code lang="bash"]  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python dox2wp.py isnotmarkdown.txt doesnotexist.md \&lt;br /&gt;
existsbutisafolder.md realmarkdown.md&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;then we get:&lt;/p&gt;
&lt;p&gt;[code]&lt;br /&gt;
isnotmarkdown.txt is not Markdown&lt;br /&gt;
doesnotexist.md does not exist or is not a file&lt;br /&gt;
existsbutisafolder.md does not exist or is not a file&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Note there's no error message referring to &lt;code&gt;realmarkdown.md&lt;/code&gt;, which
meets the criteria and so is processed successfully.&lt;/p&gt;
&lt;p&gt;It's important to understand that this isn't the same as being
fault-tolerant or trying to recover from the errors. In principle, as
soon as the user does something that doesn't seem to fit in with the way
a piece of code is intended to work, we should stop and let the user
know; trying to recover starts to get into the realm of making
assumptions about what the user wants. All we're doing here is
continuing to progress through the &lt;em&gt;error-checking&lt;/em&gt; when an error is
encountered; as soon as one is, the actual processing is prevented by
the &lt;code&gt;if&lt;/code&gt; statement around the call to &lt;code&gt;processfile&lt;/code&gt;. We do allow the
application to continue to the next Markdown file if an error was
encountered previously, but since processing of each file is completely
independent, this seems safe enough.&lt;/p&gt;
&lt;p&gt;Of course, all this is total overkill for what we're trying to do, but
is useful to illustrate the principles in a simple application.&lt;/p&gt;
&lt;h2&gt;The actual format conversion part&lt;/h2&gt;
&lt;h3&gt;Preamble&lt;/h3&gt;
&lt;p&gt;Function &lt;code&gt;processfile&lt;/code&gt; executes the real work. This is somewhat longer
so we'll deal with it in sections. It starts with:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
def processfile(filename,reffile='references.md'):&lt;/p&gt;
&lt;p&gt;fi = open(filename,'r')&lt;br /&gt;
fo = open(filename+'.txt','w')&lt;br /&gt;
fr = open(reffile,'r')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;After the function definition, which like the previous one we saw
defines the input arguments &lt;code&gt;filename&lt;/code&gt; and &lt;code&gt;reffile&lt;/code&gt; (but with the
addition that the &lt;code&gt;reffile&lt;/code&gt; variable defaults to &lt;code&gt;references.md&lt;/code&gt; if no
argument is passed in), the next three lines open some files. &lt;code&gt;filename&lt;/code&gt;
and &lt;code&gt;reffile&lt;/code&gt; are opened as read-only (with some obvious error-checking
around &lt;code&gt;reffile&lt;/code&gt; clearly missing). A new file called &lt;code&gt;reffile + '.txt'&lt;/code&gt;
is opened as writeable, and this will contain the output; the filename
will be the same as the input but with &lt;code&gt;.txt&lt;/code&gt; appended, e.g.
&lt;code&gt;example.md.txt&lt;/code&gt; if the input was &lt;code&gt;example.md&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The next stage is to define some regular expressions that will get used
later; we define them here rather than nearer to where they get used
because their use will be inside a loop, and there's no point
re-defining them every time the loop is executed, because they're always
the same.&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
p1 = re.compile('@f\&lt;span class="math"&gt;\([^@]*@f\\\)&lt;/span&gt;')&lt;br /&gt;
p2 = re.compile('@ref [^"]&lt;em&gt; "[^"]&lt;/em&gt;"')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;We'll come back to these when they're needed.&lt;/p&gt;
&lt;p&gt;The final part of the pre-amble involved setting up a counter and an
empty list for the references, again which we'll come to when we need
them.&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
refnum = 1&lt;br /&gt;
footnotes = []&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;In the next stage we enter the loop over individual lines in the input
file, which Python implements very simply as &lt;code&gt;for line in fi:&lt;/code&gt;, with
&lt;code&gt;line&lt;/code&gt; being the variable name into which each successive line is
placed, and &lt;code&gt;fi&lt;/code&gt; just being the pointer to the opened text file.&lt;/p&gt;
&lt;p&gt;The first text-processing operation is to replace &amp;lt; and &amp;gt; with their
HTML equivalents: &lt;code&gt;&amp;amp;lt;&lt;/code&gt; and &lt;code&gt;&amp;amp;gt;&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
for line in fi:&lt;/p&gt;
&lt;p&gt;# Some of the later changes insert "&amp;lt;" and "&amp;gt;" so do&lt;br /&gt;
# these as early as possible&lt;br /&gt;
line = line.replace('&amp;lt;','&amp;lt;')&lt;br /&gt;
line = line.replace('&amp;gt;','&amp;gt;')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The reason for this is that, for this to work overall, the final output
needs to be copied and pasted into WordPress's HTML editor, rather than
the Visual editor. Consequently, there's a risk that any &amp;lt; and &amp;gt;
symbols appearing in mathematical formulae will get interpreted as
delimiters for an HTML tag. E.g. if:&lt;/p&gt;
&lt;div class="math"&gt;$$ a &amp;lt; b$ and also $ b &amp;gt; c $$&lt;/div&gt;
&lt;p&gt;appeared on a single line then the string:&lt;/p&gt;
&lt;div class="math"&gt;$$ &amp;lt; b$ and also $ b &amp;gt; $$&lt;/div&gt;
&lt;p&gt;would get interpreted as an HTML tag (and ignored as not recognised),
leaving:&lt;/p&gt;
&lt;div class="math"&gt;$$ a c $$&lt;/div&gt;
&lt;p&gt;I wasn't expecting this, at least not when the &amp;lt; and &amp;gt; symbols were
safely inside the correct &lt;code&gt;$latex&lt;/code&gt; and &lt;code&gt;$&lt;/code&gt; delimiters identifying them
as maths - but it happened, which seems like a flaw in the WordPress
parsing.&lt;/p&gt;
&lt;h3&gt;Special commands&lt;/h3&gt;
&lt;p&gt;Subsequently, we remove some of the Doxygen special commands:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
# Remove the table of contents special command&lt;br /&gt;
line = line.replace('\\tableofcontents','')&lt;/p&gt;
&lt;p&gt;# Replace the Doxygen special commands for sections&lt;br /&gt;
# with Markdown&lt;br /&gt;
if '\section' in line:&lt;br /&gt;
fields = line.split()&lt;br /&gt;
line = '# ' + ' '.join(fields[2:])&lt;br /&gt;
if '\subsection' in line:&lt;br /&gt;
fields = line.split()&lt;br /&gt;
line = '## ' + ' '.join(fields[2:])&lt;br /&gt;
if '\subsubsection' in line:&lt;br /&gt;
fields = line.split()&lt;br /&gt;
line = '### ' + ' '.join(fields[2:])&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The first special command is &lt;code&gt;\tableofcontents&lt;/code&gt;, which appears on its
own and causes Doxygen to automatically insert a contents table into the
rendered page at that location. We strip this out by replacing it with
an empty string, using the &lt;code&gt;replace&lt;/code&gt; string method.&lt;/p&gt;
&lt;p&gt;Next are &lt;code&gt;\section&lt;/code&gt;, &lt;code&gt;\subsection&lt;/code&gt; and &lt;code&gt;\subsubsection&lt;/code&gt;. Each of these
special commands is followed by two arguments: first an identifying tag,
which can then be used elsewhere in the Doxygen pages to create a link
to this section, followed by the actual title of the section, e.g.:&lt;/p&gt;
&lt;p&gt;[code]&lt;br /&gt;
\subsection introdoxy Introduction to Doxygen&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;We don't care about the ID tag, but we want to keep the title and retain
it at the same location as the section title in the WordPress post. To
do this we split the line into a list of tokens, separated by
whitespace, using &lt;code&gt;line.split()&lt;/code&gt;. The resulting list, in &lt;code&gt;fields&lt;/code&gt;, would
look like this for the example above if we printed it out:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
['\\subsection', 'introdoxy', 'Introduction', 'to', 'Doxygen']&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The idea is to discard the first two elements and keep the rest, joining
them back together into a string, and stripping out the quotation marks.&lt;/p&gt;
&lt;p&gt;[code]&lt;br /&gt;
line = '## ' + ' '.join(fields[2:])&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Here the &lt;code&gt;string.join(list)&lt;/code&gt; syntax in Python joins all the elements of
&lt;code&gt;list&lt;/code&gt; together into a single string, using &lt;code&gt;string&lt;/code&gt; as the delimiter.
Hence in our example, &lt;code&gt;' '.join(fields[2:])&lt;/code&gt; would yield
&lt;code&gt;Introduction to Doxygen&lt;/code&gt;, and we prepend &lt;code&gt;##&lt;/code&gt; to this string to turn it
into standard Markdown format for a level 2 section header.&lt;/p&gt;
&lt;p&gt;There's probably a more compact way to deal with the multiple cases
(i.e. &lt;code&gt;\section&lt;/code&gt;, &lt;code&gt;\subsection&lt;/code&gt;, etc.) involving counting how many times
the string &lt;code&gt;sub&lt;/code&gt; appears and prepending the appropriate number of hashes
accordingly; but for only three cases, writing them out explicitly isn't
difficult, and leads to easier-to-understand code.&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;The next section of code deals with references. In Doxygen, we insert
references into the main body of the text like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;@ref ref01 &amp;quot;Fick (1855)&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(or we could use &lt;code&gt;\ref&lt;/code&gt; instead of &lt;code&gt;@ref&lt;/code&gt;). Elsewhere, there would be a
references section - in this case in a separate file called
&lt;code&gt;references.md&lt;/code&gt;, which is why we've previously seen that file being
hard-wired in the main script and then passed in to this function as an
argument. In the references section, there would be an entry like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;-# \anchor ref01 Fick, A, 1855. On liquid diffusion. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, X, 30-39.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The initial &lt;code&gt;-#&lt;/code&gt; is to create a numbered list, and the &lt;code&gt;\anchor ref01&lt;/code&gt;
creates an anchor that the earlier &lt;code&gt;@ref ref01&lt;/code&gt; syntax can link to. The
remainder is the text that appears in the references section.&lt;/p&gt;
&lt;p&gt;What we want to do is replace the in-line reference with a link to a
footnote, and use the long reference text as the footnote.&lt;/p&gt;
&lt;p&gt;For an individual references, the code that does this looks like this:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
# References&lt;/p&gt;
&lt;p&gt;refidstr = 'fn'+str(refnum)&lt;br /&gt;
refnum += 1&lt;/p&gt;
&lt;p&gt;fields = istr.split()&lt;br /&gt;
reftxt = " ".join(fields[2:]).strip('"')&lt;/p&gt;
&lt;p&gt;ostr = '&lt;a href="\#'+refidstr+'"&gt;'+reftxt+'&lt;/a&gt;'&lt;br /&gt;
line = line.replace(istr,ostr)&lt;/p&gt;
&lt;p&gt;doxref = fields[1]&lt;br /&gt;
for refline in fr:&lt;br /&gt;
if doxref in refline:&lt;br /&gt;
reffull = ' '.join(refline.strip().split()[3:])&lt;br /&gt;
break&lt;br /&gt;
footnotes.append('&lt;a name="'+refidstr+'"&gt;'+reffull+'&lt;/a&gt;')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Although you don't see it here, the Doxygen text containing the in-line
reference is contained in &lt;code&gt;istr&lt;/code&gt; - we'll explain how it got there
shortly. The first thing we do is create a unique string for the anchor
that will be used as the ID for the footnote; i.e. if the anchor is
&lt;code&gt;fn1&lt;/code&gt;, then the inline reference will be:&lt;/p&gt;
&lt;p&gt;[code lang="html"]&lt;br /&gt;
&lt;a href="fn1"&gt;Fick (1855)&lt;/a&gt;&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;and the footnote would be:&lt;/p&gt;
&lt;p&gt;[code lang="html"]&lt;br /&gt;
&lt;a name="fn1"&gt;Fick, A, 1855. On liquid diffusion...&lt;/a&gt;&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;We have previously set up a counter for the references we discover,
which was &lt;code&gt;refnum&lt;/code&gt;, so the code &lt;code&gt;refidstr = 'fn'+str(refnum)&lt;/code&gt; will
create &lt;code&gt;fn1&lt;/code&gt; for the first reference, &lt;code&gt;fn2&lt;/code&gt; for the second, etc. You can
see that &lt;code&gt;refnum&lt;/code&gt; is incremented by 1 in the next line of the code
fragment above to ensure this.&lt;/p&gt;
&lt;p&gt;Next, we want to extract the text for the in-line reference ("Fick
(1855)" in our example), for which we use the same kind of trick as we
did for the section headings. The only difference here is that we have
to add the &lt;code&gt;strip('"')&lt;/code&gt; function to strip off the quotation marks.&lt;/p&gt;
&lt;p&gt;At this point we have enough information to construct the new text for
the in-line reference:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
ostr = '&lt;a href="\#'+refidstr+'"&gt;'+reftxt+'&lt;/a&gt;'&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;and replace the original string with the new one:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
line = line.replace(istr,ostr)&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;There's one final job; we have to create the footnote and put it at the
bottom of the page. We'll store it in a list called &lt;code&gt;footnotes&lt;/code&gt; in the
interim, and then write the list out after all the other processing has
been finished, so it appears in its proper place at the bottom of the
page.&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
doxref = fields[1]&lt;br /&gt;
for refline in fr:&lt;br /&gt;
if doxref in refline:&lt;br /&gt;
reffull = ' '.join(refline.strip().split()[3:])&lt;br /&gt;
break&lt;br /&gt;
footnotes.append('&lt;a name="'+refidstr+'"&gt;'+reffull+'&lt;/a&gt;')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;So what is this doing? We know the text that Doxygen is using - &lt;code&gt;ref01&lt;/code&gt;
- in our example, because we can extract it from the second token of the
&lt;code&gt;istr&lt;/code&gt; line (where the first token is just the &lt;code&gt;@ref&lt;/code&gt; code). Then we
have to search line-by-line through the reference file, &lt;code&gt;fr&lt;/code&gt;, until we
find a line that contains the string we're after - this will cause
&lt;code&gt;if doxref in refline&lt;/code&gt; to return true. We know this is the right line,
so we can extract the long text of the reference into &lt;code&gt;reffull&lt;/code&gt; using
the same &lt;code&gt;split&lt;/code&gt; then &lt;code&gt;join&lt;/code&gt; technique as we've seen before, starting at
the fourth token (the first three being &lt;code&gt;-#&lt;/code&gt;, &lt;code&gt;\anchor&lt;/code&gt; and &lt;code&gt;ref01&lt;/code&gt;, all
of which we want to discard).&lt;/p&gt;
&lt;p&gt;The real code, however, is a bit more complex; firstly because we need
to find the appropriate text strings in our Doxygen code before we can
format them (recall we haven't explained how &lt;code&gt;istr&lt;/code&gt; gets defined yet),
and also because there might be more than one reference on one line, so
we have to deal with that. We do this via regular expressions, which
first requires that the Python &lt;code&gt;re&lt;/code&gt; module is imported (documented
&lt;a href="https://docs.python.org/2/library/re.html"&gt;here&lt;/a&gt;). Once it is, we can
compile a regular expression using the code we saw earlier but didn't
explain:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
p2 = re.compile('@ref [^"]&lt;em&gt; "[^"]&lt;/em&gt;"')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The regular expression is the bit inside the single quotes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;@ref [^&amp;quot;]* &amp;quot;[^&amp;quot;]*&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and the &lt;code&gt;[&lt;/code&gt;, &lt;code&gt;]&lt;/code&gt;, &lt;code&gt;^&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt; characters are special characters that
have particular meanings in the regular expression language. The caret,
&lt;code&gt;^&lt;/code&gt;, is a &lt;code&gt;not&lt;/code&gt; operator, so &lt;code&gt;^"&lt;/code&gt; means not the quotation mark
character. Using &lt;code&gt;[ ]&lt;/code&gt; defines a set of characters that are allowed, so
for example &lt;code&gt;[aeiou]&lt;/code&gt; would match any vowel character. So &lt;code&gt;[^"]&lt;/code&gt; means
any character from the set of characters that are not the quotation mark
&lt;code&gt;"&lt;/code&gt;. Finally, the &lt;code&gt;*&lt;/code&gt; character means match any number of whatever went
previously. Hence, for example, &lt;code&gt;a*&lt;/code&gt; would match &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;aa&lt;/code&gt;, &lt;code&gt;aaa&lt;/code&gt;, etc.
Putting all this together, the regular expression &lt;code&gt;[^"]*&lt;/code&gt;, which appears
twice, means match any string of any length that doesn't contain a
quotation mark. The reason we need to specify that the string shouldn't
contain quotation marks is that these are used as delimiters, to
surround the in-line text of the reference. If we could guarantee that
quotation marks would never appear elsewhere on the same line, it
wouldn't matter; but we can't.&lt;/p&gt;
&lt;p&gt;Now we understand the regular expression syntax used, we need to
understand the rest of the line. Compiling the regular expression
creates a special regular expression object, which we've bound to &lt;code&gt;p2&lt;/code&gt;,
and which can be used later. We do this by writing:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
for item in p2.finditer(line):&lt;br /&gt;
istr = item.group()&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This calls the &lt;code&gt;finditer&lt;/code&gt; method of the &lt;code&gt;p2&lt;/code&gt; regular expression object
on the text string &lt;code&gt;line&lt;/code&gt;, which returns an iterator of all the
instances where the pattern represented by &lt;code&gt;p2&lt;/code&gt; was matched. We need to
do this because there could be more than one match in any given &lt;code&gt;line&lt;/code&gt;.
The second line returns the actual matched text string from &lt;code&gt;item&lt;/code&gt;,
using the &lt;code&gt;group&lt;/code&gt; method, and puts it into &lt;code&gt;istr&lt;/code&gt;. We now have the full
thing:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
# Loop over all matches against p2 in line&lt;br /&gt;
for item in p2.finditer(line):&lt;/p&gt;
&lt;p&gt;# Extract the matched text&lt;br /&gt;
istr = item.group()&lt;/p&gt;
&lt;p&gt;# Create the unique reference (and increment the counter for next
time)&lt;br /&gt;
refidstr = 'fn'+str(refnum)&lt;br /&gt;
refnum += 1&lt;/p&gt;
&lt;p&gt;# Get the in-line reference text&lt;br /&gt;
fields = istr.split()&lt;br /&gt;
reftxt = " ".join(fields[2:]).strip('"')&lt;/p&gt;
&lt;p&gt;# Construct the WordPress-format inline reference and&lt;br /&gt;
# replace the old Doxygen-format one&lt;br /&gt;
ostr = '&lt;a href="\#'+refidstr+'"&gt;'+reftxt+'&lt;/a&gt;'&lt;br /&gt;
line = line.replace(istr,ostr)&lt;/p&gt;
&lt;p&gt;# Get the full reference text to use as the footnote&lt;br /&gt;
doxref = fields[1]&lt;br /&gt;
fr.seek(0)&lt;br /&gt;
for refline in fr:&lt;br /&gt;
if doxref in refline:&lt;br /&gt;
reffull = ' '.join(refline.strip().split()[3:])&lt;br /&gt;
break&lt;br /&gt;
footnotes.append('&lt;a name="'+refidstr+'"&gt;'+reffull+'&lt;/a&gt;')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The only additonal thing here that you haven't already seen is the
&lt;code&gt;fr.seek(0)&lt;/code&gt; line, which rewinds the references file to the beginning
each time we do a search through it. It's common snafu in Python that
once you've done a &lt;code&gt;for line in file:&lt;/code&gt;-type of construct, you can't just
do another one. The file pointer is left at the end, so the second time
round nothing will happen (and it's not an error).&lt;/p&gt;
&lt;h3&gt;Maths&lt;/h3&gt;
&lt;p&gt;The final set of replacement operations we want to conduct is to replace
any Doxygen-style maths delimiters with the appropriate WordPress ones.
Doxygen allows several different kinds of delimiter. Firstly, in-line
equations can be included by surrounding them with &lt;code&gt;\f$&lt;/code&gt; tags; e.g.:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;...the equation \f$ E = mc^2 \f$ is well-known...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Alternatively, we can create a numbered equation on its own line by
using the opening delimiter &lt;code&gt;\f{equation}&lt;/code&gt; and the closing delimiter
&lt;code&gt;\f}&lt;/code&gt;. For example:&lt;/p&gt;
&lt;p&gt;[code]&lt;br /&gt;
\f{equation}&lt;br /&gt;
F = ma&lt;br /&gt;
\f}&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Then finally, a non-numbered equation can be created on its own line by
using:&lt;/p&gt;
&lt;p&gt;[code]&lt;br /&gt;
\f[&lt;br /&gt;
a^2 + b^2 = c^2&lt;br /&gt;
\f]&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;In WordPress, there is only one way to embed mathematics, which is to
use the opening delimiter &lt;code&gt;$latex&lt;/code&gt; followed by the closing delimiter
&lt;code&gt;$&lt;/code&gt;. This is used whether we want the maths in-line or on its own line;
there's no support for equation numbering.&lt;/p&gt;
&lt;p&gt;Replacing the second two types is trivial, because the opening and
closing delimiters are different, as they are for WordPress. Hence:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
# Replace the maths delimiters&lt;br /&gt;
line = line.replace('\\f{equation}','&lt;span class="math"&gt;\(')  
line = line.replace('\\\\f[','\)&lt;/span&gt;')&lt;br /&gt;
line = line.replace('\\f}','&lt;span class="math"&gt;\(')  
line = line.replace('\\\\f]','\)&lt;/span&gt;')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;does the trick nicely. Note we add an extra &lt;code&gt;\&lt;/code&gt; to protect the &lt;code&gt;\&lt;/code&gt; that
appears in the string we want to match. Without this, the &lt;code&gt;\f&lt;/code&gt; would be
interpreted as the form-feed escape sequence.&lt;/p&gt;
&lt;p&gt;For the in-line equations it's slightly more complex, because the start
and end delimiter in Doxygen are the same, but we need to replace them
with different start and end delimiters for WordPress to understand. We
go back to regular expressions:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
# Replace the inline maths delimiters&lt;br /&gt;
for item in p1.finditer(line):&lt;br /&gt;
istr = item.group()&lt;br /&gt;
ostr = '&lt;span class="math"&gt;\('+istr.strip('@f\)&lt;/span&gt;')+'$'&lt;br /&gt;
line = line.replace(istr,ostr)&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;We saw &lt;code&gt;p1&lt;/code&gt; defined earlier as:&lt;/p&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
p1 = re.compile('@f\&lt;span class="math"&gt;\([^@]*@f\\\)&lt;/span&gt;')&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Here we are trying to match something that begins and ends with a
literal &lt;code&gt;@f$&lt;/code&gt;, which we have to write as &lt;code&gt;@f$&lt;/code&gt; because &lt;code&gt;$&lt;/code&gt; is also a
special character in the regular expression language, but we want it to
be interpreted literally. In between we will allow any expression of any
length as long as it doesn't contain a &lt;code&gt;@&lt;/code&gt; symbol. This is represented
by &lt;code&gt;[^@]*&lt;/code&gt;. The rest should be self-explanatory.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;So that's a lengthy explanation of a fairly short and simple script (it
certainly took a lot longer to write...). It's also a fairly esoteric
use case I should think, so will probably be of use to all of 3 other
people if I'm lucky! The final, full script is reproduced below.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;[code lang="python"]&lt;br /&gt;
import sys&lt;br /&gt;
import os&lt;br /&gt;
import re&lt;/p&gt;
&lt;h2&gt;#&lt;/h2&gt;
&lt;p&gt;def checkfile(filename):&lt;/p&gt;
&lt;p&gt;errmsg = []&lt;/p&gt;
&lt;p&gt;filebase, fileext = os.path.splitext(filename)&lt;/p&gt;
&lt;p&gt;if fileext != '.md':&lt;br /&gt;
errmsg.append(filename+' is not Markdown')&lt;/p&gt;
&lt;p&gt;if not os.path.isfile(filename):&lt;br /&gt;
errmsg.append(filename+' does not exist or is not&lt;br /&gt;
a file')&lt;/p&gt;
&lt;p&gt;return errmsg&lt;/p&gt;
&lt;h2&gt;#&lt;/h2&gt;
&lt;p&gt;def processfile(filename,reffile='references.md'):&lt;/p&gt;
&lt;p&gt;fi = open(filename,'r')&lt;br /&gt;
fo = open(filename+'.txt','w')&lt;br /&gt;
fr = open(reffile,'r')&lt;/p&gt;
&lt;p&gt;p1 = re.compile('@f\&lt;span class="math"&gt;\([^@]*@f\\\)&lt;/span&gt;')&lt;br /&gt;
p2 = re.compile('@ref [^"]&lt;em&gt; "[^"]&lt;/em&gt;"')&lt;/p&gt;
&lt;p&gt;refnum = 1&lt;br /&gt;
footnotes = []&lt;/p&gt;
&lt;p&gt;for line in fi:&lt;/p&gt;
&lt;p&gt;# Some of the later changes insert "&amp;lt;" and "&amp;gt;" so do these&lt;br /&gt;
# as early as possible&lt;br /&gt;
line = line.replace('&amp;lt;','&amp;lt;')&lt;br /&gt;
line = line.replace('&amp;gt;','&amp;gt;')&lt;/p&gt;
&lt;p&gt;# Remove the table of contents special command&lt;br /&gt;
line = line.replace('\\tableofcontents','')&lt;/p&gt;
&lt;p&gt;# Replace the Doxygen special commands for sections with&lt;br /&gt;
# Markdown&lt;br /&gt;
if '\section' in line:&lt;br /&gt;
fields = line.split()&lt;br /&gt;
line = '# ' + ' '.join(fields[2:])&lt;br /&gt;
if '\subsection' in line:&lt;br /&gt;
fields = line.split()&lt;br /&gt;
line = '## ' + ' '.join(fields[2:])&lt;br /&gt;
if '\subsubsection' in line:&lt;br /&gt;
fields = line.split()&lt;br /&gt;
line = '### ' + ' '.join(fields[2:])&lt;/p&gt;
&lt;p&gt;# References&lt;br /&gt;
# Doxygen format is '@ref doxref "reference text"'&lt;br /&gt;
# Replace with an HTML link to a footnote '&lt;a href="fn1"&gt;reference
text&lt;/a&gt;'&lt;br /&gt;
for item in p2.finditer(line):&lt;br /&gt;
istr = item.group()&lt;br /&gt;
refidstr = 'fn'+str(refnum)&lt;br /&gt;
fields = istr.split()&lt;br /&gt;
reftxt = " ".join(fields[2:]).strip('"')&lt;br /&gt;
doxref = fields[1]&lt;br /&gt;
fr.seek(0)&lt;br /&gt;
for refline in fr:&lt;br /&gt;
if doxref in refline:&lt;br /&gt;
reffull = ' '.join(refline.strip().split()[3:])&lt;br /&gt;
break&lt;br /&gt;
ostr = '&lt;a href="\#'+refidstr+'"&gt;'+reftxt+'&lt;/a&gt;'&lt;br /&gt;
line = line.replace(istr,ostr)&lt;br /&gt;
footnotes.append('&lt;a name="'+refidstr+'"&gt;'+reffull+'&lt;/a&gt;')&lt;br /&gt;
refnum += 1&lt;/p&gt;
&lt;p&gt;# Replace the maths delimiters&lt;br /&gt;
line = line.replace('\\f{equation}','&lt;span class="math"&gt;\(')  
line = line.replace('\\\\f[','\)&lt;/span&gt;')&lt;br /&gt;
line = line.replace('\\f}','&lt;span class="math"&gt;\(')  
line = line.replace('\\\\f]','\)&lt;/span&gt;')&lt;/p&gt;
&lt;p&gt;# Replace the inline maths delimiters&lt;br /&gt;
for item in p1.finditer(line):&lt;br /&gt;
istr = item.group()&lt;br /&gt;
ostr = '&lt;span class="math"&gt;\('+istr.strip('@f\)&lt;/span&gt;')+'$'&lt;br /&gt;
line = line.replace(istr,ostr)&lt;/p&gt;
&lt;p&gt;fo.write(line+'\n')&lt;/p&gt;
&lt;p&gt;# Write out the footnotes generated by processing the references&lt;br /&gt;
fo.write('&lt;hr&gt;\n')&lt;br /&gt;
fo.write('&lt;ol&gt;\n')&lt;br /&gt;
for fn in footnotes:&lt;br /&gt;
fo.write('&lt;li&gt;'+fn+'\n')&lt;br /&gt;
fo.write('&lt;/ol&gt;\n')&lt;/p&gt;
&lt;p&gt;fi.close()&lt;br /&gt;
fo.close()&lt;br /&gt;
fr.close()&lt;/p&gt;
&lt;p&gt;return&lt;/p&gt;
&lt;h2&gt;#&lt;/h2&gt;
&lt;p&gt;def processdox(filename,reffile):&lt;/p&gt;
&lt;p&gt;errmsg = checkfile(filename)&lt;/p&gt;
&lt;p&gt;if len(errmsg) == 0:&lt;br /&gt;
processfile(filename,reffile=reffile)&lt;/p&gt;
&lt;p&gt;return errmsg&lt;/p&gt;
&lt;h2&gt;#&lt;/h2&gt;
&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == "&lt;strong&gt;main&lt;/strong&gt;":&lt;/p&gt;
&lt;p&gt;args = sys.argv[1:]&lt;/p&gt;
&lt;p&gt;reffile = '/default/path/to/references.md'&lt;/p&gt;
&lt;p&gt;for arg in args:&lt;br /&gt;
errmsg = processdox(arg,reffile)&lt;br /&gt;
for msg in errmsg:&lt;br /&gt;
print msg&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="doxygen"></category><category term="latex"></category><category term="markdown"></category><category term="python"></category><category term="regular expressions"></category><category term="text processing"></category><category term="wordpress"></category></entry><entry><title>Restarting the LHC</title><link href="http://0x7df.github.io/restarting-the-lhc.html" rel="alternate"></link><updated>2015-03-22T18:13:00+00:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-03-22:restarting-the-lhc.html</id><summary type="html">&lt;p&gt;[caption id="" align="alignleft" width="320"]&lt;a href="https://www.flickr.com/photos/11304375@N07/2046228644/"&gt;&lt;img alt="The Large Hadron
Collider/ATLAS at CERN from Flickr via
Wylio" src="https://farm3.staticflickr.com/2326/2046228644_05507000b3_z.jpg" title="'The Large Hadron Collider/ATLAS at CERN' by Image Editor, released on Flickr under the Creative Commons Attribution License (https://creativecommons.org/licenses/by/2.0/), found via Wylio" /&gt;&lt;/a&gt;
© 2007 &lt;a href="https://www.flickr.com/people/11304375@N07/" title="'The Large Hadron Collider/ATLAS at CERN' published on Flickr by Image Editor"&gt;Image
Editor&lt;/a&gt;,
&lt;a href="https://www.flickr.com/photos/11304375@N07/2046228644/" title="from Flickr"&gt;Flickr&lt;/a&gt;
|
&lt;a href="https://creativecommons.org/licenses/by/2.0/" title="Creative Commons Attribution License  https://creativecommons.org/licenses/by/2.0/"&gt;CC-BY&lt;/a&gt;
| &lt;a href="https://www.wylio.com" title="Easily credit free 'large hadron collider' pictures with Wylio."&gt;via
Wylio&lt;/a&gt;[/caption]&lt;/p&gt;
&lt;p&gt;As the &lt;a href="http://home.web.cern.ch/topics/large-hadron-collider"&gt;Large Hadron Collider
(LHC)&lt;/a&gt; gears up,
after a big upgrade, to start its second major run, this post is a
reminder of the story so far.&lt;/p&gt;
&lt;h2&gt;What is it?&lt;/h2&gt;
&lt;p&gt;The Large Hadron Collider (LHC) is the largest &lt;a href="http://en.wikipedia.org/wiki/Particle_accelerator"&gt;particle
accelerator&lt;/a&gt; in the
world, costing over 6.3b Euros.&lt;/p&gt;
&lt;p&gt;For &lt;a href="http://www.particleadventure.org/hadrons.html"&gt;hadrons&lt;/a&gt;, read
&lt;a href="http://education.jlab.org/glossary/proton.html"&gt;protons&lt;/a&gt;. (Protons are
one of a class of sub-atomic particles called hadrons; hence the name.)
The basic idea is to accelerate the protons until they have very high
energies, and then smack them into each other; the result of each
collision is the creation of a number other particles, which can be
studied. In particular, the purpose of it was to find and study one
particular particle called the &lt;a href="www.newscientist.com/topic/higgs-boson"&gt;Higgs
boson&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;How are the particles accelerated?&lt;/h2&gt;
&lt;p&gt;To get to the necessary high energies, the protons need a long track; so
they're steered around a 27 km-long underground ring, typically
circulating many times before colliding. The acceleration, including the
steering round the circular track, is done by thousands of powerful
&lt;a href="http://hyperphysics.phy-astr.gsu.edu/hbase/solids/scmag.html"&gt;superconducting
magnets&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;How much energy?&lt;/h2&gt;
&lt;p&gt;The energy of the protons being collided is measured in TeV -
tera-electron-volts (probably easier just to say teravolts - people will
know what you mean from the context). During the first run of LHC, up to
the end of 2012, the proton beams had an energy of 3.5 TeV.&lt;/p&gt;
&lt;p&gt;Now, 1 TeV is 10^12^ - or 1 trillion - electron-volts, where an
&lt;a href="http://physics.stackexchange.com/questions/23294/how-much-is-1-electron-volt-ev"&gt;electron-volt is defined as the amount of energy an electron would have
if it were accelerated from rest through a potential difference of 1
V&lt;/a&gt;.
That turns out to be 1.6 × 10^-19^ J, so 3.5 TeV is 5.6 × 10^-7^ J. For
context, a &lt;a href="www.thefreedictionary.com/joule"&gt;Joule&lt;/a&gt;is the energy it
takes to lift 100 g (e.g. a small apple) through 1 m at the earth's
surface; so, with an energy of 3.5 TeV each, it would take the combined
energy of only 1.8 million of these protons to lift that apple...&lt;/p&gt;
&lt;p&gt;After the upgrade, the proton energy will be 6.5 TeV.&lt;/p&gt;
&lt;p&gt;The total collision energy is twice the beam energy, because two beams
of equal energy are directed head-on at each other. So the first run had
a collision energy of 7 TeV, and the post-upgrade second run will have a
collision energy of 13 TeV. The design intent was always that the LHC
would achieve 14 TeV, but because of technological problems (discussed
later), &lt;a href="home.web.cern.ch"&gt;CERN&lt;/a&gt;have played it safe and kept the energy
lower.&lt;/p&gt;
&lt;p&gt;However, even the lower collision energy of 7 TeV was a big step up from
what had been achieved before: the previous record, set by the 6.3 km
&lt;a href="http://www.fnal.gov/pub/tevatron/"&gt;Tevatron&lt;/a&gt;proton-&lt;a href="www.britannica.com/EBchecked/topic/28507/antiproton"&gt;antiproton&lt;/a&gt;
collider at &lt;a href="www.fnal.gov"&gt;Fermilab&lt;/a&gt;in Illinois, was 1.96 TeV. And, it
turned out OK, because as we'll see (and as you already know unless you
were living in a cave at the bottom of the sea in July 2012), the LHC
fulfilled its main purpose of discovering the Higgs boson.&lt;/p&gt;
&lt;h2&gt;What are the limiting factors on collision energy?&lt;/h2&gt;
&lt;p&gt;The beam energy, and therefore the collision energy, is limited by the
&lt;a href="http://whatis.techtarget.com/definition/magnetic-field"&gt;magnetic field&lt;/a&gt;
that steers the beam, and the size of the ring.&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://physics.info/lorentz/"&gt;magnetic force&lt;/a&gt; provides the
&lt;a href="http://theory.uwinnipeg.ca/physics/circ/node6.html"&gt;centripetal
acceleration&lt;/a&gt;, so:&lt;/p&gt;
&lt;div class="math"&gt;$$ q_pvB = \frac{\gamma m_p v^2}{r} $$&lt;/div&gt;
&lt;p&gt;where &lt;em&gt;q&lt;/em&gt;~p~ and &lt;em&gt;m&lt;/em&gt;~p~ are the charge and mass of the proton,
respectively, &lt;em&gt;v&lt;/em&gt; is its speed, &lt;em&gt;B&lt;/em&gt; is the magnetic field strength, &lt;em&gt;r&lt;/em&gt;
is the radius of the circular motion, and &lt;em&gt;γ&lt;/em&gt; is the &lt;a href="http://simple.wikipedia.org/wiki/Lorentz_factor"&gt;relativistic
factor&lt;/a&gt; that we must
include to account for the fact that the protons are moving at an
appreciable fraction of the speed of light. The energy of a relativistic
proton is &lt;em&gt;γm&lt;/em&gt;~p~, so:&lt;/p&gt;
&lt;div class="math"&gt;$$ q_p B = \frac{E v}{r} $$&lt;/div&gt;
&lt;p&gt;Hence:&lt;/p&gt;
&lt;div class="math"&gt;$$ E = \frac{q_p B r}{v} $$&lt;/div&gt;
&lt;p&gt;A larger ring would have a smaller radius of curvature, and so particles
could be given higher energies and still be kept on track with a given
field strength. For example, using the LHC-type 9
&lt;a href="http://www.teslasociety.com/teslaunit.htm"&gt;Tesla&lt;/a&gt; magnets in a 100
km-circumference collider, rather than a 27 km one, would allow an
increase of the collision energy to 50 TeV. Clearly, the limitation on
size is the cost.&lt;/p&gt;
&lt;p&gt;Alternatively, for a fixed-size ring, further increasing the beam energy
means having to increase the field strength. The limiting factor for the
field strength is local heating in the superconducting coils, caused in
turn by movement due to the high fields themselves. The heating causes
the coils to cease to be superconducting; this is called &lt;em&gt;quenching&lt;/em&gt;.
The magnet starts to conduct normally, and releases a large part of its
stored energy as heat, which in turn boils off the &lt;a href="http://www.wired.com/2012/08/questions-and-answers-about-liquid-helium/"&gt;liquid
helium&lt;/a&gt;
coolant and induces high pressures. (Note that, during preparations,
quenching is done deliberately to increase the strength of the field
that the magnets can support. The field is gradually increased until
quenching occurs; when this process is repeated, the quenching occurs at
a higher field strength. This is continued until the magnets can support
a sufficiently high field for the beam energy required. The process is
called &lt;em&gt;training&lt;/em&gt;, and takes months.)&lt;/p&gt;
&lt;p&gt;Furthermore, protons, like electrons and other charged particles, emit
&lt;a href="http://abyss.uoregon.edu/~js/glossary/synchrotron_radiation.html"&gt;synchrotron
radiation&lt;/a&gt;
and thus lose energy when they travel in circular orbits such as in the
LHC. The radiated power goes as the fourth power of &lt;em&gt;γ&lt;/em&gt;, and since the
energy of a relativistic proton is &lt;em&gt;γm&lt;/em&gt;~p~, the rate of energy loss is
proportional to the fourth power of the beam energy. Clearly also, the
loss is worse for electrons and positrons, because of their lower mass,
than for protons.&lt;/p&gt;
&lt;h2&gt;Is the beam energy all that matters?&lt;/h2&gt;
&lt;p&gt;The other important aspect of a particle collider is the intensity of
the beam, which dictates the rate of collisions. This is usually
characterised by a quantity called the &lt;em&gt;luminosity.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Working out the collision rate is fairly simply. It helps to know that
the particles are actually grouped into &lt;em&gt;bunches&lt;/em&gt;, rather than being a
continuous stream. If we imagine one beam as a stationary target and the
other beam as impacting on it (with twice the nominal collision energy),
it makes it easier to work out the collision rate. The number of protons
in the target bunch is &lt;em&gt;n~T~&lt;/em&gt;, and the cross-sectional area of each
proton is &lt;em&gt;σ&lt;/em&gt;, so the total area 'blocked out' by the target protons in
&lt;em&gt;n~T~σ&lt;/em&gt;. The actual cross-sectional area of the beam is &lt;em&gt;πr&lt;/em&gt;^2^; so the
proportion of this that's blocked out by protons is &lt;em&gt;n~T~σ&lt;/em&gt; / &lt;em&gt;πr&lt;/em&gt;^2^ -
the rest of the area is empty space. (This assumes that the protons in
the bunch are spaced out enough that, if we were to look along the
length of the 'target' beam, none of the protons further away from us
would be hidden behind any others. Because the size of the protons is so
astonishingly tiny relative to the cross-sectional area of the beam,
this is a fair assumption).&lt;/p&gt;
&lt;p&gt;Now, when the incident bunch of protons, &lt;em&gt;n~I~&lt;/em&gt;, impacts the target
bunch, the fraction of them that collide with a proton in the target is
equal to the fraction of the total area that's blocked out by target
protons; which we've already determined to be &lt;em&gt;n~T~σ&lt;/em&gt; / &lt;em&gt;πr&lt;/em&gt;^2^. Hence
there are &lt;em&gt;n~I~n~T~σ&lt;/em&gt; / &lt;em&gt;πr&lt;/em&gt;^2^ collisions for every bunch crossing. If
the rate of bunch crossings is &lt;em&gt;f&lt;/em&gt;, then the overall collision rate is
&lt;em&gt;fn~I~n~T~σ&lt;/em&gt; / &lt;em&gt;πr&lt;/em&gt;^2^.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.nature.com/ncomms/journal/v2/n9/full/ncomms1472.html"&gt;The cross-section for inelastic scatter is about 60
mb&lt;/a&gt;,
which is 6 × 10^-30^ m^2^. The diameter of the beam at the point of
collision is about 16 microns, so its cross-sectional area is 2 ×
10^-10^ m^2^. The ratio of these areas - and therefore the probability
of a collision - is about 3 × 10^-20^. The value of &lt;em&gt;n&lt;/em&gt; is about 10^11^,
which suggests the number of collisions is 300 per bunch crossing. The
bunches are crossed every 50 ns, so there are 2 × 10^7^ crossings per
second, and so 6 billion collisions per second. (Actually, the figures
are about a factor of 15 too high - &lt;a href="http://cds.cern.ch/record/1165534/files/CERN-Brochure-2009-003-Eng.pdf"&gt;CERN reports the number of
collision per bunch to be about 20 for bunch size of
10&lt;/a&gt;^11^,
suggesting the cross-section of 60 mb used should be more like 4 mb.)&lt;/p&gt;
&lt;p&gt;It's conventional to take the proton cross-section, which is dependent
on the proton energy but otherwise doesn't vary with the characteristics
of the accelerator, out of this equation; what's left is referred to as
the &lt;em&gt;luminosity&lt;/em&gt;, &lt;em&gt;L&lt;/em&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ L = \frac{f n_I n_T }{\pi r^2}  $$&lt;/div&gt;
&lt;p&gt;which is expressed in collisions per unit area per unit time, i.e. it
has units of [T]^-1^ [L]^-2^.  With luminosity so defined, the collision
rate is just the product of the accelerator's luminosity and the
cross-section of the proton collision (at the particular proton energy
in question).&lt;/p&gt;
&lt;p&gt;The total number of collisions during some time period is the integral
of the collision rate over the time period. Of course, this is equal to
the integral of the luminosity over the time period, times the
cross-section (assuming that the cross-section remains constant over
time, because it only depends on the beam energy, so it can be brought
out of this integration):&lt;/p&gt;
&lt;div class="math"&gt;$$ N = \int_0^T R dt  $$&lt;/div&gt;
&lt;div class="math"&gt;$$ N = \sigma \int_0^T L dt  $$&lt;/div&gt;
&lt;p&gt;The integrated luminosity has units of inverse area, [L]^-2^.&lt;/p&gt;
&lt;p&gt;The unit of area in typical use is the
&lt;a href="http://en.wikipedia.org/wiki/Barn_%28unit%29"&gt;&lt;em&gt;barn&lt;/em&gt;&lt;/a&gt;, which is
approximately the cross-sectional area of the
&lt;a href="http://education.jlab.org/itselemental/ele092.html"&gt;uranium&lt;/a&gt;nucleus (1
b is 10^-28^ m^2^). A &lt;em&gt;femtobarn&lt;/em&gt; is 10^-15^ b, so 1 fb = 10^-43^ m^2^.
Hence, the luminosity is measured in fb^-1^ s^-1^, which, when
multiplied by the collision cross-section in fb, gives a collision rate
in s^-1^. The time-integrated luminosity is therefore typically
expressed in &lt;em&gt;inverse femtobarns&lt;/em&gt;. In fact, the total number of
collisions is also usually quoted in inverse femtobarns (the true number
of collisions would be this number times the cross-section of the
proton-proton collision at whatever energy is being used). Given the
actual cross-section of the proton-proton collision at 7 TeV collision
energy, 1 fb^-1^ corresponds to about 8 × 10^12^ collisions.&lt;/p&gt;
&lt;h2&gt;What about the magnets?&lt;/h2&gt;
&lt;p&gt;There are several thousand superconducting magnets, cooled by helium to
1.9 K, of various types. For example, there are 392 quadrupole-type
magnets, which focus the proton beams along the straight sections, and
1,232 dipole magnets.&lt;/p&gt;
&lt;h2&gt;So there were teething problems?&lt;/h2&gt;
&lt;p&gt;There were some early problems. On 27 March 2007 one of the
quadrupole-type superconducting magnets failed a preliminary test. The
magnet was deliberately being subjected to high pressures, similar to
those that occur during quenching. The magnet that failed was built by
Fermilab.&lt;/p&gt;
&lt;p&gt;That was embarrassing, more for Fermilab than CERN, but things got worse
after initial switch-on. Protons were first streamed in both directions
around the tunnel on 10 September 2008, at 0.45 TeV beam energy.
However, only eight or nine days later, an accident occurred in which
the electrical connection between two of the 1,232 superconducting
dipole magnets evaporated while carrying a current of 8.7 kA, as the
beam energy was being increased to 5 TeV per beam. An electrical arc
occurred that ruptured the cooling system, allowing six tonnes of liquid
helium to boil off and leak into the tunnel. The pressure spike created
a shock wave that damaged a few hundred metres of the tunnel. Repairs
cost 40m Euros: 53 magnets had to be brought back to the surface, and
either repaired or replaced.&lt;/p&gt;
&lt;p&gt;On 23 November 2009, over a year later, the LHC returned to accelerating
protons, initially at 0.45 TeV per beam again. On December 9 members of
the &lt;a href="http://iopscience.iop.org/1748-0221/3/08/S08003"&gt;ATLAS
collaboration&lt;/a&gt; spotted
2.36 TeV collisions during test circulations. By December 16, there had
been 50,000 collisions at this energy. Overall this was four years later
than originally expected.&lt;/p&gt;
&lt;p&gt;In March 2010, CERN announced its plans to keep the collision energy to
7 TeV for the next 18-24 months, or until an inverse femtobarn of data
had been collected.&lt;/p&gt;
&lt;p&gt;It was realised that the copper stabilisers surrounding the
superconducting cables, which bear electrical current in the event that
the superconducting cables fail, had too high a resistance. There are
10,000 of these connections. The upgrade that has been going on over the
past two years has involved, among other things, replacing these shunts.
The upgrade cost 124m Euros. However, despite this, CERN is still going
to run LHC at 13 TeV rather than the design energy of 14 TeV.&lt;/p&gt;
&lt;h2&gt;What are the experiments?&lt;/h2&gt;
&lt;p&gt;There are four interaction points around the ring. The two main
experiments are the 7000-tonne ATLAS and the 12,500-tonne CMS (compact
muon solenoid), which are general-purpose detectors involved in the
search for the Higgs boson. A third, smaller experiment -
&lt;a href="http://www-pnp.physics.ox.ac.uk/~lhcb/index.shtml"&gt;LHCb&lt;/a&gt; - is involved
in detailed investigations into B-mesons. A fourth is
&lt;a href="http://www.uslhc.us/What_is_the_LHC/Experiments/ALICE"&gt;ALICE&lt;/a&gt;, which is
designed to study collisions between nuclei such as lead, which the LHC
delivers in special runs.&lt;/p&gt;
&lt;h2&gt;What is it for?&lt;/h2&gt;
&lt;p&gt;The Higgs boson was the last missing piece of &lt;a href="http://www.superstringtheory.com/experm/exper2.html"&gt;the Standard Model of
particle physics&lt;/a&gt;,
which was conceived in the early 1970s and remains the best description
of particle physics. The existence of the particle was predicted by
&lt;a href="http://www.ph.ed.ac.uk/higgs/peter-higgs"&gt;Peter Higgs&lt;/a&gt; in 1964, and
Higgs (along with&lt;a href="http://www.ulb.ac.be/sciences/physth/people_FEnglert.html"&gt;Francois
Englert&lt;/a&gt;) won
the &lt;a href="http://www.nobelprize.org/nobel_prizes/physics/laureates/2013/"&gt;Nobel Prize for physics in
2013&lt;/a&gt;,
after the particle was discovered at the LHC. The significance of the
Higgs is usually said to be that it explains how some particles acquire
mass.&lt;/p&gt;
&lt;p&gt;The idea is that there's a uniform scalar field pervading the universe,
and that interactions of particles with this field is what gives those
particles their mass. The stronger a particle's interaction with the
field is, the greater its mass. Photons have no interaction whatsoever,
electrons have a weak interaction, etc. This field has come to be known
as the &lt;a href="http://simple.wikipedia.org/wiki/Higgs_field"&gt;&lt;em&gt;Higgs field&lt;/em&gt;&lt;/a&gt;,
and the phenomenon of particles acquiring mass through coupling with
this field as the &lt;em&gt;Higgs mechanism&lt;/em&gt;. An analogy often given for the
mechanism is that it's like the particles are travelling through treacle
or molasses; particles more strongly coupled to the field aren't able to
travel as far, before they decay into lighter particles. But Higgs
himself has complained that this isn't an appropriate metaphor, as the
mechanism isn't dissipative.&lt;/p&gt;
&lt;p&gt;This mechanism was independently proposed by Francois Englert and
&lt;a href="http://cerncourier.com/cws/article/cern/46542"&gt;Robert Brout&lt;/a&gt; at the
&lt;a href="http://www.ulb.ac.be/ulb/presentation/uk.html"&gt;Free University of
Brussels&lt;/a&gt;, as well as
Higgs, and also by &lt;a href="http://www.nytimes.com/2014/05/04/us/gerald-guralnik-77-a-god-particle-pioneer-dies.html"&gt;Gerald
Guralnik&lt;/a&gt;,
&lt;a href="http://www.rochester.edu/news/hagen/"&gt;Carl Hagen&lt;/a&gt; and &lt;a href="http://www.imperial.ac.uk/people/t.kibble"&gt;Thomas
Kibble&lt;/a&gt; at &lt;a href="www.imperial.ac.uk"&gt;Imperial
College&lt;/a&gt;. Higgs has always felt uncomfortable about
his name being the one associated with the phenomenon; in fact, Brout
and Englert published their paper two weeks before he did. However,
Higgs was the one who proposed that the mechanism would have
'experimental consequences'; i.e. that, as a consequence of
wave-particle duality, vibrations in the Higgs field ought to manifest
as particles, in the same way that vibrations in the electromagnetic
field manifest as
&lt;a href="www.universetoday.com/74027/what-are-photons"&gt;photons&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The theory did not predict the mass, however, of the Higgs boson. Hence,
the &lt;a href="http://hepwww.rl.ac.uk/public/bigbang/file9.html"&gt;LEP&lt;/a&gt; (the Large
Electron Positron Collider, which previously occupied the tunnel the LHC
is in now and which operated with a collision energy of 200 GeV for 11
years from 1989 to 2000, to provide data to study the
&lt;a href="http://images-of-elements.com/particle-zoo/w-boson.php"&gt;W&lt;/a&gt; and &lt;a href="http://images-of-elements.com/particle-zoo/z-boson.php"&gt;Z
bosons&lt;/a&gt;, as well
as to search for the Higgs boson), the &lt;a href="http://www.scientificamerican.com/article/the-supercollider-that-never-was/"&gt;Superconducting Super
Collider&lt;/a&gt;
(which started to be built in Texas but was never completed due to cost
over-runs), the Tevatron at Fermilab, and ultimately the LHC, were
conceived of to verify the existence of the Higgs boson and measure its
mass.&lt;/p&gt;
&lt;p&gt;Prior to the LHC, theory suggested the mass of the Higgs was probably no
more than 186 GeV, and the LEP's failure to find it demonstrated that
the Higgs could not be less than 114 GeV. The Tevatron data at 1.96 TeV
collision energy ruled out masses around 165 GeV, and suggested the
160-180 GeV range was unlikely. This left two regions - a lighter region
of 114-160 GeV and a heavier region of 180-186 GeV - unexplored.&lt;/p&gt;
&lt;h2&gt;Finding the Higgs&lt;/h2&gt;
&lt;p&gt;On 30 March 2010, 18 months after start-up, the first collisions at 7
TeV collisions, were achieved, but at low luminosity. The original
intention was to run for 18-24 months at 7 TeV. Serious data collection
began in 2011; by summer 2011 the mass range of the Higgs had been
narrowed down to 115-145 GeV, and by 13 December 2011 CERN was able to
announce that the energy range had been restricted to 116-130 GeV, with
'an intriguing excess' at around 125 GeV.&lt;/p&gt;
&lt;p&gt;Further measurements began in April 2012. At this point, the beam energy
was increased from 3.5 TeV to 4 TeV. On 4 July 2012, the discovery of
the Higgs boson, with a mass of around 125 GeV, was announced with
5&lt;span class="math"&gt;\( \sigma\)&lt;/span&gt; significance by both ATLAS and
&lt;a href="http://iopscience.iop.org/1748-0221/3/08/S08004/pdf/1748-0221_3_08_S08004.pdf"&gt;CMS&lt;/a&gt;.
This is the same mass as about 133 protons, or one caesium atom.&lt;/p&gt;
&lt;p&gt;A further three months of run time was announced beyond the scheduled
shut-down at the end of 2012. The first run ended in February 2013,
after three years.&lt;/p&gt;
&lt;h2&gt;What is 'five sigma' significance?&lt;/h2&gt;
&lt;p&gt;The protons are collided in bunches, which causes pile-up - multiple
collisions within each bunch crossing. Furthermore, protons aren't
elementary particles like electrons, but are composite particles made of
&lt;a href="http://www.physics.ox.ac.uk/documents/PUS/dis/fundam.htm"&gt;quarks&lt;/a&gt;held
together by
&lt;a href="http://math.ucr.edu/home/baez/physics/ParticleAndNuclear/gluons.html"&gt;gluons&lt;/a&gt;.
Therefore, when they collide at these high energies, a lot of debris is
created - &lt;a href="www.feynman.com/"&gt;Feynman&lt;/a&gt;likened it to 'smashing garbage
cans into garbage cans'. This means there's a huge background of
detected events that disguise the events actually being looked for;
getting confidence about the signal in the light of this background
requires a very large number of collisions to be integrated over a long
period. This is why the luminosity is so significant; obviously the
higher the luminosity, the higher the collision rate, and the less time
it takes to accumulate the necessary data.&lt;/p&gt;
&lt;p&gt;So, the determination of the existence of the Higgs was a statistical
one, based on the agglomeration of a lot of data, rather than something
that could be determined from analysing any one particular collision.
There are many possible outcomes from a proton-proton collision at these
energies, each one a different combination of outgoing particles. Each
combination of outgoing particles is referred to as a &lt;em&gt;decay channel&lt;/em&gt;,
and the probability of each channel, and of the production of each
possible particle, is predicted by the Standard Model and precisely
known. Deviations from these known probabilities, indicating the
presence of a new particle, need to be built up over a long period of
time to establish confidence that it's not merely background. The number
of particles actually detected in a given energy range over a given
period of time is not fixed, but follows a &lt;a href="http://mathworld.wolfram.com/PoissonDistribution.html"&gt;Poisson
distribution&lt;/a&gt;
with a mean equal to the expected number based on the probability.
There's therefore a finite likelihood of detecting more than the
expected number even if there is no new particle in that energy range;
this is just a statistical fluctuation. The excess has to be large to be
attributed to the presence of a new particle; 5&lt;em&gt;σ&lt;/em&gt; is the 'gold
standard' (i.e. the excess has to be at least 5 times the standard
deviation for it to be confidently attributed to a new particle). An
excess of 3&lt;em&gt;σ&lt;/em&gt; is usually referred to as only 'evidence for' it.&lt;/p&gt;
&lt;h2&gt;How much data is this?&lt;/h2&gt;
&lt;p&gt;Each collision/event that is recorded represents a few hundred MB of
data. Because only a small fraction of the theoretically-possible decay
channels involve a Higgs boson being produced, many can be disregarded;
hence only a small fraction of events taking place need to be recorded,
with the majority being deliberately discarded. The data is initially
stored at the on-site tape silo facility known as Tier 0. Reconstructed
data are delivered to regional centres around the world.&lt;/p&gt;
&lt;h2&gt;What's next?&lt;/h2&gt;
&lt;p&gt;The upgrade involved:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Upgrading the 10,000 electrical interconnections between the dipole
    magnets (the component that failed in the accident that put the LHC
    out of commission for over a year)&lt;/li&gt;
&lt;li&gt;Improving the quench protection system, so that when quenching
    occurs the released energy is dissipated in a controlled way that
    minimises the chance of damage&lt;/li&gt;
&lt;li&gt;Replacing 18 of the 1,232 dipole magnets&lt;/li&gt;
&lt;li&gt;Upgrading the cryogenics&lt;/li&gt;
&lt;li&gt;Improving the vacuum in the beam pipe.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These modifications will allow the LHC to operate safely at the higher
collision energy of 13 TeV.&lt;/p&gt;
&lt;p&gt;The other operational change will be that the bunch size will be reduced
from 1.7 × 10^11^ protons per bunch down to 1.2 × 10^11^. This will
reduce 'pile-up', which is the simultaneous occurrence of numerous
collisions, which are hard to disentangle from each other when analysing
the data. However, the bunches will be collided every 25 ns instead of
every 50 ns, giving an overall increase in luminosity despite the
reduced bunch size.&lt;/p&gt;
&lt;p&gt;Now the two-year upgrade is complete, preparations are underway for the
next major run. The SPS - a 7 km-long accelerator that feeds protons to
the LHC - began being powered up in early July 2014.&lt;/p&gt;
&lt;p&gt;The objectives of the next set of experiments are to further study the
Higgs, but also to investigate dark matter. We've known for some time
that observable matter and energy make up only 5% of the energy in the
universe; the rest is invisible, hard to detect, and we don't know what
it is. The remainder is comprised of &lt;em&gt;dark energy&lt;/em&gt; (70%) and &lt;em&gt;dark
matter&lt;/em&gt; (25%) - we know it's there only through its gravitational pull.
At the new high energies, LHC scientists hope to be able to detect
particles that display the same properties&lt;/p&gt;
&lt;p&gt;LHC is expected to operate into the 2030s.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="particle physics"></category></entry><entry><title>Combinations and permutations</title><link href="http://0x7df.github.io/combinations-and-permutations.html" rel="alternate"></link><updated>2015-03-13T05:01:00+00:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-03-13:combinations-and-permutations.html</id><summary type="html">&lt;p&gt;&lt;a href="https://0x7df.files.wordpress.com/2015/02/abstract-balls-blue-200.png"&gt;&lt;img alt="abstract-balls-blue-200" src="https://0x7df.files.wordpress.com/2015/02/abstract-balls-blue-200.png" /&gt;&lt;/a&gt;I
recently had to explain the formulae for calculating the number of
combinations and permutations, when selecting &lt;span class="math"&gt;\( r $\)&lt;/span&gt;
items out of a pool of &lt;span class="math"&gt;\( n\)&lt;/span&gt;. In case you're ever
in the same boat, here's a refresher. There are four scenarios:&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;span style="color:#333399;"&gt;Combinations&lt;/span&gt;&lt;span
style="color:#333399;"&gt;(order doesn't matter):&lt;/span&gt;

&lt;/td&gt;
&lt;td&gt;
&lt;span style="color:#333399;"&gt;Permutations&lt;/span&gt; &lt;span
style="color:#333399;"&gt;(order does matter):&lt;/span&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;span style="color:#333399;"&gt;Selected items are replaced:&lt;/span&gt;

&lt;/td&gt;
&lt;td align="center"&gt;
$$ \frac{\left(n + r - 1\right)!}{ r!\left(n - 1\right)!}
$$

&lt;/td&gt;
&lt;td align="center"&gt;
$$ n^r $$

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;span style="color:#333399;"&gt;Selected items are not replaced:&lt;/span&gt;

&lt;/td&gt;
&lt;td align="center"&gt;
$$ \frac{n!}{r!\left(n-r\right)!} $$

&lt;/td&gt;
&lt;td align="center"&gt;
$$ \frac{n!}{\left(n-r\right)!} $$

&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3&gt;The factorial function&lt;/h3&gt;
&lt;p&gt;The exclamation mark represents &lt;a href="http://mathworld.wolfram.com/Factorial.html"&gt;the
&lt;em&gt;factorial&lt;/em&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ x! = x \times \left(x-1\right) \times \left(x-2\right)
\times \ldots \times 2 \times 1 $$&lt;/div&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;div class="math"&gt;$$ 5! = 5 \times 4 \times 3 \times 2 \times 1 = 120
$$&lt;/div&gt;
&lt;p&gt;You can invoke it in &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;factorial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;or perhaps, if you're going to use it a lot:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;factorial&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;fac&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;fac&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;24&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In &lt;a href="http://julialang.org/"&gt;Julia&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;julia
julia&amp;gt; factorial&lt;span class="o"&gt;(&lt;/span&gt;7&lt;span class="o"&gt;)&lt;/span&gt;
5040
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One last thing to know about the factorial function, is that &lt;span class="math"&gt;\( 0! = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;h3&gt;Permutations vs. combinations&lt;/h3&gt;
&lt;p&gt;To get the formula right, there are two choices to make. First, we have
to decide whether or not the order that items are selected in matters to
us. The various different arrangements of some group of items are called
&lt;em&gt;permutations&lt;/em&gt; when the order matters; e.g. if the arrangement (1, 2, 3)
is considered different from (2, 3, 1). If the order doesn't matter -
e.g. if the arrangements (a, b, c), (b, c, a), (b, a, c), etc., are
considered to be the same - then the arrangements are referred to as
&lt;em&gt;combinations&lt;/em&gt;.  This depends on the application.&lt;/p&gt;
&lt;h3&gt;With vs. without replacement&lt;/h3&gt;
&lt;p&gt;The second thing we have to consider is whether or not each item that
gets selected is put back into the pool before the next selection is
made. In a &lt;a href="http://en.wikipedia.org/wiki/Lottery"&gt;lottery&lt;/a&gt;, when a ball
is selected, it can't get selected again - this scenario is selection
&lt;em&gt;without replacement&lt;/em&gt;. For a group of kids playing &lt;a href="http://en.wikipedia.org/wiki/Hot_potato_%28game%29"&gt;pass the
parcel&lt;/a&gt;, as far as
they're concerned the same individual can get selected any number of
times - you stay in the game even after you've been selected and you
hope you might get chosen again. So this is selection &lt;em&gt;with
replacement&lt;/em&gt;. (NB in practice that's not a very sensible way to play
pass the parcel if you want an easy time, so adults running the game are
more likely to see it as selection &lt;em&gt;without replacement&lt;/em&gt;...)&lt;/p&gt;
&lt;p&gt;This leads to our four scenarios. Now let's work out the equations.&lt;/p&gt;
&lt;h3&gt;1. Permutations without replacement&lt;/h3&gt;
&lt;p&gt;You have &lt;span class="math"&gt;\( n\)&lt;/span&gt; distinct items and you have to
select &lt;span class="math"&gt;\( r\)&lt;/span&gt;. The order doesn't matter, and the
items aren't replaced in the pool once selected. There are &lt;span class="math"&gt;\( n\)&lt;/span&gt;
possibilities for the first item, but because there is
no replacement, there are only &lt;span class="math"&gt;\( n-1 $\)&lt;/span&gt;
possibilities for the second item, then only &lt;span class="math"&gt;\( n-2\)&lt;/span&gt;
possibilities for the third, etc. Since, to get the
total number, we're going to multiply these together, we start to see
that the formula for the total number of combinations, say &lt;span class="math"&gt;\( M\)&lt;/span&gt;,
is going to look something like:&lt;/p&gt;
&lt;div class="math"&gt;$$ M = n \times \left(n-1\right) \times \left(n-2\right)
\times \ldots $$&lt;/div&gt;
&lt;p&gt;If we continued this series of terms right to the end,  down to 1, then
that would be the same as taking the factorial of &lt;span class="math"&gt;\( n\)&lt;/span&gt;.
However, the number of terms we need to multiply
together is the same as the number of selections in whatever game we're
playing. We need to remember we're only selecting &lt;span class="math"&gt;\( r\)&lt;/span&gt;
items, so there are going to be only &lt;span class="math"&gt;\( r\)&lt;/span&gt;
terms:&lt;/p&gt;
&lt;div class="math"&gt;$$ M = n \times \left(n-1\right) \times \left(n-2\right)
\times \ldots \times \left(n-r+1\right) $$&lt;/div&gt;
&lt;p&gt;So just taking the factorial of &lt;span class="math"&gt;\( n\)&lt;/span&gt; will only
give the right answer if we want to select all the items eventually,
i.e. if &lt;span class="math"&gt;\( r = n\)&lt;/span&gt;. In general we need to truncate
the series after &lt;span class="math"&gt;\( r\)&lt;/span&gt; terms. How do we do this?
The answer is going to be &lt;span class="math"&gt;\( n!/\left(n-r\right)!\)&lt;/span&gt;,
and this will be easiest to see using an example. Let
&lt;span class="math"&gt;\($ n = 6\)&lt;/span&gt; and &lt;span class="math"&gt;\( r = 3\)&lt;/span&gt;. We
can write the answer out the long way: &lt;span class="math"&gt;\( M = 6 \times 5 \times 4
and compare this with the formula for $ n!\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ n! = 6 \times 5 \times 4 \times 3 \times 2 \times 1
$$&lt;/div&gt;
&lt;p&gt;Clearly, &lt;span class="math"&gt;\( M = n! /\left(3 \times 2 \times 1 \right)
$, which of course is the same as $ M = n! / 3!\)&lt;/span&gt;.
After working out another couple of simple examples
like this, you will see that the denominator always needs to be
&lt;span class="math"&gt;\( \left(n-r\right)!\)&lt;/span&gt;, to cancel out the last
&lt;span class="math"&gt;\( \left(n-r\right)!\)&lt;/span&gt; terms of the factorial of &lt;span class="math"&gt;\( n
$, leaving just the first $ r $\)&lt;/span&gt;
terms that we need. Hence:&lt;/p&gt;
&lt;div class="math"&gt;$$ M = \frac{n!}{\left(n-r\right)!} $$&lt;/div&gt;
&lt;h3&gt;2. Permutations with replacement&lt;/h3&gt;
&lt;p&gt;The difference here from the last example is that each time we make a
selection, we replace the item afterwards. Every selection is made from
the same original pool, rather than from a gradually decreasing pool. So
in this case the formula is going to look something like:&lt;/p&gt;
&lt;div class="math"&gt;$$ M = n \times n \times n \times \ldots $$&lt;/div&gt;
&lt;p&gt;The logic above about there only being &lt;span class="math"&gt;\( r\)&lt;/span&gt; terms
is exactly the same here, so we end up with:&lt;/p&gt;
&lt;div class="math"&gt;$$ M = n^r $$&lt;/div&gt;
&lt;p&gt;Simple!&lt;/p&gt;
&lt;h3&gt;3. Combinations without replacement&lt;/h3&gt;
&lt;p&gt;Now we take the first scenario - permutations without replacement - and
adapt it to the scenario where we don't distinguish between different
orderings of the selected items. Clearly, we're going to have reduce the
number - there will be fewer combinations than there are permutations.
Let's assume &lt;span class="math"&gt;\( n = 5\)&lt;/span&gt; and &lt;span class="math"&gt;\( r = 3\)&lt;/span&gt;.
Imagine the items are numbered balls like in a
lottery, and imagine the selected balls are (1, 3, 4). If these were
your numbers, you'd win no matter what order they came out in, so the
permutations of the &lt;span class="math"&gt;\( r\)&lt;/span&gt; selected items - (1, 3,
4), (1, 4, 3), (3, 1, 4), (3, 4, 1), (4, 1, 3) and (4, 3, 1) - are the
same, and should be considered just one distinct arrangement. Of course,
we already know that there are &lt;span class="math"&gt;\( r!\)&lt;/span&gt; permutations
of &lt;span class="math"&gt;\( r\)&lt;/span&gt; selected items, so if we care about the
order of the selected items, then there are going to be &lt;span class="math"&gt;\( r!\)&lt;/span&gt;
more possibilities than if we don't. So, all we have to
do to get the number of combinations is reduce the number of
permutations by a factor of &lt;span class="math"&gt;\( r!\)&lt;/span&gt;. Hence:&lt;/p&gt;
&lt;div class="math"&gt;$$ M = \frac{n!}{r!\left(n-r\right)!} $$&lt;/div&gt;
&lt;h3&gt;4. Combinations with replacement&lt;/h3&gt;
&lt;p&gt;This scenario is slightly more complicated. &lt;em&gt;Without&lt;/em&gt; replacement, to
get from the number of permutations to the number of combinations, we
just reduced by a factor of &lt;span class="math"&gt;\( r!\)&lt;/span&gt;. You might
therefore think that the answer here is going to be the number of
permutations &lt;em&gt;with&lt;/em&gt; replacement, similarly reduced by a factor of
&lt;span class="math"&gt;\($ r!\)&lt;/span&gt;; but it isn't. Let's take a simple example:
a pool of three numbers, and selection of two items. The permutations
without replacement are:&lt;/p&gt;
&lt;p&gt;(1,2) &lt;span style="color:#ff0000;"&gt;(2,1)&lt;/span&gt; (1,3) &lt;span
style="color:#ff0000;"&gt;(3,1)&lt;/span&gt; (2,3) &lt;span
style="color:#ff0000;"&gt;(3,2)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the additional ones if replacement is allowed are:&lt;/p&gt;
&lt;p&gt;(1,1) (2,2) (3,3)&lt;/p&gt;
&lt;p&gt;The permutations highlighted in red are the ones you'd get rid of if you
were interested only in combinations. Notice that there aren't any red
ones in the second batch - the "extra" possibilities that arise when
replacement is allowed are the same for permutations as for combinations
(in this special case of selecting two items). When you generalise this
idea to larger numbers, you do end up with some red items in the second
batch, but not as high a proportion as in the first batch. So we have to
reduce the second batch by some different factor, not &lt;span class="math"&gt;\( r!\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This shows us why reducing the total number of permutations by
&lt;span class="math"&gt;\( r!\)&lt;/span&gt; doesn't work with replacement, but it doesn't
actually help us do the calculation, because we can't easily work out
how big the second batch is, nor what factor to reduce it by. However,
what if we pretend that, whenever we get repetition due to the items
being replaced, an item being selected a second time is actually a new
item? So instead of (1,1) we could perhaps write (1,1′), with the prime
on the second 1 indicating our pretense that it's a different item. If
we had (1,1,2,1) for an &lt;span class="math"&gt;\( r = 4\)&lt;/span&gt; trial, we'd call
it (1,1′,2,1′′), indicating that the three instances where 1 was
selected should all be treated as if they were different items. We're
now back in the realm of permutations without replacement, for which the
formula is &lt;span class="math"&gt;\( m! /r!\left(m-r\right)!\)&lt;/span&gt;, where now
we're using &lt;span class="math"&gt;\( m\)&lt;/span&gt;, for the "expanded" number of
items to choose from as a consequence of replacement being allowed,
rather than &lt;span class="math"&gt;\( n\)&lt;/span&gt;, the true number of distinct
items. Now we just need to work out &lt;span class="math"&gt;\( m\)&lt;/span&gt;. It turns
out that:&lt;/p&gt;
&lt;div class="math"&gt;$$ m = n + r - 1 $$&lt;/div&gt;
&lt;p&gt;That is, selecting &lt;em&gt;with&lt;/em&gt; replacement from a pool of &lt;span class="math"&gt;\( n\)&lt;/span&gt;
is like selecting &lt;em&gt;without&lt;/em&gt; replacement from a pool of
&lt;/p&gt;
&lt;div class="math"&gt;$$ n + r - 1$. There are $ r -1
extra possibilities to select from, because once we
have selected the first item, the remaining $ r - 1$
items could be (in reality) the same item every time,
but we are pretending that they are different. Hence, substituting for
$$&lt;/div&gt;
&lt;p&gt; m$:&lt;/p&gt;
&lt;div class="math"&gt;$$ m! /\left(m - r\right)! = \left(n + r - 1\right)! /\left(n
- 1\right)! $$&lt;/div&gt;
&lt;p&gt;This gives us the number of permutations, which we &lt;em&gt;can&lt;/em&gt; now reduce by
&lt;span class="math"&gt;\($ r!\)&lt;/span&gt; to get the number of combinations. Our final
formula is therefore:&lt;/p&gt;
&lt;div class="math"&gt;$$ M = \frac{\left(n + r - 1\right)!}{ r!\left(n - 1\right)!}
$$&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="combinations"></category><category term="combinatorics"></category><category term="factorial"></category><category term="julia"></category><category term="permutations"></category><category term="python"></category></entry><entry><title>Connecting Wordpress to Twitter with IFTTT</title><link href="http://0x7df.github.io/connecting-wordpress-to-twitter-via-ifttt.html" rel="alternate"></link><updated>2015-02-14T20:40:00+00:00</updated><author><name>0x7df</name></author><id>tag:0x7df.github.io,2015-02-14:connecting-wordpress-to-twitter-via-ifttt.html</id><summary type="html">&lt;p&gt;It's possible to string together web services - like
&lt;a href="https://wordpress.com"&gt;WordPress&lt;/a&gt;, &lt;a href="http://twitter.com"&gt;Twitter&lt;/a&gt;,
&lt;a href="https://www.facebook.com"&gt;Facebook&lt;/a&gt;, &lt;a href="https://www.gmail.com"&gt;Gmail&lt;/a&gt;,
&lt;a href="https://www.tumblr.com"&gt;Tumblr&lt;/a&gt;, &lt;a href="https://evernote.com/"&gt;Evernote&lt;/a&gt;,
etc. - using &lt;a href="http://ifttt.com"&gt;&lt;em&gt;If This Then
That&lt;/em&gt;&lt;/a&gt;&lt;em&gt;(&lt;/em&gt;&lt;a href="http://ifttt.com"&gt;&lt;em&gt;IFTTT&lt;/em&gt;&lt;/a&gt;for short).&lt;/p&gt;
&lt;p&gt;In IFTTT, you create &lt;em&gt;Recipes&lt;/em&gt;, each of which consists of a &lt;em&gt;Trigger&lt;/em&gt;,
and an &lt;em&gt;Action.&lt;/em&gt; Whenever you do something that is a Trigger for one of
your Recipes (like publishing a new WordPress blog post for example),
then the associated Action (such as tweeting the link to the blog post)
is automatically performed for you.&lt;/p&gt;
&lt;p&gt;I've added a pre-existing recipe to my IFTTT account that does exactly
that, and this blog entry is to test it.&lt;/p&gt;</summary></entry></feed>